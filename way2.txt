import torch 
import torch.nn as nn 
from torch.nn import functional as F 

class MLP(nn.Module):
    """ Very simple multi-layer perceptron (also called FFN)"""

    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):
        super().__init__()
        self.num_layers = num_layers
        h = [hidden_dim] * (num_layers - 1)
        self.layers = nn.ModuleList(nn.Linear(n, k)
                                    for n, k in zip([input_dim] + h, h + [output_dim]))

    def forward(self, x):
        for i, layer in enumerate(self.layers):
            x = F.relu(layer(x)) if i < self.num_layers - 1 else layer(x)
        return x


class depthwise_separable_conv(nn.Module):
    def __init__(self, nin, nout, padding=1, kernel_size=5, activation1=None, activation2=None):
        super(depthwise_separable_conv, self).__init__()
        self.depthwise = nn.Conv2d(
            nin, nin, kernel_size=kernel_size, padding=padding, groups=nin)
        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1)
        self.activation1 = activation1
        self.activation2 = activation2

    def forward(self, x):
        out = self.depthwise(x)
        if self.activation1 is not None:
            out = self.activation1(out)
        out = self.pointwise(out)
        if self.activation1 is not None:
            out = self.activation2(out)
        return out
    
dim = 256
gn=8
num_queries = 500
hidden_dim = dim 
T = 5 
hs = torch.rand([6, 1, num_queries, hidden_dim])
fpn3 = torch.rand((1, 256, 50, 50))
fpn4 = torch.rand((1, 512, 100, 100))


lay4 = torch.nn.Conv2d(dim, dim*T, 3, padding=1)
gn4 = torch.nn.GroupNorm(gn, dim*T)
lay5 = torch.nn.Conv2d(dim*2, dim*T, 3, padding=1)
gn5 = torch.nn.GroupNorm(gn, dim*T)
adapter3 = torch.nn.Conv2d(256, dim, 1)
adapter4 = torch.nn.Conv2d(dim*2, dim*T, 1)
convert_to_weight = MLP(dim, dim, dim*T, 2)
depth_sep_conv2d = depthwise_separable_conv(
    dim, dim, kernel_size=5, padding=2, activation1=F.relu, activation2=F.relu)


a = nn.Sequential(
    nn.Conv3d(dim, dim, kernel_size=[1, 1, 1], bias=False),
    nn.BatchNorm3d(
        num_features=dim, eps=1e-5, momentum=0.1
    ),
    nn.ReLU(inplace=True),
)

# Depthwise (channel-separated) 3x3x3x1 conv
# Depthwise (channel-separated) 1x3x3x1 spatial conv
b1 = nn.Conv3d(
    dim,
    dim,
    kernel_size=[1, 3, 3],
    stride=[1, 1, 1],
    padding=[0, 1, 1],
    bias=False,
)
# Depthwise (channel-separated) 3x1x1x1 temporal conv
b2 = nn.Conv3d(
    dim,
    dim,
    kernel_size=[3, 1, 1],
    stride=[1, 1, 1],
    padding=[1, 0, 0],
    bias=False,
)


x = torch.rand((1, 256, 25, 25))
print(f"input {fpn3.shape = }, {x.shape}")
cur_fpn = adapter3(fpn3)
x = cur_fpn + F.interpolate(x, size=cur_fpn.shape[-2:], mode="nearest")
#print(f"Interpolutaion with expan: {x.shape = }")
print(f"interpolation, {x.shape}")
x = lay4(x)
x = gn4(x)
x = F.relu(x)

print(f"after adapter1 {x.shape }")
cur_fpn = adapter4(fpn4)
print(f" adapter2 {cur_fpn.shape } {x.shape}")
x = cur_fpn + F.interpolate(x, size=cur_fpn.shape[-2:], mode="nearest")


T = 5
H, W = x.shape[-2:]
# x.unsqueeze(1).reshape(1, T, -1, H, W)
x = x.unsqueeze(1).reshape(1, -1, T, H, W)
x = b1(x)
x = b2(x)
x = F.relu(x)
x = a(x).permute(0, 2, 1, 3, 4)

B, BT, C, H, W = x.shape
L, B, N, C = hs.shape

# x = depth_sep_conv2d(x.view(B*BT, C, H, W)).view(B, BT, C, H, W)

print(f"after reshape {x.shape }")
print(f"HS input {hs.shape }")
w = convert_to_weight(hs).permute(1, 0, 2, 3)
print(f"after weight {w.shape }")
#torch.Size([1, 6, 100, 256])
#torch.Size([1, 5, 6, 100, 256])
w = w.unsqueeze(1).reshape(1, T, L, N, -1)
print(f"after reshape {w.shape }")
print(x.shape)
x = x.reshape(1, BT*C, H, W)
mask_logits = F.conv2d(x,
                       w.reshape(B*T*L*N, C, 1, 1), groups=BT)
print(f"mask logits {w.shape }")
mask_logits = mask_logits.view(
    B, T, L, N, H, W).permute(2, 0, 3, 1, 4, 5)