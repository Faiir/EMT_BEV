{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet import __version__ as mmdet_version\n",
    "from mmdet3d import __version__ as mmdet3d_version\n",
    "from mmseg import __version__ as mmseg_version\n",
    "import os\n",
    "from custome_logger import setup_custom_logger\n",
    "logger = setup_custom_logger()\n",
    "logger.debug(\"test\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.benchmark as benchmark\n",
    "from timeit import default_timer as timer\n",
    "from mmcv import Config\n",
    "from mmcv.runner import wrap_fp16_model\n",
    "from mmdet3d.models import build_model\n",
    "from mmdet3d.datasets import build_dataset\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def update_cfg(\n",
    "    cfg,\n",
    "    n_future=3,\n",
    "    receptive_field=3,\n",
    "    resize_lim=(0.38, 0.55),\n",
    "    final_dim=(256, 704),\n",
    "    grid_conf={\n",
    "        \"xbound\": [-51.2, 51.2, 0.8],\n",
    "        \"ybound\": [-51.2, 51.2, 0.8],\n",
    "        \"zbound\": [-10.0, 10.0, 20.0],\n",
    "        \"dbound\": [1.0, 60.0, 1.0],\n",
    "    },\n",
    "    det_grid_conf={\n",
    "        \"xbound\": [-51.2, 51.2, 0.8],\n",
    "        \"ybound\": [-51.2, 51.2, 0.8],\n",
    "        \"zbound\": [-10.0, 10.0, 20.0],\n",
    "        \"dbound\": [1.0, 60.0, 1.0],\n",
    "    },\n",
    "    map_grid_conf={\n",
    "        \"xbound\": [-30.0, 30.0, 0.15],\n",
    "        \"ybound\": [-15.0, 15.0, 0.15],\n",
    "        \"zbound\": [-10.0, 10.0, 20.0],\n",
    "        \"dbound\": [1.0, 60.0, 1.0],\n",
    "    },\n",
    "    motion_grid_conf={\n",
    "        \"xbound\": [-50.0, 50.0, 0.5],\n",
    "        \"ybound\": [-50.0, 50.0, 0.5],\n",
    "        \"zbound\": [-10.0, 10.0, 20.0],\n",
    "        \"dbound\": [1.0, 60.0, 1.0],\n",
    "    },\n",
    "    t_input_shape=(128, 128),\n",
    "    point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],\n",
    "):\n",
    "    \n",
    "    cfg[\"det_grid_conf\"] = det_grid_conf\n",
    "    cfg[\"map_grid_conf\"] = map_grid_conf\n",
    "    cfg[\"motion_grid_conf\"] = motion_grid_conf\n",
    "    cfg[\"grid_conf\"] = det_grid_conf\n",
    "\n",
    "    cfg[\"model\"][\"temporal_model\"][\"input_shape\"] = t_input_shape\n",
    "\n",
    "    cfg[\"data\"][\"val\"][\"pipeline\"][0][\"data_aug_conf\"][\"resize_lim\"] = resize_lim\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"pipeline\"][0][\"data_aug_conf\"][\n",
    "        \"resize_lim\"\n",
    "    ] = resize_lim\n",
    "    cfg[\"data\"][\"val\"][\"pipeline\"][0][\"data_aug_conf\"][\"final_dim\"] = final_dim\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"pipeline\"][0][\"data_aug_conf\"][\n",
    "        \"final_dim\"\n",
    "    ] = final_dim\n",
    "\n",
    "    cfg[\"data\"][\"test\"][\"pipeline\"][0][\"data_aug_conf\"][\"resize_lim\"] = resize_lim\n",
    "    cfg[\"data\"][\"test\"][\"pipeline\"][0][\"data_aug_conf\"][\"final_dim\"] = final_dim\n",
    "\n",
    "    cfg[\"model\"][\"pts_bbox_head\"][\"cfg_motion\"][\n",
    "        \"grid_conf\"\n",
    "    ] = motion_grid_conf  # motion_grid\n",
    "    cfg[\"model\"][\"temporal_model\"][\"grid_conf\"] = grid_conf\n",
    "    cfg[\"model\"][\"transformer\"][\"grid_conf\"] = grid_conf\n",
    "    cfg[\"model\"][\"pts_bbox_head\"][\"grid_conf\"] = grid_conf\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"grid_conf\"] = motion_grid_conf\n",
    "    cfg[\"data\"][\"val\"][\"pipeline\"][3][\"grid_conf\"] = motion_grid_conf\n",
    "    cfg[\"data\"][\"test\"][\"pipeline\"][3][\"grid_conf\"] = motion_grid_conf\n",
    "    cfg[\"data\"][\"val\"][\"grid_conf\"] = grid_conf\n",
    "    cfg[\"data\"][\"test\"][\"grid_conf\"] = grid_conf\n",
    "\n",
    "    cfg[\"model\"][\"pts_bbox_head\"][\"det_grid_conf\"] = det_grid_conf\n",
    "\n",
    "    cfg[\"model\"][\"pts_bbox_head\"][\"map_grid_conf\"] = map_grid_conf\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"map_grid_conf\"] = map_grid_conf\n",
    "    cfg[\"data\"][\"test\"][\"pipeline\"][2][\"map_grid_conf\"] = map_grid_conf\n",
    "    cfg[\"data\"][\"val\"][\"pipeline\"][2][\"map_grid_conf\"] = map_grid_conf\n",
    "    cfg[\"data\"][\"test\"][\"map_grid_conf\"] = map_grid_conf\n",
    "    cfg[\"data\"][\"val\"][\"map_grid_conf\"] = map_grid_conf\n",
    "\n",
    "    cfg[\"model\"][\"pts_bbox_head\"][\"motion_grid_conf\"] = motion_grid_conf\n",
    "\n",
    "    cfg[\"data\"][\"test\"][\"pipeline\"][5][\"point_cloud_range\"] = point_cloud_range\n",
    "    cfg[\"data\"][\"train\"][\"pipeline\"][5][\n",
    "        \"point_cloud_range\"\n",
    "    ] = point_cloud_range  # point_cloud_range=None\n",
    "    cfg[\"data\"][\"train\"][\"pipeline\"][6][\n",
    "        \"point_cloud_range\"\n",
    "    ] = point_cloud_range  #'point_cloud_range =None\n",
    "    cfg[\"data\"][\"val\"][\"pipeline\"][5][\"point_cloud_range\"] = point_cloud_range\n",
    "\n",
    "    cfg[\"model\"][\"pts_bbox_head\"][\"cfg_motion\"][\"receptive_field\"] = receptive_field\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"receptive_field\"] = receptive_field\n",
    "    cfg[\"model\"][\"temporal_model\"][\"receptive_field\"] = receptive_field\n",
    "    cfg[\"data\"][\"test\"][\"receptive_field\"] = receptive_field\n",
    "    cfg[\"data\"][\"val\"][\"receptive_field\"] = receptive_field\n",
    "\n",
    "    cfg[\"data\"][\"val\"][\"future_frames\"] = n_future\n",
    "    cfg[\"model\"][\"pts_bbox_head\"][\"cfg_motion\"][\"n_future\"] = n_future\n",
    "    cfg[\"data\"][\"test\"][\"future_frames\"] = n_future\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"future_frames\"] = n_future\n",
    "    \n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"pipeline\"][4][\"map_grid_conf\"] = map_grid_conf\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"pipeline\"][5][\"grid_conf\"] = motion_grid_conf\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"pipeline\"][7][\"point_cloud_range\"] = point_cloud_range\n",
    "\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def import_modules_load_config(cfg_file=\"beverse_tiny.py\", samples_per_gpu=1):\n",
    "    cfg_path = r\"/home/niklas/ETM_BEV/BEVerse/projects/configs\"\n",
    "    cfg_path = os.path.join(cfg_path, cfg_file)\n",
    "\n",
    "    cfg = Config.fromfile(cfg_path)\n",
    "\n",
    "    # if args.cfg_options is not None:\n",
    "    #     cfg.merge_from_dict(args.cfg_options)\n",
    "    # import modules from string list.\n",
    "    if cfg.get(\"custom_imports\", None):\n",
    "        from mmcv.utils import import_modules_from_strings\n",
    "\n",
    "        import_modules_from_strings(**cfg[\"custom_imports\"])\n",
    "\n",
    "    # import modules from plguin/xx, registry will be updated\n",
    "    if hasattr(cfg, \"plugin\"):\n",
    "        if cfg.plugin:\n",
    "            import importlib\n",
    "\n",
    "            if hasattr(cfg, \"plugin_dir\"):\n",
    "                plugin_dir = cfg.plugin_dir\n",
    "                _module_dir = os.path.dirname(plugin_dir)\n",
    "                _module_dir = _module_dir.split(\"/\")\n",
    "                _module_path = _module_dir[0]\n",
    "\n",
    "                for m in _module_dir[1:]:\n",
    "                    _module_path = _module_path + \".\" + m\n",
    "                print(_module_path)\n",
    "                plg_lib = importlib.import_module(_module_path)\n",
    "            else:\n",
    "                # import dir is the dirpath for the config file\n",
    "                _module_dir = cfg_path\n",
    "                _module_dir = _module_dir.split(\"/\")\n",
    "                _module_path = _module_dir[0]\n",
    "                for m in _module_dir[1:]:\n",
    "                    _module_path = _module_path + \".\" + m\n",
    "                print(_module_path)\n",
    "                plg_lib = importlib.import_module(_module_path)\n",
    "\n",
    "    samples_per_gpu = 1\n",
    "    if isinstance(cfg.data.test, dict):\n",
    "        cfg.data.test.test_mode = True\n",
    "        samples_per_gpu = cfg.data.test.pop(\"samples_per_gpu\", 1)\n",
    "        if samples_per_gpu > 1:\n",
    "            # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n",
    "            cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n",
    "    elif isinstance(cfg.data.test, list):\n",
    "        for ds_cfg in cfg.data.test:\n",
    "            ds_cfg.test_mode = True\n",
    "        samples_per_gpu = max(\n",
    "            [ds_cfg.pop(\"samples_per_gpu\", 1) for ds_cfg in cfg.data.test]\n",
    "        )\n",
    "        if samples_per_gpu > 1:\n",
    "            for ds_cfg in cfg.data.test:\n",
    "                ds_cfg.pipeline = replace_ImageToTensor(ds_cfg.pipeline)\n",
    "\n",
    "    return cfg\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_time_host(\n",
    "    model: nn.Module,\n",
    "    input_tensor: torch.Tensor,\n",
    "    num_repeats: int = 100,\n",
    "    num_warmups: int = 10,\n",
    "    synchronize: bool = True,\n",
    "    continuous_measure: bool = True,\n",
    ") -> float:\n",
    "\n",
    "    for _ in range(num_warmups):\n",
    "        _ = model.forward(input_tensor)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    elapsed_time_ms = 0\n",
    "\n",
    "    if continuous_measure:\n",
    "        start = timer()\n",
    "        for _ in range(num_repeats):\n",
    "            _ = model.forward(input_tensor)\n",
    "        if synchronize:\n",
    "            torch.cuda.synchronize()\n",
    "        end = timer()\n",
    "        elapsed_time_ms = (end - start) * 1000\n",
    "\n",
    "    else:\n",
    "        for _ in range(num_repeats):\n",
    "            start = timer()\n",
    "            _ = model.forward(input_tensor)\n",
    "            if synchronize:\n",
    "                torch.cuda.synchronize()\n",
    "            end = timer()\n",
    "            elapsed_time_ms += (end - start) * 1000\n",
    "\n",
    "    return elapsed_time_ms / num_repeats\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_time_device(\n",
    "    model: nn.Module,\n",
    "    input_tensor: torch.Tensor,\n",
    "    num_repeats: int = 100,\n",
    "    num_warmups: int = 10,\n",
    "    synchronize: bool = True,\n",
    "    continuous_measure: bool = True,\n",
    ") -> float:\n",
    "\n",
    "    for _ in range(num_warmups):\n",
    "        _ = model.forward(input_tensor)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    elapsed_time_ms = 0\n",
    "\n",
    "    if continuous_measure:\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        start_event.record()\n",
    "        for _ in range(num_repeats):\n",
    "            _ = model.forward(input_tensor)\n",
    "        end_event.record()\n",
    "        if synchronize:\n",
    "            # This has to be synchronized to compute the elapsed time.\n",
    "            # Otherwise, there will be runtime error.\n",
    "            torch.cuda.synchronize()\n",
    "        elapsed_time_ms = start_event.elapsed_time(end_event)\n",
    "\n",
    "    else:\n",
    "        for _ in range(num_repeats):\n",
    "            start_event = torch.cuda.Event(enable_timing=True)\n",
    "            end_event = torch.cuda.Event(enable_timing=True)\n",
    "            start_event.record()\n",
    "            _ = model.forward(input_tensor)\n",
    "            end_event.record()\n",
    "            if synchronize:\n",
    "                # This has to be synchronized to compute the elapsed time.\n",
    "                # Otherwise, there will be runtime error.\n",
    "                torch.cuda.synchronize()\n",
    "            elapsed_time_ms += start_event.elapsed_time(end_event)\n",
    "\n",
    "    return elapsed_time_ms / num_repeats\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_inference(model: nn.Module, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "    # from model.forward because BEVerse differentiates between different input types - img lidar etc \n",
    "    return model.forward_dummy()\n",
    "\n",
    "def calculate_birds_eye_view_parameters(x_bounds, y_bounds, z_bounds):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "        x_bounds: Forward direction in the ego-car.\n",
    "        y_bounds: Sides\n",
    "        z_bounds: Height\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        bev_resolution: Bird's-eye view bev_resolution\n",
    "        bev_start_position Bird's-eye view first element\n",
    "        bev_dimension Bird's-eye view tensor spatial dimension\n",
    "    \"\"\"\n",
    "    bev_resolution = torch.tensor([row[2] for row in [x_bounds, y_bounds, z_bounds]])\n",
    "    bev_start_position = torch.tensor(\n",
    "        [row[0] + row[2] / 2.0 for row in [x_bounds, y_bounds, z_bounds]]\n",
    "    )\n",
    "    bev_dimension = torch.tensor(\n",
    "        [(row[1] - row[0]) / row[2] for row in [x_bounds, y_bounds, z_bounds]],\n",
    "        dtype=torch.long,\n",
    "    )\n",
    "\n",
    "    return bev_resolution, bev_start_position, bev_dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects.mmdet3d_plugin\n",
      "CenterPointBBoxCoder\n",
      "BaseMotionHead\n",
      "Future Prediction\n",
      "Future Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 15:19:20,575 - mmdet3d - INFO - Use load_from_http loader\n",
      "2022-11-27 15:19:20,710 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.conv1.weight - torch.Size([128, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,710 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,711 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,712 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,714 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,715 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,717 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.downsample.weight - torch.Size([128, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,718 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.downsample.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,720 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.conv1.weight - torch.Size([128, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,721 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,722 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,723 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,724 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,725 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,726 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.conv1.weight - torch.Size([256, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,728 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,734 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,736 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,737 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,738 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,739 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.downsample.weight - torch.Size([256, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,741 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.downsample.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,742 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,743 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,745 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,746 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,749 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,750 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,751 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.conv1.weight - torch.Size([512, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,752 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,755 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,756 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,757 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,759 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,760 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.downsample.weight - torch.Size([512, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,762 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.downsample.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,763 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.conv1.weight - torch.Size([512, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,764 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,766 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,767 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,770 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,771 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,772 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.up1.conv.0.weight - torch.Size([512, 640, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,773 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,779 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,782 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.up1.conv.3.weight - torch.Size([512, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,800 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,801 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,802 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.up2.1.weight - torch.Size([256, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,820 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.up2.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,822 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.up2.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,823 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.up2.4.weight - torch.Size([256, 256, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,824 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.3dod.up2.4.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,837 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.0.0.conv1.weight - torch.Size([128, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,838 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,839 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,840 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.0.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,841 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,841 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,842 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.0.0.downsample.weight - torch.Size([128, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,846 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.0.0.downsample.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,847 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.0.1.conv1.weight - torch.Size([128, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,848 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,849 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,850 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.0.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,862 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,863 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,864 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.1.0.conv1.weight - torch.Size([256, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,865 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,867 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,868 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.1.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,868 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,869 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,870 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.1.0.downsample.weight - torch.Size([256, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,871 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.1.0.downsample.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,872 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.1.1.conv1.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,873 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,875 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,875 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.1.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,876 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,877 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,892 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.2.0.conv1.weight - torch.Size([512, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,911 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,919 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,922 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.2.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,923 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,924 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,941 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.2.0.downsample.weight - torch.Size([512, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,952 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.2.0.downsample.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,963 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.2.1.conv1.weight - torch.Size([512, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,964 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,964 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,965 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.2.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,965 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,966 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,966 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.up1.conv.0.weight - torch.Size([512, 640, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,967 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,967 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,968 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.up1.conv.3.weight - torch.Size([512, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,968 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,968 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,969 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.up2.1.weight - torch.Size([256, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,969 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.up2.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,970 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.up2.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,970 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.up2.4.weight - torch.Size([256, 256, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,971 - mmdet3d - INFO - \n",
      "pts_bbox_head.taskfeat_encoders.motion.up2.4.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,971 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.shared_conv.conv.weight - torch.Size([64, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,971 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.shared_conv.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,973 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.shared_conv.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,973 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,974 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,975 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,977 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.reg.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,979 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.reg.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,979 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,981 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,982 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,983 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.height.1.weight - torch.Size([1, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,983 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.height.1.bias - torch.Size([1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,984 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,985 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,986 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,986 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.dim.1.weight - torch.Size([3, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,995 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.dim.1.bias - torch.Size([3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:20,997 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,001 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,002 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,005 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.rot.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,006 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.rot.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,007 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,016 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,020 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,029 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.vel.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,030 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.vel.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,031 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,032 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,034 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,035 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.1.weight - torch.Size([1, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,036 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.1.bias - torch.Size([1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,038 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,039 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,049 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,055 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.reg.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,056 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.reg.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,059 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,061 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,062 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,063 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.height.1.weight - torch.Size([1, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,064 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.height.1.bias - torch.Size([1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,065 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,070 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,070 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,071 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.dim.1.weight - torch.Size([3, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,073 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.dim.1.bias - torch.Size([3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,076 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,078 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,081 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,083 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.rot.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,084 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.rot.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,085 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,086 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,089 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,093 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.vel.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,096 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.vel.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,098 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,111 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,112 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,114 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,116 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,117 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,119 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,121 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,122 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.reg.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,124 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.reg.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,130 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,131 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,133 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,135 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.height.1.weight - torch.Size([1, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,136 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.height.1.bias - torch.Size([1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,139 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,140 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,141 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,142 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.dim.1.weight - torch.Size([3, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,145 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.dim.1.bias - torch.Size([3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,151 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,153 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,154 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,155 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.rot.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,156 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.rot.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,159 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,160 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,166 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,168 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.vel.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,173 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.vel.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,174 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,175 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,176 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,177 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,178 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,180 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,181 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,188 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,190 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.reg.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,192 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.reg.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,194 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,195 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,196 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,197 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.height.1.weight - torch.Size([1, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,198 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.height.1.bias - torch.Size([1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,201 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,202 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,206 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,208 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.dim.1.weight - torch.Size([3, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,209 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.dim.1.bias - torch.Size([3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,210 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,211 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,213 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,214 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.rot.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,215 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.rot.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,216 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,217 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,219 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,221 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.vel.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,222 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.vel.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,232 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,233 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,235 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,236 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.1.weight - torch.Size([1, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,237 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.1.bias - torch.Size([1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,239 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,240 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,242 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,245 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.reg.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,247 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.reg.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,249 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,250 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,251 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,253 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.height.1.weight - torch.Size([1, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,255 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.height.1.bias - torch.Size([1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,258 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,259 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,262 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,264 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.dim.1.weight - torch.Size([3, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,265 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.dim.1.bias - torch.Size([3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,266 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,267 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,270 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,271 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.rot.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,272 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.rot.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,273 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,274 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,276 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,277 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.vel.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,278 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.vel.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,280 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,285 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,287 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,288 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,290 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,291 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,292 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,294 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,296 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.reg.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,298 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.reg.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,300 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,301 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,302 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,303 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.height.1.weight - torch.Size([1, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,305 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.height.1.bias - torch.Size([1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,306 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,307 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,308 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,311 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.dim.1.weight - torch.Size([3, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,312 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.dim.1.bias - torch.Size([3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,314 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,315 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,317 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,318 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.rot.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,320 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.rot.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,321 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,322 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,324 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,325 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.vel.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,326 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.vel.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,327 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,329 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,333 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,334 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.1.weight - torch.Size([2, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,335 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.1.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,336 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.segmentation.0.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,337 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,339 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,340 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.segmentation.3.weight - torch.Size([2, 256, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,340 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.segmentation.3.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,341 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_center.0.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,342 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,343 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,344 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_center.3.weight - torch.Size([1, 256, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,345 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_center.3.bias - torch.Size([1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,347 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_offset.0.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,360 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,360 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,361 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_offset.3.weight - torch.Size([2, 256, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,362 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_offset.3.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,363 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_flow.0.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,364 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,365 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,366 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_flow.3.weight - torch.Size([2, 256, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,367 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.task_heads.instance_flow.3.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,368 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv_down_project.weight - torch.Size([128, 256, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,369 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,370 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,371 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,372 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,373 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,375 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv_up_project.weight - torch.Size([128, 128, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,376 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,377 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,378 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.conv_skip_proj.weight - torch.Size([128, 256, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,380 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,380 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,381 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv_down_project.weight - torch.Size([64, 128, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,382 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,383 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,384 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,385 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,386 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,388 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv_up_project.weight - torch.Size([128, 64, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,389 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,390 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,391 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.conv_skip_proj.weight - torch.Size([128, 128, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,392 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,393 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,395 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.last_conv.0.weight - torch.Size([64, 128, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,396 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.present_distribution.last_conv.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,397 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv_down_project.weight - torch.Size([137, 274, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,398 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.weight - torch.Size([137]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,399 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.bias - torch.Size([137]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,400 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv.weight - torch.Size([137, 137, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,407 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.weight - torch.Size([137]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,408 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.bias - torch.Size([137]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,409 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv_up_project.weight - torch.Size([137, 137, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,410 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.weight - torch.Size([137]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,411 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.bias - torch.Size([137]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,412 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.conv_skip_proj.weight - torch.Size([137, 274, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,413 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.weight - torch.Size([137]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,415 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.bias - torch.Size([137]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,416 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv_down_project.weight - torch.Size([68, 137, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,417 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.weight - torch.Size([68]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,418 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.bias - torch.Size([68]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,419 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv.weight - torch.Size([68, 68, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,419 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.weight - torch.Size([68]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,420 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.bias - torch.Size([68]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,421 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv_up_project.weight - torch.Size([137, 68, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,422 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.weight - torch.Size([137]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,423 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.bias - torch.Size([137]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,424 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.conv_skip_proj.weight - torch.Size([137, 137, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,425 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.weight - torch.Size([137]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,426 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.bias - torch.Size([137]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,429 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.last_conv.0.weight - torch.Size([64, 137, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,430 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_distribution.last_conv.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,432 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.conv.weight - torch.Size([288, 288, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,433 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.weight - torch.Size([288]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,434 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.bias - torch.Size([288]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,435 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.offset_pred.weight - torch.Size([2, 288, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,437 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.offset_pred.bias - torch.Size([2]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,438 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_update.weight - torch.Size([256, 544, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,439 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_update.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,440 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_reset.weight - torch.Size([256, 544, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,441 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_reset.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,443 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.conv.weight - torch.Size([256, 544, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,444 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,444 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,445 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,447 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,448 - mmdet3d - INFO - \n",
      "pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,451 - mmdet3d - INFO - \n",
      "img_backbone.patch_embed.projection.weight - torch.Size([96, 3, 4, 4]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,452 - mmdet3d - INFO - \n",
      "img_backbone.patch_embed.projection.bias - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,452 - mmdet3d - INFO - \n",
      "img_backbone.patch_embed.norm.weight - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,453 - mmdet3d - INFO - \n",
      "img_backbone.patch_embed.norm.bias - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,454 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.0.norm1.weight - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,454 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.0.norm1.bias - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,455 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,456 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([288, 96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,457 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([288]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,458 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([96, 96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,459 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,460 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.0.norm2.weight - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,461 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.0.norm2.bias - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,461 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([384, 96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,462 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,464 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([96, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,469 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,482 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.1.norm1.weight - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,483 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.1.norm1.bias - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,484 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,485 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([288, 96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,486 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([288]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,487 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([96, 96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,488 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,490 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.1.norm2.weight - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,491 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.1.norm2.bias - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,492 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([384, 96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,493 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,494 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([96, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,495 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([96]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,499 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.downsample.norm.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,500 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.downsample.norm.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,501 - mmdet3d - INFO - \n",
      "img_backbone.stages.0.downsample.reduction.weight - torch.Size([192, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,502 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.0.norm1.weight - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,502 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.0.norm1.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,504 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,505 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,505 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,506 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,507 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,508 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.0.norm2.weight - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,509 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.0.norm2.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,510 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,511 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,512 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,512 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,513 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.1.norm1.weight - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,514 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.1.norm1.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,515 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,516 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,517 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,517 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,519 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,520 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.1.norm2.weight - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,520 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.1.norm2.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,522 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,523 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,524 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,525 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,526 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.downsample.norm.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,527 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.downsample.norm.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,528 - mmdet3d - INFO - \n",
      "img_backbone.stages.1.downsample.reduction.weight - torch.Size([384, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,529 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.0.norm1.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,530 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.0.norm1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,531 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,532 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,533 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,534 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,535 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,536 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.0.norm2.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,537 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.0.norm2.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,538 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,539 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,546 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,547 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,548 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.1.norm1.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,551 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.1.norm1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,554 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,555 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,556 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,557 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,558 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,559 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.1.norm2.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,560 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.1.norm2.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,561 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,562 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,563 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,563 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,564 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.2.norm1.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,565 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.2.norm1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,566 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,568 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([1152, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,569 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([1152]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,570 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([384, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,571 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,572 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.2.norm2.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,573 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.2.norm2.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,574 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([1536, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,575 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,575 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([384, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,576 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,577 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.3.norm1.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,577 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.3.norm1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,578 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,579 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([1152, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,582 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([1152]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,584 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([384, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,585 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,586 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.3.norm2.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,586 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.3.norm2.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,587 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([1536, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,588 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,589 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([384, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,590 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,591 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.4.norm1.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,591 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.4.norm1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,592 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,593 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([1152, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,593 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([1152]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,594 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([384, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,610 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,611 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.4.norm2.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,613 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.4.norm2.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,627 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([1536, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,644 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,645 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([384, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,646 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,646 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.5.norm1.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,647 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.5.norm1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,648 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,649 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([1152, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,650 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([1152]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,653 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([384, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,659 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,661 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.5.norm2.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,661 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.5.norm2.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,662 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([1536, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,665 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,671 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([384, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,671 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,672 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.downsample.norm.weight - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,673 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.downsample.norm.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,673 - mmdet3d - INFO - \n",
      "img_backbone.stages.2.downsample.reduction.weight - torch.Size([768, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,675 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.0.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,676 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.0.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,677 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,678 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,678 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,679 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,680 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,681 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.0.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,682 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.0.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,683 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,683 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,684 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,685 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,686 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.1.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,687 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.1.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,688 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,689 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,689 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,690 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,691 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,692 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.1.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,693 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.1.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,694 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,695 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,695 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,696 - mmdet3d - INFO - \n",
      "img_backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-11-27 15:19:21,696 - mmdet3d - INFO - \n",
      "img_backbone.norm2.weight - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,697 - mmdet3d - INFO - \n",
      "img_backbone.norm2.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,699 - mmdet3d - INFO - \n",
      "img_backbone.norm3.weight - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,700 - mmdet3d - INFO - \n",
      "img_backbone.norm3.bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,701 - mmdet3d - INFO - \n",
      "img_neck.up.conv.0.weight - torch.Size([512, 1152, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,701 - mmdet3d - INFO - \n",
      "img_neck.up.conv.1.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,702 - mmdet3d - INFO - \n",
      "img_neck.up.conv.1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,703 - mmdet3d - INFO - \n",
      "img_neck.up.conv.3.weight - torch.Size([512, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,703 - mmdet3d - INFO - \n",
      "img_neck.up.conv.4.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,704 - mmdet3d - INFO - \n",
      "img_neck.up.conv.4.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,714 - mmdet3d - INFO - \n",
      "transformer.frustum - torch.Size([59, 16, 44, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,715 - mmdet3d - INFO - \n",
      "transformer.depthnet.weight - torch.Size([123, 512, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,716 - mmdet3d - INFO - \n",
      "transformer.depthnet.bias - torch.Size([123]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,717 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.0.0.conv.weight - torch.Size([35, 70, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,718 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.0.0.norm.weight - torch.Size([35]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,719 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.0.0.norm.bias - torch.Size([35]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,720 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.0.1.conv.weight - torch.Size([35, 35, 2, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,721 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.0.1.norm.weight - torch.Size([35]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,721 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.0.1.norm.bias - torch.Size([35]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,722 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.1.0.conv.weight - torch.Size([35, 70, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,723 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.1.0.norm.weight - torch.Size([35]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,723 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.1.0.norm.bias - torch.Size([35]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,724 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.1.1.conv.weight - torch.Size([35, 35, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,724 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.1.1.norm.weight - torch.Size([35]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,725 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.1.1.norm.bias - torch.Size([35]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,726 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.2.conv.weight - torch.Size([35, 70, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,726 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.2.norm.weight - torch.Size([35]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,727 - mmdet3d - INFO - \n",
      "temporal_model.model.0.convolution_paths.2.norm.bias - torch.Size([35]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,728 - mmdet3d - INFO - \n",
      "temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.conv.weight - torch.Size([23, 70, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,729 - mmdet3d - INFO - \n",
      "temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.weight - torch.Size([23]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,730 - mmdet3d - INFO - \n",
      "temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.bias - torch.Size([23]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,731 - mmdet3d - INFO - \n",
      "temporal_model.model.0.aggregation.0.conv.weight - torch.Size([64, 128, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,732 - mmdet3d - INFO - \n",
      "temporal_model.model.0.aggregation.0.norm.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,733 - mmdet3d - INFO - \n",
      "temporal_model.model.0.aggregation.0.norm.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,734 - mmdet3d - INFO - \n",
      "temporal_model.model.0.projection.0.weight - torch.Size([64, 70, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,741 - mmdet3d - INFO - \n",
      "temporal_model.model.0.projection.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,742 - mmdet3d - INFO - \n",
      "temporal_model.model.0.projection.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,743 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.0.0.conv.weight - torch.Size([32, 64, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,744 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.0.0.norm.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,745 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.0.0.norm.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,746 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.0.1.conv.weight - torch.Size([32, 32, 2, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,747 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.0.1.norm.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,748 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.0.1.norm.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,749 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.1.0.conv.weight - torch.Size([32, 64, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,750 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.1.0.norm.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,751 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.1.0.norm.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,752 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.1.1.conv.weight - torch.Size([32, 32, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,753 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.1.1.norm.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,754 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.1.1.norm.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,755 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.2.conv.weight - torch.Size([32, 64, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,756 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.2.norm.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,759 - mmdet3d - INFO - \n",
      "temporal_model.model.1.convolution_paths.2.norm.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,762 - mmdet3d - INFO - \n",
      "temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.conv.weight - torch.Size([21, 64, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,763 - mmdet3d - INFO - \n",
      "temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.weight - torch.Size([21]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,764 - mmdet3d - INFO - \n",
      "temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.bias - torch.Size([21]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,765 - mmdet3d - INFO - \n",
      "temporal_model.model.1.aggregation.0.conv.weight - torch.Size([64, 117, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,766 - mmdet3d - INFO - \n",
      "temporal_model.model.1.aggregation.0.norm.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,767 - mmdet3d - INFO - \n",
      "temporal_model.model.1.aggregation.0.norm.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,769 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.0.0.conv.weight - torch.Size([32, 64, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,770 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.0.0.norm.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,770 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.0.0.norm.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,771 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.0.1.conv.weight - torch.Size([32, 32, 2, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,772 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.0.1.norm.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,773 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.0.1.norm.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,779 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.1.0.conv.weight - torch.Size([32, 64, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,780 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.1.0.norm.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,781 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.1.0.norm.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,783 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.1.1.conv.weight - torch.Size([32, 32, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,783 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.1.1.norm.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,784 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.1.1.norm.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,790 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.2.conv.weight - torch.Size([32, 64, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,791 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.2.norm.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,792 - mmdet3d - INFO - \n",
      "temporal_model.model.2.convolution_paths.2.norm.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,794 - mmdet3d - INFO - \n",
      "temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.conv.weight - torch.Size([21, 64, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,795 - mmdet3d - INFO - \n",
      "temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.norm.weight - torch.Size([21]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,799 - mmdet3d - INFO - \n",
      "temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.norm.bias - torch.Size([21]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,800 - mmdet3d - INFO - \n",
      "temporal_model.model.2.aggregation.0.conv.weight - torch.Size([64, 117, 1, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,801 - mmdet3d - INFO - \n",
      "temporal_model.model.2.aggregation.0.norm.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n",
      "2022-11-27 15:19:21,801 - mmdet3d - INFO - \n",
      "temporal_model.model.2.aggregation.0.norm.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of BEVerse  \n",
      " \n"
     ]
    }
   ],
   "source": [
    "import gc \n",
    "from copy import deepcopy\n",
    "\n",
    "cfg = import_modules_load_config(cfg_file=\"beverse_tiny_org.py\")\n",
    "\n",
    "\n",
    "cfg.data.train.dataset[\"data_root\"] = '/home/niklas/ETM_BEV/BEVerse/data/nuscenes'\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "\n",
    "data_loaders = [build_dataloader(\n",
    "    dataset,\n",
    "    samples_per_gpu=1,\n",
    "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "    dist=False,\n",
    "    shuffle=False,)]\n",
    "\n",
    "\n",
    "model = build_model(cfg.model, train_cfg=cfg.get(\n",
    "    \"train_cfg\"), test_cfg=cfg.get('test_cfg'))\n",
    "model.init_weights()\n",
    "\n",
    "\n",
    "cfg.checkpoint_config.meta = dict(\n",
    "    mmdet_version=mmdet_version,\n",
    "    mmseg_version=mmseg_version,\n",
    "    mmdet3d_version=mmdet3d_version,\n",
    "    config=cfg.pretty_text,\n",
    "    CLASSES=dataset.CLASSES,\n",
    "    PALETTE=dataset.PALETTE  # for segmentors\n",
    "    if hasattr(dataset, 'PALETTE') else None)\n",
    "\n",
    "# weights_tiny = torch.load(\n",
    "#     \"/home/niklas/ETM_BEV/BEVerse/weights/clean_weights_tiny.pth\")\n",
    "\n",
    "# search_weights = tuple(weights_tiny['state_dict'].keys())\n",
    "# state_dict_detr = (model.state_dict())\n",
    "# print(search_weights)\n",
    "# for k in state_dict_detr.keys():\n",
    "#     if k in search_weights:\n",
    "#         try:\n",
    "#             state_dict_detr[k] = weights_tiny[k].clone()\n",
    "#             state_dict_detr[k].requires_grad = False \n",
    "#             print(\n",
    "#                 f\"Loaded weights for {k}, and required grad: {state_dict_detr[k].requires_grad}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failure for {k}, exception {e}\")\n",
    "\n",
    "# model.load_state_dict(state_dict_detr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in model.named_parameters():\n",
    "    if v.requires_grad:\n",
    "        print(f\"{k} requires grad\")\n",
    "    else:\n",
    "        print(f\"{k} frozen weights grad\")\n",
    "\n",
    "print(\"*******************\"*12)\n",
    "\n",
    "wrap_fp16_model(model)\n",
    "\n",
    "for k, v in model.named_parameters():\n",
    "    if v.requires_grad:\n",
    "        print(f\"{k} requires grad\")\n",
    "    else:\n",
    "        print(f\"{k} frozen weights grad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(\"/home/niklas/ETM_BEV/BEVerse/weights/beverse_tiny.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   'pts_bbox_head.taskfeat_encoders.map.layers.0.0.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.0.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.0.downsample.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.0.downsample.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.1.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.1.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.0.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.0.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.0.downsample.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.0.downsample.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.1.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.1.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.0.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.0.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.0.downsample.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.0.downsample.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.1.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.1.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up1.conv.0.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up1.conv.1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up1.conv.1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up1.conv.1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up1.conv.1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up1.conv.1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up1.conv.3.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up1.conv.4.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up1.conv.4.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up1.conv.4.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up1.conv.4.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up1.conv.4.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up2.1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up2.2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up2.2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up2.2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up2.2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up2.2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up2.4.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.map.up2.4.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.downsample.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.downsample.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.downsample.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.downsample.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.downsample.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.downsample.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up1.conv.0.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up1.conv.3.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up2.1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up2.2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up2.2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up2.2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up2.2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up2.2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up2.4.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.3dod.up2.4.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.0.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.0.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.0.downsample.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.0.downsample.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.1.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.1.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.0.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.0.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.0.downsample.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.0.downsample.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.1.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.1.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.0.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.0.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.0.downsample.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.0.downsample.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.1.conv1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.1.conv2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up1.conv.0.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up1.conv.3.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up2.1.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up2.2.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up2.2.bias',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up2.2.running_mean',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up2.2.running_var',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up2.2.num_batches_tracked',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up2.4.weight',\n",
      "    'pts_bbox_head.taskfeat_encoders.motion.up2.4.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.shared_conv.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.shared_conv.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.shared_conv.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.shared_conv.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.shared_conv.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.shared_conv.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.reg.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.reg.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.height.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.height.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.dim.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.dim.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.rot.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.rot.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.vel.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.vel.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.reg.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.reg.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.height.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.height.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.dim.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.dim.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.rot.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.rot.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.vel.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.vel.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.reg.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.reg.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.height.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.height.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.dim.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.dim.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.rot.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.rot.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.vel.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.vel.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.reg.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.reg.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.height.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.height.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.dim.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.dim.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.rot.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.rot.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.vel.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.vel.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.reg.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.reg.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.height.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.height.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.dim.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.dim.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.rot.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.rot.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.vel.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.vel.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.reg.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.reg.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.height.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.height.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.dim.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.dim.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.rot.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.rot.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.vel.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.vel.1.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.bias',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.running_mean',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.running_var',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.1.weight',\n",
      "    'pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.1.bias',\n",
      "    'pts_bbox_head.task_decoders.map.task_heads.semantic_seg.0.weight',\n",
      "    'pts_bbox_head.task_decoders.map.task_heads.semantic_seg.1.weight',\n",
      "    'pts_bbox_head.task_decoders.map.task_heads.semantic_seg.1.bias',\n",
      "    'pts_bbox_head.task_decoders.map.task_heads.semantic_seg.1.running_mean',\n",
      "    'pts_bbox_head.task_decoders.map.task_heads.semantic_seg.1.running_var',\n",
      "    'pts_bbox_head.task_decoders.map.task_heads.semantic_seg.1.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.map.task_heads.semantic_seg.3.weight',\n",
      "    'pts_bbox_head.task_decoders.map.task_heads.semantic_seg.3.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.segmentation.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.segmentation.3.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.segmentation.3.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_center.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_center.3.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_center.3.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_offset.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_offset.3.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_offset.3.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_flow.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_flow.3.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.task_heads.instance_flow.3.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv_down_project.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv_up_project.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.conv_skip_proj.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv_down_project.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv_up_project.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.conv_skip_proj.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.last_conv.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.present_distribution.last_conv.0.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv_down_project.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv_up_project.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.conv_skip_proj.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv_down_project.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv_up_project.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.conv_skip_proj.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.last_conv.0.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_distribution.last_conv.0.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.offset_pred.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.offset_pred.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_update.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_update.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_reset.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_reset.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.num_batches_tracked',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.conv.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.weight',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.bias',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.running_mean',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.running_var',\n",
      "    'pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.num_batches_tracked',\n",
      "    'img_backbone.patch_embed.projection.weight',\n",
      "    'img_backbone.patch_embed.projection.bias',\n",
      "    'img_backbone.patch_embed.norm.weight',\n",
      "    'img_backbone.patch_embed.norm.bias',\n",
      "    'img_backbone.stages.0.blocks.0.norm1.weight',\n",
      "    'img_backbone.stages.0.blocks.0.norm1.bias',\n",
      "    'img_backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table',\n",
      "    'img_backbone.stages.0.blocks.0.attn.w_msa.relative_position_index',\n",
      "    'img_backbone.stages.0.blocks.0.attn.w_msa.qkv.weight',\n",
      "    'img_backbone.stages.0.blocks.0.attn.w_msa.qkv.bias',\n",
      "    'img_backbone.stages.0.blocks.0.attn.w_msa.proj.weight',\n",
      "    'img_backbone.stages.0.blocks.0.attn.w_msa.proj.bias',\n",
      "    'img_backbone.stages.0.blocks.0.norm2.weight',\n",
      "    'img_backbone.stages.0.blocks.0.norm2.bias',\n",
      "    'img_backbone.stages.0.blocks.0.ffn.layers.0.0.weight',\n",
      "    'img_backbone.stages.0.blocks.0.ffn.layers.0.0.bias',\n",
      "    'img_backbone.stages.0.blocks.0.ffn.layers.1.weight',\n",
      "    'img_backbone.stages.0.blocks.0.ffn.layers.1.bias',\n",
      "    'img_backbone.stages.0.blocks.1.norm1.weight',\n",
      "    'img_backbone.stages.0.blocks.1.norm1.bias',\n",
      "    'img_backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table',\n",
      "    'img_backbone.stages.0.blocks.1.attn.w_msa.relative_position_index',\n",
      "    'img_backbone.stages.0.blocks.1.attn.w_msa.qkv.weight',\n",
      "    'img_backbone.stages.0.blocks.1.attn.w_msa.qkv.bias',\n",
      "    'img_backbone.stages.0.blocks.1.attn.w_msa.proj.weight',\n",
      "    'img_backbone.stages.0.blocks.1.attn.w_msa.proj.bias',\n",
      "    'img_backbone.stages.0.blocks.1.norm2.weight',\n",
      "    'img_backbone.stages.0.blocks.1.norm2.bias',\n",
      "    'img_backbone.stages.0.blocks.1.ffn.layers.0.0.weight',\n",
      "    'img_backbone.stages.0.blocks.1.ffn.layers.0.0.bias',\n",
      "    'img_backbone.stages.0.blocks.1.ffn.layers.1.weight',\n",
      "    'img_backbone.stages.0.blocks.1.ffn.layers.1.bias',\n",
      "    'img_backbone.stages.0.downsample.norm.weight',\n",
      "    'img_backbone.stages.0.downsample.norm.bias',\n",
      "    'img_backbone.stages.0.downsample.reduction.weight',\n",
      "    'img_backbone.stages.1.blocks.0.norm1.weight',\n",
      "    'img_backbone.stages.1.blocks.0.norm1.bias',\n",
      "    'img_backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table',\n",
      "    'img_backbone.stages.1.blocks.0.attn.w_msa.relative_position_index',\n",
      "    'img_backbone.stages.1.blocks.0.attn.w_msa.qkv.weight',\n",
      "    'img_backbone.stages.1.blocks.0.attn.w_msa.qkv.bias',\n",
      "    'img_backbone.stages.1.blocks.0.attn.w_msa.proj.weight',\n",
      "    'img_backbone.stages.1.blocks.0.attn.w_msa.proj.bias',\n",
      "    'img_backbone.stages.1.blocks.0.norm2.weight',\n",
      "    'img_backbone.stages.1.blocks.0.norm2.bias',\n",
      "    'img_backbone.stages.1.blocks.0.ffn.layers.0.0.weight',\n",
      "    'img_backbone.stages.1.blocks.0.ffn.layers.0.0.bias',\n",
      "    'img_backbone.stages.1.blocks.0.ffn.layers.1.weight',\n",
      "    'img_backbone.stages.1.blocks.0.ffn.layers.1.bias',\n",
      "    'img_backbone.stages.1.blocks.1.norm1.weight',\n",
      "    'img_backbone.stages.1.blocks.1.norm1.bias',\n",
      "    'img_backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table',\n",
      "    'img_backbone.stages.1.blocks.1.attn.w_msa.relative_position_index',\n",
      "    'img_backbone.stages.1.blocks.1.attn.w_msa.qkv.weight',\n",
      "    'img_backbone.stages.1.blocks.1.attn.w_msa.qkv.bias',\n",
      "    'img_backbone.stages.1.blocks.1.attn.w_msa.proj.weight',\n",
      "    'img_backbone.stages.1.blocks.1.attn.w_msa.proj.bias',\n",
      "    'img_backbone.stages.1.blocks.1.norm2.weight',\n",
      "    'img_backbone.stages.1.blocks.1.norm2.bias',\n",
      "    'img_backbone.stages.1.blocks.1.ffn.layers.0.0.weight',\n",
      "    'img_backbone.stages.1.blocks.1.ffn.layers.0.0.bias',\n",
      "    'img_backbone.stages.1.blocks.1.ffn.layers.1.weight',\n",
      "    'img_backbone.stages.1.blocks.1.ffn.layers.1.bias',\n",
      "    'img_backbone.stages.1.downsample.norm.weight',\n",
      "    'img_backbone.stages.1.downsample.norm.bias',\n",
      "    'img_backbone.stages.1.downsample.reduction.weight',\n",
      "    'img_backbone.stages.2.blocks.0.norm1.weight',\n",
      "    'img_backbone.stages.2.blocks.0.norm1.bias',\n",
      "    'img_backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table',\n",
      "    'img_backbone.stages.2.blocks.0.attn.w_msa.relative_position_index',\n",
      "    'img_backbone.stages.2.blocks.0.attn.w_msa.qkv.weight',\n",
      "    'img_backbone.stages.2.blocks.0.attn.w_msa.qkv.bias',\n",
      "    'img_backbone.stages.2.blocks.0.attn.w_msa.proj.weight',\n",
      "    'img_backbone.stages.2.blocks.0.attn.w_msa.proj.bias',\n",
      "    'img_backbone.stages.2.blocks.0.norm2.weight',\n",
      "    'img_backbone.stages.2.blocks.0.norm2.bias',\n",
      "    'img_backbone.stages.2.blocks.0.ffn.layers.0.0.weight',\n",
      "    'img_backbone.stages.2.blocks.0.ffn.layers.0.0.bias',\n",
      "    'img_backbone.stages.2.blocks.0.ffn.layers.1.weight',\n",
      "    'img_backbone.stages.2.blocks.0.ffn.layers.1.bias',\n",
      "    'img_backbone.stages.2.blocks.1.norm1.weight',\n",
      "    'img_backbone.stages.2.blocks.1.norm1.bias',\n",
      "    'img_backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table',\n",
      "    'img_backbone.stages.2.blocks.1.attn.w_msa.relative_position_index',\n",
      "    'img_backbone.stages.2.blocks.1.attn.w_msa.qkv.weight',\n",
      "    'img_backbone.stages.2.blocks.1.attn.w_msa.qkv.bias',\n",
      "    'img_backbone.stages.2.blocks.1.attn.w_msa.proj.weight',\n",
      "    'img_backbone.stages.2.blocks.1.attn.w_msa.proj.bias',\n",
      "    'img_backbone.stages.2.blocks.1.norm2.weight',\n",
      "    'img_backbone.stages.2.blocks.1.norm2.bias',\n",
      "    'img_backbone.stages.2.blocks.1.ffn.layers.0.0.weight',\n",
      "    'img_backbone.stages.2.blocks.1.ffn.layers.0.0.bias',\n",
      "    'img_backbone.stages.2.blocks.1.ffn.layers.1.weight',\n",
      "    'img_backbone.stages.2.blocks.1.ffn.layers.1.bias',\n",
      "    'img_backbone.stages.2.blocks.2.norm1.weight',\n",
      "    'img_backbone.stages.2.blocks.2.norm1.bias',\n",
      "    'img_backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table',\n",
      "    'img_backbone.stages.2.blocks.2.attn.w_msa.relative_position_index',\n",
      "    'img_backbone.stages.2.blocks.2.attn.w_msa.qkv.weight',\n",
      "    'img_backbone.stages.2.blocks.2.attn.w_msa.qkv.bias',\n",
      "    'img_backbone.stages.2.blocks.2.attn.w_msa.proj.weight',\n",
      "    'img_backbone.stages.2.blocks.2.attn.w_msa.proj.bias',\n",
      "    'img_backbone.stages.2.blocks.2.norm2.weight',\n",
      "    'img_backbone.stages.2.blocks.2.norm2.bias',\n",
      "    'img_backbone.stages.2.blocks.2.ffn.layers.0.0.weight',\n",
      "    'img_backbone.stages.2.blocks.2.ffn.layers.0.0.bias',\n",
      "    'img_backbone.stages.2.blocks.2.ffn.layers.1.weight',\n",
      "    'img_backbone.stages.2.blocks.2.ffn.layers.1.bias',\n",
      "    'img_backbone.stages.2.blocks.3.norm1.weight',\n",
      "    'img_backbone.stages.2.blocks.3.norm1.bias',\n",
      "    'img_backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table',\n",
      "    'img_backbone.stages.2.blocks.3.attn.w_msa.relative_position_index',\n",
      "    'img_backbone.stages.2.blocks.3.attn.w_msa.qkv.weight',\n",
      "    'img_backbone.stages.2.blocks.3.attn.w_msa.qkv.bias',\n",
      "    'img_backbone.stages.2.blocks.3.attn.w_msa.proj.weight',\n",
      "    'img_backbone.stages.2.blocks.3.attn.w_msa.proj.bias',\n",
      "    'img_backbone.stages.2.blocks.3.norm2.weight',\n",
      "    'img_backbone.stages.2.blocks.3.norm2.bias',\n",
      "    'img_backbone.stages.2.blocks.3.ffn.layers.0.0.weight',\n",
      "    'img_backbone.stages.2.blocks.3.ffn.layers.0.0.bias',\n",
      "    'img_backbone.stages.2.blocks.3.ffn.layers.1.weight',\n",
      "    'img_backbone.stages.2.blocks.3.ffn.layers.1.bias',\n",
      "    'img_backbone.stages.2.blocks.4.norm1.weight',\n",
      "    'img_backbone.stages.2.blocks.4.norm1.bias',\n",
      "    'img_backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table',\n",
      "    'img_backbone.stages.2.blocks.4.attn.w_msa.relative_position_index',\n",
      "    'img_backbone.stages.2.blocks.4.attn.w_msa.qkv.weight',\n",
      "    'img_backbone.stages.2.blocks.4.attn.w_msa.qkv.bias',\n",
      "    'img_backbone.stages.2.blocks.4.attn.w_msa.proj.weight',\n",
      "    'img_backbone.stages.2.blocks.4.attn.w_msa.proj.bias',\n",
      "    'img_backbone.stages.2.blocks.4.norm2.weight',\n",
      "    'img_backbone.stages.2.blocks.4.norm2.bias',\n",
      "    'img_backbone.stages.2.blocks.4.ffn.layers.0.0.weight',\n",
      "    'img_backbone.stages.2.blocks.4.ffn.layers.0.0.bias',\n",
      "    'img_backbone.stages.2.blocks.4.ffn.layers.1.weight',\n",
      "    'img_backbone.stages.2.blocks.4.ffn.layers.1.bias',\n",
      "    'img_backbone.stages.2.blocks.5.norm1.weight',\n",
      "    'img_backbone.stages.2.blocks.5.norm1.bias',\n",
      "    'img_backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table',\n",
      "    'img_backbone.stages.2.blocks.5.attn.w_msa.relative_position_index',\n",
      "    'img_backbone.stages.2.blocks.5.attn.w_msa.qkv.weight',\n",
      "    'img_backbone.stages.2.blocks.5.attn.w_msa.qkv.bias',\n",
      "    'img_backbone.stages.2.blocks.5.attn.w_msa.proj.weight',\n",
      "    'img_backbone.stages.2.blocks.5.attn.w_msa.proj.bias',\n",
      "    'img_backbone.stages.2.blocks.5.norm2.weight',\n",
      "    'img_backbone.stages.2.blocks.5.norm2.bias',\n",
      "    'img_backbone.stages.2.blocks.5.ffn.layers.0.0.weight',\n",
      "    'img_backbone.stages.2.blocks.5.ffn.layers.0.0.bias',\n",
      "    'img_backbone.stages.2.blocks.5.ffn.layers.1.weight',\n",
      "    'img_backbone.stages.2.blocks.5.ffn.layers.1.bias',\n",
      "    'img_backbone.stages.2.downsample.norm.weight',\n",
      "    'img_backbone.stages.2.downsample.norm.bias',\n",
      "    'img_backbone.stages.2.downsample.reduction.weight',\n",
      "    'img_backbone.stages.3.blocks.0.norm1.weight',\n",
      "    'img_backbone.stages.3.blocks.0.norm1.bias',\n",
      "    'img_backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table',\n",
      "    'img_backbone.stages.3.blocks.0.attn.w_msa.relative_position_index',\n",
      "    'img_backbone.stages.3.blocks.0.attn.w_msa.qkv.weight',\n",
      "    'img_backbone.stages.3.blocks.0.attn.w_msa.qkv.bias',\n",
      "    'img_backbone.stages.3.blocks.0.attn.w_msa.proj.weight',\n",
      "    'img_backbone.stages.3.blocks.0.attn.w_msa.proj.bias',\n",
      "    'img_backbone.stages.3.blocks.0.norm2.weight',\n",
      "    'img_backbone.stages.3.blocks.0.norm2.bias',\n",
      "    'img_backbone.stages.3.blocks.0.ffn.layers.0.0.weight',\n",
      "    'img_backbone.stages.3.blocks.0.ffn.layers.0.0.bias',\n",
      "    'img_backbone.stages.3.blocks.0.ffn.layers.1.weight',\n",
      "    'img_backbone.stages.3.blocks.0.ffn.layers.1.bias',\n",
      "    'img_backbone.stages.3.blocks.1.norm1.weight',\n",
      "    'img_backbone.stages.3.blocks.1.norm1.bias',\n",
      "    'img_backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table',\n",
      "    'img_backbone.stages.3.blocks.1.attn.w_msa.relative_position_index',\n",
      "    'img_backbone.stages.3.blocks.1.attn.w_msa.qkv.weight',\n",
      "    'img_backbone.stages.3.blocks.1.attn.w_msa.qkv.bias',\n",
      "    'img_backbone.stages.3.blocks.1.attn.w_msa.proj.weight',\n",
      "    'img_backbone.stages.3.blocks.1.attn.w_msa.proj.bias',\n",
      "    'img_backbone.stages.3.blocks.1.norm2.weight',\n",
      "    'img_backbone.stages.3.blocks.1.norm2.bias',\n",
      "    'img_backbone.stages.3.blocks.1.ffn.layers.0.0.weight',\n",
      "    'img_backbone.stages.3.blocks.1.ffn.layers.0.0.bias',\n",
      "    'img_backbone.stages.3.blocks.1.ffn.layers.1.weight',\n",
      "    'img_backbone.stages.3.blocks.1.ffn.layers.1.bias',\n",
      "    'img_backbone.norm2.weight', 'img_backbone.norm2.bias',\n",
      "    'img_backbone.norm3.weight', 'img_backbone.norm3.bias',\n",
      "    'img_neck.up.conv.0.weight', 'img_neck.up.conv.1.weight',\n",
      "    'img_neck.up.conv.1.bias', 'img_neck.up.conv.1.running_mean',\n",
      "    'img_neck.up.conv.1.running_var', 'img_neck.up.conv.1.num_batches_tracked',\n",
      "    'img_neck.up.conv.3.weight', 'img_neck.up.conv.4.weight',\n",
      "    'img_neck.up.conv.4.bias', 'img_neck.up.conv.4.running_mean',\n",
      "    'img_neck.up.conv.4.running_var', 'img_neck.up.conv.4.num_batches_tracked',\n",
      "    'transformer.frustum', 'transformer.depthnet.weight',\n",
      "    'transformer.depthnet.bias',\n",
      "    'temporal_model.model.0.convolution_paths.0.0.conv.weight',\n",
      "    'temporal_model.model.0.convolution_paths.0.0.norm.weight',\n",
      "    'temporal_model.model.0.convolution_paths.0.0.norm.bias',\n",
      "    'temporal_model.model.0.convolution_paths.0.0.norm.running_mean',\n",
      "    'temporal_model.model.0.convolution_paths.0.0.norm.running_var',\n",
      "    'temporal_model.model.0.convolution_paths.0.0.norm.num_batches_tracked',\n",
      "    'temporal_model.model.0.convolution_paths.0.1.conv.weight',\n",
      "    'temporal_model.model.0.convolution_paths.0.1.norm.weight',\n",
      "    'temporal_model.model.0.convolution_paths.0.1.norm.bias',\n",
      "    'temporal_model.model.0.convolution_paths.0.1.norm.running_mean',\n",
      "    'temporal_model.model.0.convolution_paths.0.1.norm.running_var',\n",
      "    'temporal_model.model.0.convolution_paths.0.1.norm.num_batches_tracked',\n",
      "    'temporal_model.model.0.convolution_paths.1.0.conv.weight',\n",
      "    'temporal_model.model.0.convolution_paths.1.0.norm.weight',\n",
      "    'temporal_model.model.0.convolution_paths.1.0.norm.bias',\n",
      "    'temporal_model.model.0.convolution_paths.1.0.norm.running_mean',\n",
      "    'temporal_model.model.0.convolution_paths.1.0.norm.running_var',\n",
      "    'temporal_model.model.0.convolution_paths.1.0.norm.num_batches_tracked',\n",
      "    'temporal_model.model.0.convolution_paths.1.1.conv.weight',\n",
      "    'temporal_model.model.0.convolution_paths.1.1.norm.weight',\n",
      "    'temporal_model.model.0.convolution_paths.1.1.norm.bias',\n",
      "    'temporal_model.model.0.convolution_paths.1.1.norm.running_mean',\n",
      "    'temporal_model.model.0.convolution_paths.1.1.norm.running_var',\n",
      "    'temporal_model.model.0.convolution_paths.1.1.norm.num_batches_tracked',\n",
      "    'temporal_model.model.0.convolution_paths.2.conv.weight',\n",
      "    'temporal_model.model.0.convolution_paths.2.norm.weight',\n",
      "    'temporal_model.model.0.convolution_paths.2.norm.bias',\n",
      "    'temporal_model.model.0.convolution_paths.2.norm.running_mean',\n",
      "    'temporal_model.model.0.convolution_paths.2.norm.running_var',\n",
      "    'temporal_model.model.0.convolution_paths.2.norm.num_batches_tracked',\n",
      "    'temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.conv.weight',\n",
      "    'temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.weight',\n",
      "    'temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.bias',\n",
      "    'temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.running_mean',\n",
      "    'temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.running_var',\n",
      "    'temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.num_batches_tracked',\n",
      "    'temporal_model.model.0.aggregation.0.conv.weight',\n",
      "    'temporal_model.model.0.aggregation.0.norm.weight',\n",
      "    'temporal_model.model.0.aggregation.0.norm.bias',\n",
      "    'temporal_model.model.0.aggregation.0.norm.running_mean',\n",
      "    'temporal_model.model.0.aggregation.0.norm.running_var',\n",
      "    'temporal_model.model.0.aggregation.0.norm.num_batches_tracked',\n",
      "    'temporal_model.model.0.projection.0.weight',\n",
      "    'temporal_model.model.0.projection.1.weight',\n",
      "    'temporal_model.model.0.projection.1.bias',\n",
      "    'temporal_model.model.0.projection.1.running_mean',\n",
      "    'temporal_model.model.0.projection.1.running_var',\n",
      "    'temporal_model.model.0.projection.1.num_batches_tracked',\n",
      "    'temporal_model.model.1.convolution_paths.0.0.conv.weight',\n",
      "    'temporal_model.model.1.convolution_paths.0.0.norm.weight',\n",
      "    'temporal_model.model.1.convolution_paths.0.0.norm.bias',\n",
      "    'temporal_model.model.1.convolution_paths.0.0.norm.running_mean',\n",
      "    'temporal_model.model.1.convolution_paths.0.0.norm.running_var',\n",
      "    'temporal_model.model.1.convolution_paths.0.0.norm.num_batches_tracked',\n",
      "    'temporal_model.model.1.convolution_paths.0.1.conv.weight',\n",
      "    'temporal_model.model.1.convolution_paths.0.1.norm.weight',\n",
      "    'temporal_model.model.1.convolution_paths.0.1.norm.bias',\n",
      "    'temporal_model.model.1.convolution_paths.0.1.norm.running_mean',\n",
      "    'temporal_model.model.1.convolution_paths.0.1.norm.running_var',\n",
      "    'temporal_model.model.1.convolution_paths.0.1.norm.num_batches_tracked',\n",
      "    'temporal_model.model.1.convolution_paths.1.0.conv.weight',\n",
      "    'temporal_model.model.1.convolution_paths.1.0.norm.weight',\n",
      "    'temporal_model.model.1.convolution_paths.1.0.norm.bias',\n",
      "    'temporal_model.model.1.convolution_paths.1.0.norm.running_mean',\n",
      "    'temporal_model.model.1.convolution_paths.1.0.norm.running_var',\n",
      "    'temporal_model.model.1.convolution_paths.1.0.norm.num_batches_tracked',\n",
      "    'temporal_model.model.1.convolution_paths.1.1.conv.weight',\n",
      "    'temporal_model.model.1.convolution_paths.1.1.norm.weight',\n",
      "    'temporal_model.model.1.convolution_paths.1.1.norm.bias',\n",
      "    'temporal_model.model.1.convolution_paths.1.1.norm.running_mean',\n",
      "    'temporal_model.model.1.convolution_paths.1.1.norm.running_var',\n",
      "    'temporal_model.model.1.convolution_paths.1.1.norm.num_batches_tracked',\n",
      "    'temporal_model.model.1.convolution_paths.2.conv.weight',\n",
      "    'temporal_model.model.1.convolution_paths.2.norm.weight',\n",
      "    'temporal_model.model.1.convolution_paths.2.norm.bias',\n",
      "    'temporal_model.model.1.convolution_paths.2.norm.running_mean',\n",
      "    'temporal_model.model.1.convolution_paths.2.norm.running_var',\n",
      "    'temporal_model.model.1.convolution_paths.2.norm.num_batches_tracked',\n",
      "    'temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.conv.weight',\n",
      "    'temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.weight',\n",
      "    'temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.bias',\n",
      "    'temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.running_mean',\n",
      "    'temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.running_var',\n",
      "    'temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.num_batches_tracked',\n",
      "    'temporal_model.model.1.aggregation.0.conv.weight',\n",
      "    'temporal_model.model.1.aggregation.0.norm.weight',\n",
      "    'temporal_model.model.1.aggregation.0.norm.bias',\n",
      "    'temporal_model.model.1.aggregation.0.norm.running_mean',\n",
      "    'temporal_model.model.1.aggregation.0.norm.running_var',\n",
      "    'temporal_model.model.1.aggregation.0.norm.num_batches_tracked']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4, compact=True)\n",
    "\n",
    "pp.pprint(list(weights[\"state_dict\"].keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.0.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.0.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.0.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.0.downsample.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.0.downsample.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.1.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.1.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.0.1.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.0.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.0.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.0.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.0.downsample.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.0.downsample.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.1.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.1.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.1.1.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.0.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.0.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.0.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.0.downsample.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.0.downsample.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.1.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.1.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.layers.2.1.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up1.conv.0.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up1.conv.1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up1.conv.1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up1.conv.1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up1.conv.1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up1.conv.1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up1.conv.3.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up1.conv.4.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up1.conv.4.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up1.conv.4.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up1.conv.4.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up1.conv.4.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up2.1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up2.2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up2.2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up2.2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up2.2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up2.2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up2.4.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.map.up2.4.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.downsample.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.downsample.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.downsample.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.downsample.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.downsample.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.downsample.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up1.conv.0.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up1.conv.3.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up2.1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up2.2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up2.2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up2.2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up2.2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up2.2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up2.4.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.3dod.up2.4.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.0.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.0.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.0.downsample.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.0.downsample.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.1.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.1.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.0.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.0.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.0.downsample.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.0.downsample.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.1.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.1.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.0.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.0.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.0.downsample.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.0.downsample.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.1.conv1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.1.conv2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up1.conv.0.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up1.conv.3.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up2.1.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up2.2.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up2.2.bias\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up2.2.running_mean\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up2.2.running_var\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up2.2.num_batches_tracked\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up2.4.weight\n",
      "passed pts_bbox_head.taskfeat_encoders.motion.up2.4.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.shared_conv.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.shared_conv.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.shared_conv.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.shared_conv.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.shared_conv.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.shared_conv.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.reg.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.reg.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.height.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.height.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.dim.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.dim.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.rot.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.rot.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.vel.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.vel.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.reg.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.reg.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.height.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.height.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.dim.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.dim.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.rot.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.rot.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.vel.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.vel.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.reg.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.reg.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.height.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.height.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.dim.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.dim.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.rot.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.rot.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.vel.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.vel.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.reg.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.reg.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.height.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.height.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.dim.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.dim.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.rot.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.rot.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.vel.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.vel.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.reg.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.reg.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.height.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.height.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.dim.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.dim.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.rot.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.rot.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.vel.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.vel.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.reg.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.reg.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.height.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.height.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.dim.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.dim.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.rot.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.rot.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.vel.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.vel.1.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.conv.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.bias\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.running_mean\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.running_var\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.1.weight\n",
      "passed pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.1.bias\n",
      "passed pts_bbox_head.task_decoders.map.task_heads.semantic_seg.0.weight\n",
      "passed pts_bbox_head.task_decoders.map.task_heads.semantic_seg.1.weight\n",
      "passed pts_bbox_head.task_decoders.map.task_heads.semantic_seg.1.bias\n",
      "passed pts_bbox_head.task_decoders.map.task_heads.semantic_seg.1.running_mean\n",
      "passed pts_bbox_head.task_decoders.map.task_heads.semantic_seg.1.running_var\n",
      "passed pts_bbox_head.task_decoders.map.task_heads.semantic_seg.1.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.map.task_heads.semantic_seg.3.weight\n",
      "passed pts_bbox_head.task_decoders.map.task_heads.semantic_seg.3.bias\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.segmentation.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.weight\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.bias\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.segmentation.3.weight\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.segmentation.3.bias\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_center.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.weight\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.bias\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_center.3.weight\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_center.3.bias\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_offset.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.weight\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.bias\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_offset.3.weight\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_offset.3.bias\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_flow.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.weight\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.bias\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_flow.3.weight\n",
      "passed pts_bbox_head.task_decoders.motion.task_heads.instance_flow.3.bias\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv_down_project.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.bias\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.bias\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv_up_project.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.bias\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.conv_skip_proj.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.bias\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv_down_project.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.bias\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.bias\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv_up_project.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.bias\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.conv_skip_proj.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.bias\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.last_conv.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.present_distribution.last_conv.0.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv_down_project.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv_up_project.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.conv_skip_proj.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv_down_project.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv_up_project.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.conv_skip_proj.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.last_conv.0.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_distribution.last_conv.0.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.conv.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.offset_pred.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.offset_pred.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_update.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_update.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_reset.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_reset.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.conv.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.num_batches_tracked\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.conv.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.weight\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.bias\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.running_mean\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.running_var\n",
      "passed pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.num_batches_tracked\n",
      "took img_backbone.patch_embed.projection.weight\n",
      "took img_backbone.patch_embed.projection.bias\n",
      "took img_backbone.patch_embed.norm.weight\n",
      "took img_backbone.patch_embed.norm.bias\n",
      "took img_backbone.stages.0.blocks.0.norm1.weight\n",
      "took img_backbone.stages.0.blocks.0.norm1.bias\n",
      "took img_backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "took img_backbone.stages.0.blocks.0.attn.w_msa.relative_position_index\n",
      "took img_backbone.stages.0.blocks.0.attn.w_msa.qkv.weight\n",
      "took img_backbone.stages.0.blocks.0.attn.w_msa.qkv.bias\n",
      "took img_backbone.stages.0.blocks.0.attn.w_msa.proj.weight\n",
      "took img_backbone.stages.0.blocks.0.attn.w_msa.proj.bias\n",
      "took img_backbone.stages.0.blocks.0.norm2.weight\n",
      "took img_backbone.stages.0.blocks.0.norm2.bias\n",
      "took img_backbone.stages.0.blocks.0.ffn.layers.0.0.weight\n",
      "took img_backbone.stages.0.blocks.0.ffn.layers.0.0.bias\n",
      "took img_backbone.stages.0.blocks.0.ffn.layers.1.weight\n",
      "took img_backbone.stages.0.blocks.0.ffn.layers.1.bias\n",
      "took img_backbone.stages.0.blocks.1.norm1.weight\n",
      "took img_backbone.stages.0.blocks.1.norm1.bias\n",
      "took img_backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "took img_backbone.stages.0.blocks.1.attn.w_msa.relative_position_index\n",
      "took img_backbone.stages.0.blocks.1.attn.w_msa.qkv.weight\n",
      "took img_backbone.stages.0.blocks.1.attn.w_msa.qkv.bias\n",
      "took img_backbone.stages.0.blocks.1.attn.w_msa.proj.weight\n",
      "took img_backbone.stages.0.blocks.1.attn.w_msa.proj.bias\n",
      "took img_backbone.stages.0.blocks.1.norm2.weight\n",
      "took img_backbone.stages.0.blocks.1.norm2.bias\n",
      "took img_backbone.stages.0.blocks.1.ffn.layers.0.0.weight\n",
      "took img_backbone.stages.0.blocks.1.ffn.layers.0.0.bias\n",
      "took img_backbone.stages.0.blocks.1.ffn.layers.1.weight\n",
      "took img_backbone.stages.0.blocks.1.ffn.layers.1.bias\n",
      "took img_backbone.stages.0.downsample.norm.weight\n",
      "took img_backbone.stages.0.downsample.norm.bias\n",
      "took img_backbone.stages.0.downsample.reduction.weight\n",
      "took img_backbone.stages.1.blocks.0.norm1.weight\n",
      "took img_backbone.stages.1.blocks.0.norm1.bias\n",
      "took img_backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "took img_backbone.stages.1.blocks.0.attn.w_msa.relative_position_index\n",
      "took img_backbone.stages.1.blocks.0.attn.w_msa.qkv.weight\n",
      "took img_backbone.stages.1.blocks.0.attn.w_msa.qkv.bias\n",
      "took img_backbone.stages.1.blocks.0.attn.w_msa.proj.weight\n",
      "took img_backbone.stages.1.blocks.0.attn.w_msa.proj.bias\n",
      "took img_backbone.stages.1.blocks.0.norm2.weight\n",
      "took img_backbone.stages.1.blocks.0.norm2.bias\n",
      "took img_backbone.stages.1.blocks.0.ffn.layers.0.0.weight\n",
      "took img_backbone.stages.1.blocks.0.ffn.layers.0.0.bias\n",
      "took img_backbone.stages.1.blocks.0.ffn.layers.1.weight\n",
      "took img_backbone.stages.1.blocks.0.ffn.layers.1.bias\n",
      "took img_backbone.stages.1.blocks.1.norm1.weight\n",
      "took img_backbone.stages.1.blocks.1.norm1.bias\n",
      "took img_backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "took img_backbone.stages.1.blocks.1.attn.w_msa.relative_position_index\n",
      "took img_backbone.stages.1.blocks.1.attn.w_msa.qkv.weight\n",
      "took img_backbone.stages.1.blocks.1.attn.w_msa.qkv.bias\n",
      "took img_backbone.stages.1.blocks.1.attn.w_msa.proj.weight\n",
      "took img_backbone.stages.1.blocks.1.attn.w_msa.proj.bias\n",
      "took img_backbone.stages.1.blocks.1.norm2.weight\n",
      "took img_backbone.stages.1.blocks.1.norm2.bias\n",
      "took img_backbone.stages.1.blocks.1.ffn.layers.0.0.weight\n",
      "took img_backbone.stages.1.blocks.1.ffn.layers.0.0.bias\n",
      "took img_backbone.stages.1.blocks.1.ffn.layers.1.weight\n",
      "took img_backbone.stages.1.blocks.1.ffn.layers.1.bias\n",
      "took img_backbone.stages.1.downsample.norm.weight\n",
      "took img_backbone.stages.1.downsample.norm.bias\n",
      "took img_backbone.stages.1.downsample.reduction.weight\n",
      "took img_backbone.stages.2.blocks.0.norm1.weight\n",
      "took img_backbone.stages.2.blocks.0.norm1.bias\n",
      "took img_backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "took img_backbone.stages.2.blocks.0.attn.w_msa.relative_position_index\n",
      "took img_backbone.stages.2.blocks.0.attn.w_msa.qkv.weight\n",
      "took img_backbone.stages.2.blocks.0.attn.w_msa.qkv.bias\n",
      "took img_backbone.stages.2.blocks.0.attn.w_msa.proj.weight\n",
      "took img_backbone.stages.2.blocks.0.attn.w_msa.proj.bias\n",
      "took img_backbone.stages.2.blocks.0.norm2.weight\n",
      "took img_backbone.stages.2.blocks.0.norm2.bias\n",
      "took img_backbone.stages.2.blocks.0.ffn.layers.0.0.weight\n",
      "took img_backbone.stages.2.blocks.0.ffn.layers.0.0.bias\n",
      "took img_backbone.stages.2.blocks.0.ffn.layers.1.weight\n",
      "took img_backbone.stages.2.blocks.0.ffn.layers.1.bias\n",
      "took img_backbone.stages.2.blocks.1.norm1.weight\n",
      "took img_backbone.stages.2.blocks.1.norm1.bias\n",
      "took img_backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "took img_backbone.stages.2.blocks.1.attn.w_msa.relative_position_index\n",
      "took img_backbone.stages.2.blocks.1.attn.w_msa.qkv.weight\n",
      "took img_backbone.stages.2.blocks.1.attn.w_msa.qkv.bias\n",
      "took img_backbone.stages.2.blocks.1.attn.w_msa.proj.weight\n",
      "took img_backbone.stages.2.blocks.1.attn.w_msa.proj.bias\n",
      "took img_backbone.stages.2.blocks.1.norm2.weight\n",
      "took img_backbone.stages.2.blocks.1.norm2.bias\n",
      "took img_backbone.stages.2.blocks.1.ffn.layers.0.0.weight\n",
      "took img_backbone.stages.2.blocks.1.ffn.layers.0.0.bias\n",
      "took img_backbone.stages.2.blocks.1.ffn.layers.1.weight\n",
      "took img_backbone.stages.2.blocks.1.ffn.layers.1.bias\n",
      "took img_backbone.stages.2.blocks.2.norm1.weight\n",
      "took img_backbone.stages.2.blocks.2.norm1.bias\n",
      "took img_backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table\n",
      "took img_backbone.stages.2.blocks.2.attn.w_msa.relative_position_index\n",
      "took img_backbone.stages.2.blocks.2.attn.w_msa.qkv.weight\n",
      "took img_backbone.stages.2.blocks.2.attn.w_msa.qkv.bias\n",
      "took img_backbone.stages.2.blocks.2.attn.w_msa.proj.weight\n",
      "took img_backbone.stages.2.blocks.2.attn.w_msa.proj.bias\n",
      "took img_backbone.stages.2.blocks.2.norm2.weight\n",
      "took img_backbone.stages.2.blocks.2.norm2.bias\n",
      "took img_backbone.stages.2.blocks.2.ffn.layers.0.0.weight\n",
      "took img_backbone.stages.2.blocks.2.ffn.layers.0.0.bias\n",
      "took img_backbone.stages.2.blocks.2.ffn.layers.1.weight\n",
      "took img_backbone.stages.2.blocks.2.ffn.layers.1.bias\n",
      "took img_backbone.stages.2.blocks.3.norm1.weight\n",
      "took img_backbone.stages.2.blocks.3.norm1.bias\n",
      "took img_backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table\n",
      "took img_backbone.stages.2.blocks.3.attn.w_msa.relative_position_index\n",
      "took img_backbone.stages.2.blocks.3.attn.w_msa.qkv.weight\n",
      "took img_backbone.stages.2.blocks.3.attn.w_msa.qkv.bias\n",
      "took img_backbone.stages.2.blocks.3.attn.w_msa.proj.weight\n",
      "took img_backbone.stages.2.blocks.3.attn.w_msa.proj.bias\n",
      "took img_backbone.stages.2.blocks.3.norm2.weight\n",
      "took img_backbone.stages.2.blocks.3.norm2.bias\n",
      "took img_backbone.stages.2.blocks.3.ffn.layers.0.0.weight\n",
      "took img_backbone.stages.2.blocks.3.ffn.layers.0.0.bias\n",
      "took img_backbone.stages.2.blocks.3.ffn.layers.1.weight\n",
      "took img_backbone.stages.2.blocks.3.ffn.layers.1.bias\n",
      "took img_backbone.stages.2.blocks.4.norm1.weight\n",
      "took img_backbone.stages.2.blocks.4.norm1.bias\n",
      "took img_backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table\n",
      "took img_backbone.stages.2.blocks.4.attn.w_msa.relative_position_index\n",
      "took img_backbone.stages.2.blocks.4.attn.w_msa.qkv.weight\n",
      "took img_backbone.stages.2.blocks.4.attn.w_msa.qkv.bias\n",
      "took img_backbone.stages.2.blocks.4.attn.w_msa.proj.weight\n",
      "took img_backbone.stages.2.blocks.4.attn.w_msa.proj.bias\n",
      "took img_backbone.stages.2.blocks.4.norm2.weight\n",
      "took img_backbone.stages.2.blocks.4.norm2.bias\n",
      "took img_backbone.stages.2.blocks.4.ffn.layers.0.0.weight\n",
      "took img_backbone.stages.2.blocks.4.ffn.layers.0.0.bias\n",
      "took img_backbone.stages.2.blocks.4.ffn.layers.1.weight\n",
      "took img_backbone.stages.2.blocks.4.ffn.layers.1.bias\n",
      "took img_backbone.stages.2.blocks.5.norm1.weight\n",
      "took img_backbone.stages.2.blocks.5.norm1.bias\n",
      "took img_backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table\n",
      "took img_backbone.stages.2.blocks.5.attn.w_msa.relative_position_index\n",
      "took img_backbone.stages.2.blocks.5.attn.w_msa.qkv.weight\n",
      "took img_backbone.stages.2.blocks.5.attn.w_msa.qkv.bias\n",
      "took img_backbone.stages.2.blocks.5.attn.w_msa.proj.weight\n",
      "took img_backbone.stages.2.blocks.5.attn.w_msa.proj.bias\n",
      "took img_backbone.stages.2.blocks.5.norm2.weight\n",
      "took img_backbone.stages.2.blocks.5.norm2.bias\n",
      "took img_backbone.stages.2.blocks.5.ffn.layers.0.0.weight\n",
      "took img_backbone.stages.2.blocks.5.ffn.layers.0.0.bias\n",
      "took img_backbone.stages.2.blocks.5.ffn.layers.1.weight\n",
      "took img_backbone.stages.2.blocks.5.ffn.layers.1.bias\n",
      "took img_backbone.stages.2.downsample.norm.weight\n",
      "took img_backbone.stages.2.downsample.norm.bias\n",
      "took img_backbone.stages.2.downsample.reduction.weight\n",
      "took img_backbone.stages.3.blocks.0.norm1.weight\n",
      "took img_backbone.stages.3.blocks.0.norm1.bias\n",
      "took img_backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "took img_backbone.stages.3.blocks.0.attn.w_msa.relative_position_index\n",
      "took img_backbone.stages.3.blocks.0.attn.w_msa.qkv.weight\n",
      "took img_backbone.stages.3.blocks.0.attn.w_msa.qkv.bias\n",
      "took img_backbone.stages.3.blocks.0.attn.w_msa.proj.weight\n",
      "took img_backbone.stages.3.blocks.0.attn.w_msa.proj.bias\n",
      "took img_backbone.stages.3.blocks.0.norm2.weight\n",
      "took img_backbone.stages.3.blocks.0.norm2.bias\n",
      "took img_backbone.stages.3.blocks.0.ffn.layers.0.0.weight\n",
      "took img_backbone.stages.3.blocks.0.ffn.layers.0.0.bias\n",
      "took img_backbone.stages.3.blocks.0.ffn.layers.1.weight\n",
      "took img_backbone.stages.3.blocks.0.ffn.layers.1.bias\n",
      "took img_backbone.stages.3.blocks.1.norm1.weight\n",
      "took img_backbone.stages.3.blocks.1.norm1.bias\n",
      "took img_backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "took img_backbone.stages.3.blocks.1.attn.w_msa.relative_position_index\n",
      "took img_backbone.stages.3.blocks.1.attn.w_msa.qkv.weight\n",
      "took img_backbone.stages.3.blocks.1.attn.w_msa.qkv.bias\n",
      "took img_backbone.stages.3.blocks.1.attn.w_msa.proj.weight\n",
      "took img_backbone.stages.3.blocks.1.attn.w_msa.proj.bias\n",
      "took img_backbone.stages.3.blocks.1.norm2.weight\n",
      "took img_backbone.stages.3.blocks.1.norm2.bias\n",
      "took img_backbone.stages.3.blocks.1.ffn.layers.0.0.weight\n",
      "took img_backbone.stages.3.blocks.1.ffn.layers.0.0.bias\n",
      "took img_backbone.stages.3.blocks.1.ffn.layers.1.weight\n",
      "took img_backbone.stages.3.blocks.1.ffn.layers.1.bias\n",
      "took img_backbone.norm2.weight\n",
      "took img_backbone.norm2.bias\n",
      "took img_backbone.norm3.weight\n",
      "took img_backbone.norm3.bias\n",
      "took img_neck.up.conv.0.weight\n",
      "took img_neck.up.conv.1.weight\n",
      "took img_neck.up.conv.1.bias\n",
      "took img_neck.up.conv.1.running_mean\n",
      "took img_neck.up.conv.1.running_var\n",
      "took img_neck.up.conv.1.num_batches_tracked\n",
      "took img_neck.up.conv.3.weight\n",
      "took img_neck.up.conv.4.weight\n",
      "took img_neck.up.conv.4.bias\n",
      "took img_neck.up.conv.4.running_mean\n",
      "took img_neck.up.conv.4.running_var\n",
      "took img_neck.up.conv.4.num_batches_tracked\n",
      "took transformer.frustum\n",
      "took transformer.depthnet.weight\n",
      "took transformer.depthnet.bias\n",
      "took temporal_model.model.0.convolution_paths.0.0.conv.weight\n",
      "took temporal_model.model.0.convolution_paths.0.0.norm.weight\n",
      "took temporal_model.model.0.convolution_paths.0.0.norm.bias\n",
      "took temporal_model.model.0.convolution_paths.0.0.norm.running_mean\n",
      "took temporal_model.model.0.convolution_paths.0.0.norm.running_var\n",
      "took temporal_model.model.0.convolution_paths.0.0.norm.num_batches_tracked\n",
      "took temporal_model.model.0.convolution_paths.0.1.conv.weight\n",
      "took temporal_model.model.0.convolution_paths.0.1.norm.weight\n",
      "took temporal_model.model.0.convolution_paths.0.1.norm.bias\n",
      "took temporal_model.model.0.convolution_paths.0.1.norm.running_mean\n",
      "took temporal_model.model.0.convolution_paths.0.1.norm.running_var\n",
      "took temporal_model.model.0.convolution_paths.0.1.norm.num_batches_tracked\n",
      "took temporal_model.model.0.convolution_paths.1.0.conv.weight\n",
      "took temporal_model.model.0.convolution_paths.1.0.norm.weight\n",
      "took temporal_model.model.0.convolution_paths.1.0.norm.bias\n",
      "took temporal_model.model.0.convolution_paths.1.0.norm.running_mean\n",
      "took temporal_model.model.0.convolution_paths.1.0.norm.running_var\n",
      "took temporal_model.model.0.convolution_paths.1.0.norm.num_batches_tracked\n",
      "took temporal_model.model.0.convolution_paths.1.1.conv.weight\n",
      "took temporal_model.model.0.convolution_paths.1.1.norm.weight\n",
      "took temporal_model.model.0.convolution_paths.1.1.norm.bias\n",
      "took temporal_model.model.0.convolution_paths.1.1.norm.running_mean\n",
      "took temporal_model.model.0.convolution_paths.1.1.norm.running_var\n",
      "took temporal_model.model.0.convolution_paths.1.1.norm.num_batches_tracked\n",
      "took temporal_model.model.0.convolution_paths.2.conv.weight\n",
      "took temporal_model.model.0.convolution_paths.2.norm.weight\n",
      "took temporal_model.model.0.convolution_paths.2.norm.bias\n",
      "took temporal_model.model.0.convolution_paths.2.norm.running_mean\n",
      "took temporal_model.model.0.convolution_paths.2.norm.running_var\n",
      "took temporal_model.model.0.convolution_paths.2.norm.num_batches_tracked\n",
      "took temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.conv.weight\n",
      "took temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.weight\n",
      "took temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.bias\n",
      "took temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.running_mean\n",
      "took temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.running_var\n",
      "took temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.num_batches_tracked\n",
      "took temporal_model.model.0.aggregation.0.conv.weight\n",
      "took temporal_model.model.0.aggregation.0.norm.weight\n",
      "took temporal_model.model.0.aggregation.0.norm.bias\n",
      "took temporal_model.model.0.aggregation.0.norm.running_mean\n",
      "took temporal_model.model.0.aggregation.0.norm.running_var\n",
      "took temporal_model.model.0.aggregation.0.norm.num_batches_tracked\n",
      "took temporal_model.model.0.projection.0.weight\n",
      "took temporal_model.model.0.projection.1.weight\n",
      "took temporal_model.model.0.projection.1.bias\n",
      "took temporal_model.model.0.projection.1.running_mean\n",
      "took temporal_model.model.0.projection.1.running_var\n",
      "took temporal_model.model.0.projection.1.num_batches_tracked\n",
      "took temporal_model.model.1.convolution_paths.0.0.conv.weight\n",
      "took temporal_model.model.1.convolution_paths.0.0.norm.weight\n",
      "took temporal_model.model.1.convolution_paths.0.0.norm.bias\n",
      "took temporal_model.model.1.convolution_paths.0.0.norm.running_mean\n",
      "took temporal_model.model.1.convolution_paths.0.0.norm.running_var\n",
      "took temporal_model.model.1.convolution_paths.0.0.norm.num_batches_tracked\n",
      "took temporal_model.model.1.convolution_paths.0.1.conv.weight\n",
      "took temporal_model.model.1.convolution_paths.0.1.norm.weight\n",
      "took temporal_model.model.1.convolution_paths.0.1.norm.bias\n",
      "took temporal_model.model.1.convolution_paths.0.1.norm.running_mean\n",
      "took temporal_model.model.1.convolution_paths.0.1.norm.running_var\n",
      "took temporal_model.model.1.convolution_paths.0.1.norm.num_batches_tracked\n",
      "took temporal_model.model.1.convolution_paths.1.0.conv.weight\n",
      "took temporal_model.model.1.convolution_paths.1.0.norm.weight\n",
      "took temporal_model.model.1.convolution_paths.1.0.norm.bias\n",
      "took temporal_model.model.1.convolution_paths.1.0.norm.running_mean\n",
      "took temporal_model.model.1.convolution_paths.1.0.norm.running_var\n",
      "took temporal_model.model.1.convolution_paths.1.0.norm.num_batches_tracked\n",
      "took temporal_model.model.1.convolution_paths.1.1.conv.weight\n",
      "took temporal_model.model.1.convolution_paths.1.1.norm.weight\n",
      "took temporal_model.model.1.convolution_paths.1.1.norm.bias\n",
      "took temporal_model.model.1.convolution_paths.1.1.norm.running_mean\n",
      "took temporal_model.model.1.convolution_paths.1.1.norm.running_var\n",
      "took temporal_model.model.1.convolution_paths.1.1.norm.num_batches_tracked\n",
      "took temporal_model.model.1.convolution_paths.2.conv.weight\n",
      "took temporal_model.model.1.convolution_paths.2.norm.weight\n",
      "took temporal_model.model.1.convolution_paths.2.norm.bias\n",
      "took temporal_model.model.1.convolution_paths.2.norm.running_mean\n",
      "took temporal_model.model.1.convolution_paths.2.norm.running_var\n",
      "took temporal_model.model.1.convolution_paths.2.norm.num_batches_tracked\n",
      "took temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.conv.weight\n",
      "took temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.weight\n",
      "took temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.bias\n",
      "took temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.running_mean\n",
      "took temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.running_var\n",
      "took temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.num_batches_tracked\n",
      "took temporal_model.model.1.aggregation.0.conv.weight\n",
      "took temporal_model.model.1.aggregation.0.norm.weight\n",
      "took temporal_model.model.1.aggregation.0.norm.bias\n",
      "took temporal_model.model.1.aggregation.0.norm.running_mean\n",
      "took temporal_model.model.1.aggregation.0.norm.running_var\n",
      "took temporal_model.model.1.aggregation.0.norm.num_batches_tracked\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "relevant_weights = [\"transformer\",\"img_neck\", \"temporal_model\", \"img_backbone\"]\n",
    "\n",
    "new_weights = {}\n",
    "for key in weights[\"state_dict\"]:\n",
    "    if key.startswith(tuple(relevant_weights)):\n",
    "        print(\"took\", key)\n",
    "        new_weights[key] = weights[\"state_dict\"][key].clone()\n",
    "    else:\n",
    "        print(\"passed\",key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weights_tiny = OrderedDict(new_weights)\n",
    "torch.save(weights_tiny, \"weights/clean_weights_tiny.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.downsample.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.downsample.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.downsample.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.downsample.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.downsample.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.downsample.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.0.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.3.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.4.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.4.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.downsample.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.downsample.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.downsample.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.downsample.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.downsample.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.downsample.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.0.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.3.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.4.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.4.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.shared_conv.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.shared_conv.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.shared_conv.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.shared_conv.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.shared_conv.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.shared_conv.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.1.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.3.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.3.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.3.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.3.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.3.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.3.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.3.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.3.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv_down_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv_up_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.conv_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv_down_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv_up_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.conv_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.last_conv.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.last_conv.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv_down_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv_up_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.conv_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv_down_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv_up_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.conv_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.last_conv.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.last_conv.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_pred.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_pred.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_update.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_update.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_reset.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_reset.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.num_batches_tracked\n",
      "Loaded weights for img_backbone.patch_embed.projection.weight, and required grad: False\n",
      "Loaded weights for img_backbone.patch_embed.projection.bias, and required grad: False\n",
      "Loaded weights for img_backbone.patch_embed.norm.weight, and required grad: False\n",
      "Loaded weights for img_backbone.patch_embed.norm.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.downsample.norm.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.downsample.norm.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.downsample.reduction.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.downsample.norm.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.downsample.norm.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.downsample.reduction.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.downsample.norm.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.downsample.norm.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.downsample.reduction.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.norm3.weight, and required grad: False\n",
      "Loaded weights for img_backbone.norm3.bias, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.0.weight, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.1.weight, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.1.bias, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.1.running_mean, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.1.running_var, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.1.num_batches_tracked, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.3.weight, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.4.weight, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.4.bias, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.4.running_mean, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.4.running_var, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.4.num_batches_tracked, and required grad: False\n",
      "Loaded weights for transformer.frustum, and required grad: False\n",
      "Loaded weights for transformer.depthnet.weight, and required grad: False\n",
      "Loaded weights for transformer.depthnet.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.0.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.0.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.0.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.0.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.0.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.0.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.1.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.1.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.1.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.1.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.1.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.1.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.0.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.0.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.0.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.0.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.0.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.0.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.1.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.1.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.1.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.1.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.1.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.1.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.2.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.2.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.2.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.2.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.2.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.2.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.aggregation.0.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.aggregation.0.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.aggregation.0.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.aggregation.0.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.aggregation.0.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.aggregation.0.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.projection.0.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.projection.1.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.projection.1.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.projection.1.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.projection.1.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.projection.1.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.0.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.0.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.0.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.0.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.0.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.0.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.1.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.1.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.1.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.1.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.1.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.1.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.0.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.0.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.0.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.0.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.0.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.0.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.1.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.1.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.1.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.1.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.1.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.1.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.2.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.2.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.2.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.2.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.2.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.2.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.aggregation.0.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.aggregation.0.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.aggregation.0.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.aggregation.0.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.aggregation.0.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.aggregation.0.norm.num_batches_tracked, and required grad: False\n",
      "ignored temporal_model.model.2.convolution_paths.0.0.conv.weight\n",
      "ignored temporal_model.model.2.convolution_paths.0.0.norm.weight\n",
      "ignored temporal_model.model.2.convolution_paths.0.0.norm.bias\n",
      "ignored temporal_model.model.2.convolution_paths.0.0.norm.running_mean\n",
      "ignored temporal_model.model.2.convolution_paths.0.0.norm.running_var\n",
      "ignored temporal_model.model.2.convolution_paths.0.0.norm.num_batches_tracked\n",
      "ignored temporal_model.model.2.convolution_paths.0.1.conv.weight\n",
      "ignored temporal_model.model.2.convolution_paths.0.1.norm.weight\n",
      "ignored temporal_model.model.2.convolution_paths.0.1.norm.bias\n",
      "ignored temporal_model.model.2.convolution_paths.0.1.norm.running_mean\n",
      "ignored temporal_model.model.2.convolution_paths.0.1.norm.running_var\n",
      "ignored temporal_model.model.2.convolution_paths.0.1.norm.num_batches_tracked\n",
      "ignored temporal_model.model.2.convolution_paths.1.0.conv.weight\n",
      "ignored temporal_model.model.2.convolution_paths.1.0.norm.weight\n",
      "ignored temporal_model.model.2.convolution_paths.1.0.norm.bias\n",
      "ignored temporal_model.model.2.convolution_paths.1.0.norm.running_mean\n",
      "ignored temporal_model.model.2.convolution_paths.1.0.norm.running_var\n",
      "ignored temporal_model.model.2.convolution_paths.1.0.norm.num_batches_tracked\n",
      "ignored temporal_model.model.2.convolution_paths.1.1.conv.weight\n",
      "ignored temporal_model.model.2.convolution_paths.1.1.norm.weight\n",
      "ignored temporal_model.model.2.convolution_paths.1.1.norm.bias\n",
      "ignored temporal_model.model.2.convolution_paths.1.1.norm.running_mean\n",
      "ignored temporal_model.model.2.convolution_paths.1.1.norm.running_var\n",
      "ignored temporal_model.model.2.convolution_paths.1.1.norm.num_batches_tracked\n",
      "ignored temporal_model.model.2.convolution_paths.2.conv.weight\n",
      "ignored temporal_model.model.2.convolution_paths.2.norm.weight\n",
      "ignored temporal_model.model.2.convolution_paths.2.norm.bias\n",
      "ignored temporal_model.model.2.convolution_paths.2.norm.running_mean\n",
      "ignored temporal_model.model.2.convolution_paths.2.norm.running_var\n",
      "ignored temporal_model.model.2.convolution_paths.2.norm.num_batches_tracked\n",
      "ignored temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.conv.weight\n",
      "ignored temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.norm.weight\n",
      "ignored temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.norm.bias\n",
      "ignored temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.norm.running_mean\n",
      "ignored temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.norm.running_var\n",
      "ignored temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.norm.num_batches_tracked\n",
      "ignored temporal_model.model.2.aggregation.0.conv.weight\n",
      "ignored temporal_model.model.2.aggregation.0.norm.weight\n",
      "ignored temporal_model.model.2.aggregation.0.norm.bias\n",
      "ignored temporal_model.model.2.aggregation.0.norm.running_mean\n",
      "ignored temporal_model.model.2.aggregation.0.norm.running_var\n",
      "ignored temporal_model.model.2.aggregation.0.norm.num_batches_tracked\n"
     ]
    }
   ],
   "source": [
    "search_weights = tuple(weights_tiny.keys())\n",
    "\n",
    "for k,v in model.state_dict().items():\n",
    "    if k in search_weights:\n",
    "        v = weights_tiny[k].clone()\n",
    "        v.requires_grad = False\n",
    "        print(\n",
    "            f\"Loaded weights for {k}, and required grad: {v.requires_grad}\")\n",
    "    else:\n",
    "        print(f\"ignored {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = model.state_dict()\n",
    "\n",
    "sum(model_dict[\"img_backbone.stages.0.blocks.0.norm1.weight\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.downsample.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.downsample.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.downsample.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.downsample.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.downsample.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.downsample.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.0.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.3.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.4.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.3dod.up2.4.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.downsample.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.0.downsample.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.downsample.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.0.downsample.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.downsample.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.0.downsample.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.conv1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.conv2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.0.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.3.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.1.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.2.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.2.bias\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.2.running_mean\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.2.running_var\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.2.num_batches_tracked\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.4.weight\n",
      "ignored pts_bbox_head.taskfeat_encoders.motion.up2.4.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.shared_conv.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.shared_conv.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.shared_conv.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.shared_conv.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.shared_conv.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.shared_conv.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.reg.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.height.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.dim.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.rot.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.vel.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.reg.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.height.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.dim.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.rot.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.vel.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.reg.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.height.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.dim.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.rot.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.vel.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.reg.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.height.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.dim.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.rot.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.vel.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.reg.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.height.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.dim.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.rot.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.vel.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.reg.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.height.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.dim.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.rot.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.vel.1.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.bias\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.running_mean\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.running_var\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.1.weight\n",
      "ignored pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.1.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.3.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.segmentation.3.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.3.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_center.3.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.3.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_offset.3.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.3.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.task_heads.instance_flow.3.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv_down_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv_up_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.conv_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv_down_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv_up_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.conv_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.last_conv.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.present_distribution.last_conv.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv_down_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv_up_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.conv_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv_down_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv_up_project.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.conv_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.last_conv.0.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_distribution.last_conv.0.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_pred.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.offset_pred.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_update.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_update.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_reset.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_reset.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.num_batches_tracked\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.conv.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.weight\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.bias\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.running_mean\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.running_var\n",
      "ignored pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.num_batches_tracked\n",
      "Loaded weights for img_backbone.patch_embed.projection.weight, and required grad: False\n",
      "Loaded weights for img_backbone.patch_embed.projection.bias, and required grad: False\n",
      "Loaded weights for img_backbone.patch_embed.norm.weight, and required grad: False\n",
      "Loaded weights for img_backbone.patch_embed.norm.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.0.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.blocks.1.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.downsample.norm.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.downsample.norm.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.0.downsample.reduction.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.0.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.blocks.1.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.downsample.norm.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.downsample.norm.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.1.downsample.reduction.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.0.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.1.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.2.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.3.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.4.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.blocks.5.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.downsample.norm.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.downsample.norm.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.2.downsample.reduction.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.0.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.norm1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.norm1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.attn.w_msa.relative_position_index, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.attn.w_msa.qkv.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.attn.w_msa.qkv.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.attn.w_msa.proj.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.attn.w_msa.proj.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.ffn.layers.0.0.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.ffn.layers.0.0.bias, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.ffn.layers.1.weight, and required grad: False\n",
      "Loaded weights for img_backbone.stages.3.blocks.1.ffn.layers.1.bias, and required grad: False\n",
      "Loaded weights for img_backbone.norm2.weight, and required grad: False\n",
      "Loaded weights for img_backbone.norm2.bias, and required grad: False\n",
      "Loaded weights for img_backbone.norm3.weight, and required grad: False\n",
      "Loaded weights for img_backbone.norm3.bias, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.0.weight, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.1.weight, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.1.bias, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.1.running_mean, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.1.running_var, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.1.num_batches_tracked, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.3.weight, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.4.weight, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.4.bias, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.4.running_mean, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.4.running_var, and required grad: False\n",
      "Loaded weights for img_neck.up.conv.4.num_batches_tracked, and required grad: False\n",
      "Loaded weights for transformer.frustum, and required grad: False\n",
      "Loaded weights for transformer.depthnet.weight, and required grad: False\n",
      "Loaded weights for transformer.depthnet.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.0.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.0.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.0.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.0.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.0.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.0.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.1.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.1.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.1.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.1.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.1.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.0.1.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.0.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.0.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.0.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.0.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.0.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.0.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.1.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.1.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.1.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.1.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.1.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.1.1.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.2.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.2.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.2.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.2.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.2.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.convolution_paths.2.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.aggregation.0.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.aggregation.0.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.aggregation.0.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.aggregation.0.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.aggregation.0.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.aggregation.0.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.projection.0.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.projection.1.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.projection.1.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.projection.1.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.projection.1.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.0.projection.1.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.0.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.0.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.0.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.0.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.0.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.0.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.1.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.1.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.1.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.1.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.1.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.0.1.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.0.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.0.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.0.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.0.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.0.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.0.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.1.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.1.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.1.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.1.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.1.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.1.1.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.2.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.2.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.2.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.2.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.2.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.convolution_paths.2.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.num_batches_tracked, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.aggregation.0.conv.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.aggregation.0.norm.weight, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.aggregation.0.norm.bias, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.aggregation.0.norm.running_mean, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.aggregation.0.norm.running_var, and required grad: False\n",
      "Loaded weights for temporal_model.model.1.aggregation.0.norm.num_batches_tracked, and required grad: False\n",
      "ignored temporal_model.model.2.convolution_paths.0.0.conv.weight\n",
      "ignored temporal_model.model.2.convolution_paths.0.0.norm.weight\n",
      "ignored temporal_model.model.2.convolution_paths.0.0.norm.bias\n",
      "ignored temporal_model.model.2.convolution_paths.0.0.norm.running_mean\n",
      "ignored temporal_model.model.2.convolution_paths.0.0.norm.running_var\n",
      "ignored temporal_model.model.2.convolution_paths.0.0.norm.num_batches_tracked\n",
      "ignored temporal_model.model.2.convolution_paths.0.1.conv.weight\n",
      "ignored temporal_model.model.2.convolution_paths.0.1.norm.weight\n",
      "ignored temporal_model.model.2.convolution_paths.0.1.norm.bias\n",
      "ignored temporal_model.model.2.convolution_paths.0.1.norm.running_mean\n",
      "ignored temporal_model.model.2.convolution_paths.0.1.norm.running_var\n",
      "ignored temporal_model.model.2.convolution_paths.0.1.norm.num_batches_tracked\n",
      "ignored temporal_model.model.2.convolution_paths.1.0.conv.weight\n",
      "ignored temporal_model.model.2.convolution_paths.1.0.norm.weight\n",
      "ignored temporal_model.model.2.convolution_paths.1.0.norm.bias\n",
      "ignored temporal_model.model.2.convolution_paths.1.0.norm.running_mean\n",
      "ignored temporal_model.model.2.convolution_paths.1.0.norm.running_var\n",
      "ignored temporal_model.model.2.convolution_paths.1.0.norm.num_batches_tracked\n",
      "ignored temporal_model.model.2.convolution_paths.1.1.conv.weight\n",
      "ignored temporal_model.model.2.convolution_paths.1.1.norm.weight\n",
      "ignored temporal_model.model.2.convolution_paths.1.1.norm.bias\n",
      "ignored temporal_model.model.2.convolution_paths.1.1.norm.running_mean\n",
      "ignored temporal_model.model.2.convolution_paths.1.1.norm.running_var\n",
      "ignored temporal_model.model.2.convolution_paths.1.1.norm.num_batches_tracked\n",
      "ignored temporal_model.model.2.convolution_paths.2.conv.weight\n",
      "ignored temporal_model.model.2.convolution_paths.2.norm.weight\n",
      "ignored temporal_model.model.2.convolution_paths.2.norm.bias\n",
      "ignored temporal_model.model.2.convolution_paths.2.norm.running_mean\n",
      "ignored temporal_model.model.2.convolution_paths.2.norm.running_var\n",
      "ignored temporal_model.model.2.convolution_paths.2.norm.num_batches_tracked\n",
      "ignored temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.conv.weight\n",
      "ignored temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.norm.weight\n",
      "ignored temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.norm.bias\n",
      "ignored temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.norm.running_mean\n",
      "ignored temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.norm.running_var\n",
      "ignored temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.norm.num_batches_tracked\n",
      "ignored temporal_model.model.2.aggregation.0.conv.weight\n",
      "ignored temporal_model.model.2.aggregation.0.norm.weight\n",
      "ignored temporal_model.model.2.aggregation.0.norm.bias\n",
      "ignored temporal_model.model.2.aggregation.0.norm.running_mean\n",
      "ignored temporal_model.model.2.aggregation.0.norm.running_var\n",
      "ignored temporal_model.model.2.aggregation.0.norm.num_batches_tracked\n"
     ]
    }
   ],
   "source": [
    "relevant_weights = [\"transformer\", \"img_neck\",\n",
    "                    \"temporal_model\", \"img_backbone\"]\n",
    "\n",
    "\n",
    "weights_tiny = torch.load(\n",
    "    \"/home/niklas/ETM_BEV/BEVerse/weights/clean_weights_tiny.pth\")\n",
    "\n",
    "search_weights = tuple(weights_tiny.keys())\n",
    "\n",
    "for k, v in model_dict.items():\n",
    "    if k in search_weights:\n",
    "        v = weights_tiny[k].clone()\n",
    "        v.requires_grad = False\n",
    "        print(\n",
    "            f\"Loaded weights for {k}, and required grad: {v.requires_grad}\")\n",
    "    else:\n",
    "        print(f\"ignored {k}\")\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "for k, v in model.named_parameters():\n",
    "    if k.startswith(tuple(relevant_weights)):\n",
    "        print(f\"turned_of_val for {k}\")\n",
    "        v.requires_grad = False\n",
    "    else:\n",
    "        print(f\"Grad stays for {k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(model_dict)\n",
    "model_dict2 = model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model_dict2[\"img_backbone.stages.0.blocks.0.norm1.weight\"].requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.conv1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn1.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.conv2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.bn2.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.downsample.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.0.0.downsample.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.conv1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn1.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.conv2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.0.1.bn2.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.conv1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn1.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.conv2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.bn2.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.downsample.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.1.0.downsample.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.conv1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn1.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.conv2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.1.1.bn2.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.conv1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn1.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.conv2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.bn2.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.downsample.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.2.0.downsample.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.conv1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn1.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.conv2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.layers.2.1.bn2.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.up1.conv.0.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.up1.conv.1.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.up1.conv.3.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.up1.conv.4.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.up2.1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.up2.2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.up2.2.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.up2.4.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.3dod.up2.4.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.0.0.conv1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn1.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.0.0.conv2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.0.0.bn2.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.0.0.downsample.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.0.0.downsample.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.0.1.conv1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn1.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.0.1.conv2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.0.1.bn2.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.1.0.conv1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn1.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.1.0.conv2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.1.0.bn2.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.1.0.downsample.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.1.0.downsample.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.1.1.conv1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn1.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.1.1.conv2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.1.1.bn2.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.2.0.conv1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn1.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.2.0.conv2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.2.0.bn2.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.2.0.downsample.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.2.0.downsample.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.2.1.conv1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn1.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.2.1.conv2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.layers.2.1.bn2.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.up1.conv.0.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.up1.conv.1.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.up1.conv.3.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.up1.conv.4.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.up2.1.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.up2.2.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.up2.2.bias\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.up2.4.weight\n",
      "Grad stays for pts_bbox_head.taskfeat_encoders.motion.up2.4.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.shared_conv.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.shared_conv.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.shared_conv.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.reg.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.reg.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.reg.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.height.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.height.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.height.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.dim.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.dim.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.dim.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.rot.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.rot.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.rot.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.vel.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.vel.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.vel.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.0.heatmap.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.reg.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.reg.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.reg.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.height.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.height.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.height.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.dim.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.dim.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.dim.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.rot.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.rot.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.rot.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.vel.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.vel.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.vel.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.1.heatmap.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.reg.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.reg.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.reg.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.height.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.height.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.height.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.dim.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.dim.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.dim.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.rot.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.rot.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.rot.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.vel.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.vel.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.vel.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.2.heatmap.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.reg.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.reg.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.reg.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.height.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.height.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.height.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.dim.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.dim.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.dim.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.rot.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.rot.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.rot.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.vel.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.vel.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.vel.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.3.heatmap.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.reg.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.reg.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.reg.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.height.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.height.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.height.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.dim.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.dim.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.dim.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.rot.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.rot.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.rot.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.vel.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.vel.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.vel.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.4.heatmap.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.reg.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.reg.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.reg.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.height.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.height.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.height.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.dim.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.dim.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.dim.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.rot.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.rot.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.rot.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.vel.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.vel.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.vel.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.0.bn.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.3dod.task_heads.5.heatmap.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.segmentation.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.segmentation.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.segmentation.3.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.segmentation.3.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_center.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_center.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_center.3.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_center.3.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_offset.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_offset.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_offset.3.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_offset.3.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_flow.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_flow.1.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_flow.3.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.task_heads.instance_flow.3.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv_down_project.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_down_project.0.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn.0.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.conv_up_project.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.layers.abn_up_project.0.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.conv_skip_proj.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.0.projection.bn_skip_proj.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv_down_project.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_down_project.0.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn.0.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.conv_up_project.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.layers.abn_up_project.0.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.conv_skip_proj.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.encoder.model.1.projection.bn_skip_proj.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.last_conv.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.present_distribution.last_conv.0.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv_down_project.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_down_project.0.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn.0.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.conv_up_project.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.layers.abn_up_project.0.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.conv_skip_proj.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.0.projection.bn_skip_proj.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv_down_project.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_down_project.0.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn.0.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.conv_up_project.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.layers.abn_up_project.0.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.conv_skip_proj.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.encoder.model.1.projection.bn_skip_proj.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.last_conv.0.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_distribution.last_conv.0.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.offset_conv.norm.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.offset_pred.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.offset_pred.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_update.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_update.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_reset.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_reset.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.gru_cells.0.conv_state_tilde.norm.bias\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.conv.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.weight\n",
      "Grad stays for pts_bbox_head.task_decoders.motion.future_prediction.spatial_conv.norm.bias\n",
      "turned_of_val for img_backbone.patch_embed.projection.weight\n",
      "turned_of_val for img_backbone.patch_embed.projection.bias\n",
      "turned_of_val for img_backbone.patch_embed.norm.weight\n",
      "turned_of_val for img_backbone.patch_embed.norm.bias\n",
      "turned_of_val for img_backbone.stages.0.blocks.0.norm1.weight\n",
      "turned_of_val for img_backbone.stages.0.blocks.0.norm1.bias\n",
      "turned_of_val for img_backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "turned_of_val for img_backbone.stages.0.blocks.0.attn.w_msa.qkv.weight\n",
      "turned_of_val for img_backbone.stages.0.blocks.0.attn.w_msa.qkv.bias\n",
      "turned_of_val for img_backbone.stages.0.blocks.0.attn.w_msa.proj.weight\n",
      "turned_of_val for img_backbone.stages.0.blocks.0.attn.w_msa.proj.bias\n",
      "turned_of_val for img_backbone.stages.0.blocks.0.norm2.weight\n",
      "turned_of_val for img_backbone.stages.0.blocks.0.norm2.bias\n",
      "turned_of_val for img_backbone.stages.0.blocks.0.ffn.layers.0.0.weight\n",
      "turned_of_val for img_backbone.stages.0.blocks.0.ffn.layers.0.0.bias\n",
      "turned_of_val for img_backbone.stages.0.blocks.0.ffn.layers.1.weight\n",
      "turned_of_val for img_backbone.stages.0.blocks.0.ffn.layers.1.bias\n",
      "turned_of_val for img_backbone.stages.0.blocks.1.norm1.weight\n",
      "turned_of_val for img_backbone.stages.0.blocks.1.norm1.bias\n",
      "turned_of_val for img_backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "turned_of_val for img_backbone.stages.0.blocks.1.attn.w_msa.qkv.weight\n",
      "turned_of_val for img_backbone.stages.0.blocks.1.attn.w_msa.qkv.bias\n",
      "turned_of_val for img_backbone.stages.0.blocks.1.attn.w_msa.proj.weight\n",
      "turned_of_val for img_backbone.stages.0.blocks.1.attn.w_msa.proj.bias\n",
      "turned_of_val for img_backbone.stages.0.blocks.1.norm2.weight\n",
      "turned_of_val for img_backbone.stages.0.blocks.1.norm2.bias\n",
      "turned_of_val for img_backbone.stages.0.blocks.1.ffn.layers.0.0.weight\n",
      "turned_of_val for img_backbone.stages.0.blocks.1.ffn.layers.0.0.bias\n",
      "turned_of_val for img_backbone.stages.0.blocks.1.ffn.layers.1.weight\n",
      "turned_of_val for img_backbone.stages.0.blocks.1.ffn.layers.1.bias\n",
      "turned_of_val for img_backbone.stages.0.downsample.norm.weight\n",
      "turned_of_val for img_backbone.stages.0.downsample.norm.bias\n",
      "turned_of_val for img_backbone.stages.0.downsample.reduction.weight\n",
      "turned_of_val for img_backbone.stages.1.blocks.0.norm1.weight\n",
      "turned_of_val for img_backbone.stages.1.blocks.0.norm1.bias\n",
      "turned_of_val for img_backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "turned_of_val for img_backbone.stages.1.blocks.0.attn.w_msa.qkv.weight\n",
      "turned_of_val for img_backbone.stages.1.blocks.0.attn.w_msa.qkv.bias\n",
      "turned_of_val for img_backbone.stages.1.blocks.0.attn.w_msa.proj.weight\n",
      "turned_of_val for img_backbone.stages.1.blocks.0.attn.w_msa.proj.bias\n",
      "turned_of_val for img_backbone.stages.1.blocks.0.norm2.weight\n",
      "turned_of_val for img_backbone.stages.1.blocks.0.norm2.bias\n",
      "turned_of_val for img_backbone.stages.1.blocks.0.ffn.layers.0.0.weight\n",
      "turned_of_val for img_backbone.stages.1.blocks.0.ffn.layers.0.0.bias\n",
      "turned_of_val for img_backbone.stages.1.blocks.0.ffn.layers.1.weight\n",
      "turned_of_val for img_backbone.stages.1.blocks.0.ffn.layers.1.bias\n",
      "turned_of_val for img_backbone.stages.1.blocks.1.norm1.weight\n",
      "turned_of_val for img_backbone.stages.1.blocks.1.norm1.bias\n",
      "turned_of_val for img_backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "turned_of_val for img_backbone.stages.1.blocks.1.attn.w_msa.qkv.weight\n",
      "turned_of_val for img_backbone.stages.1.blocks.1.attn.w_msa.qkv.bias\n",
      "turned_of_val for img_backbone.stages.1.blocks.1.attn.w_msa.proj.weight\n",
      "turned_of_val for img_backbone.stages.1.blocks.1.attn.w_msa.proj.bias\n",
      "turned_of_val for img_backbone.stages.1.blocks.1.norm2.weight\n",
      "turned_of_val for img_backbone.stages.1.blocks.1.norm2.bias\n",
      "turned_of_val for img_backbone.stages.1.blocks.1.ffn.layers.0.0.weight\n",
      "turned_of_val for img_backbone.stages.1.blocks.1.ffn.layers.0.0.bias\n",
      "turned_of_val for img_backbone.stages.1.blocks.1.ffn.layers.1.weight\n",
      "turned_of_val for img_backbone.stages.1.blocks.1.ffn.layers.1.bias\n",
      "turned_of_val for img_backbone.stages.1.downsample.norm.weight\n",
      "turned_of_val for img_backbone.stages.1.downsample.norm.bias\n",
      "turned_of_val for img_backbone.stages.1.downsample.reduction.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.0.norm1.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.0.norm1.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "turned_of_val for img_backbone.stages.2.blocks.0.attn.w_msa.qkv.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.0.attn.w_msa.qkv.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.0.attn.w_msa.proj.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.0.attn.w_msa.proj.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.0.norm2.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.0.norm2.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.0.ffn.layers.0.0.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.0.ffn.layers.0.0.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.0.ffn.layers.1.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.0.ffn.layers.1.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.1.norm1.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.1.norm1.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "turned_of_val for img_backbone.stages.2.blocks.1.attn.w_msa.qkv.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.1.attn.w_msa.qkv.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.1.attn.w_msa.proj.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.1.attn.w_msa.proj.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.1.norm2.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.1.norm2.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.1.ffn.layers.0.0.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.1.ffn.layers.0.0.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.1.ffn.layers.1.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.1.ffn.layers.1.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.2.norm1.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.2.norm1.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table\n",
      "turned_of_val for img_backbone.stages.2.blocks.2.attn.w_msa.qkv.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.2.attn.w_msa.qkv.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.2.attn.w_msa.proj.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.2.attn.w_msa.proj.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.2.norm2.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.2.norm2.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.2.ffn.layers.0.0.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.2.ffn.layers.0.0.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.2.ffn.layers.1.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.2.ffn.layers.1.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.3.norm1.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.3.norm1.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table\n",
      "turned_of_val for img_backbone.stages.2.blocks.3.attn.w_msa.qkv.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.3.attn.w_msa.qkv.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.3.attn.w_msa.proj.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.3.attn.w_msa.proj.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.3.norm2.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.3.norm2.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.3.ffn.layers.0.0.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.3.ffn.layers.0.0.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.3.ffn.layers.1.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.3.ffn.layers.1.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.4.norm1.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.4.norm1.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table\n",
      "turned_of_val for img_backbone.stages.2.blocks.4.attn.w_msa.qkv.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.4.attn.w_msa.qkv.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.4.attn.w_msa.proj.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.4.attn.w_msa.proj.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.4.norm2.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.4.norm2.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.4.ffn.layers.0.0.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.4.ffn.layers.0.0.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.4.ffn.layers.1.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.4.ffn.layers.1.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.5.norm1.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.5.norm1.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table\n",
      "turned_of_val for img_backbone.stages.2.blocks.5.attn.w_msa.qkv.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.5.attn.w_msa.qkv.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.5.attn.w_msa.proj.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.5.attn.w_msa.proj.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.5.norm2.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.5.norm2.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.5.ffn.layers.0.0.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.5.ffn.layers.0.0.bias\n",
      "turned_of_val for img_backbone.stages.2.blocks.5.ffn.layers.1.weight\n",
      "turned_of_val for img_backbone.stages.2.blocks.5.ffn.layers.1.bias\n",
      "turned_of_val for img_backbone.stages.2.downsample.norm.weight\n",
      "turned_of_val for img_backbone.stages.2.downsample.norm.bias\n",
      "turned_of_val for img_backbone.stages.2.downsample.reduction.weight\n",
      "turned_of_val for img_backbone.stages.3.blocks.0.norm1.weight\n",
      "turned_of_val for img_backbone.stages.3.blocks.0.norm1.bias\n",
      "turned_of_val for img_backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "turned_of_val for img_backbone.stages.3.blocks.0.attn.w_msa.qkv.weight\n",
      "turned_of_val for img_backbone.stages.3.blocks.0.attn.w_msa.qkv.bias\n",
      "turned_of_val for img_backbone.stages.3.blocks.0.attn.w_msa.proj.weight\n",
      "turned_of_val for img_backbone.stages.3.blocks.0.attn.w_msa.proj.bias\n",
      "turned_of_val for img_backbone.stages.3.blocks.0.norm2.weight\n",
      "turned_of_val for img_backbone.stages.3.blocks.0.norm2.bias\n",
      "turned_of_val for img_backbone.stages.3.blocks.0.ffn.layers.0.0.weight\n",
      "turned_of_val for img_backbone.stages.3.blocks.0.ffn.layers.0.0.bias\n",
      "turned_of_val for img_backbone.stages.3.blocks.0.ffn.layers.1.weight\n",
      "turned_of_val for img_backbone.stages.3.blocks.0.ffn.layers.1.bias\n",
      "turned_of_val for img_backbone.stages.3.blocks.1.norm1.weight\n",
      "turned_of_val for img_backbone.stages.3.blocks.1.norm1.bias\n",
      "turned_of_val for img_backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "turned_of_val for img_backbone.stages.3.blocks.1.attn.w_msa.qkv.weight\n",
      "turned_of_val for img_backbone.stages.3.blocks.1.attn.w_msa.qkv.bias\n",
      "turned_of_val for img_backbone.stages.3.blocks.1.attn.w_msa.proj.weight\n",
      "turned_of_val for img_backbone.stages.3.blocks.1.attn.w_msa.proj.bias\n",
      "turned_of_val for img_backbone.stages.3.blocks.1.norm2.weight\n",
      "turned_of_val for img_backbone.stages.3.blocks.1.norm2.bias\n",
      "turned_of_val for img_backbone.stages.3.blocks.1.ffn.layers.0.0.weight\n",
      "turned_of_val for img_backbone.stages.3.blocks.1.ffn.layers.0.0.bias\n",
      "turned_of_val for img_backbone.stages.3.blocks.1.ffn.layers.1.weight\n",
      "turned_of_val for img_backbone.stages.3.blocks.1.ffn.layers.1.bias\n",
      "turned_of_val for img_backbone.norm2.weight\n",
      "turned_of_val for img_backbone.norm2.bias\n",
      "turned_of_val for img_backbone.norm3.weight\n",
      "turned_of_val for img_backbone.norm3.bias\n",
      "turned_of_val for img_neck.up.conv.0.weight\n",
      "turned_of_val for img_neck.up.conv.1.weight\n",
      "turned_of_val for img_neck.up.conv.1.bias\n",
      "turned_of_val for img_neck.up.conv.3.weight\n",
      "turned_of_val for img_neck.up.conv.4.weight\n",
      "turned_of_val for img_neck.up.conv.4.bias\n",
      "turned_of_val for transformer.frustum\n",
      "turned_of_val for transformer.depthnet.weight\n",
      "turned_of_val for transformer.depthnet.bias\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.0.0.conv.weight\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.0.0.norm.weight\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.0.0.norm.bias\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.0.1.conv.weight\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.0.1.norm.weight\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.0.1.norm.bias\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.1.0.conv.weight\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.1.0.norm.weight\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.1.0.norm.bias\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.1.1.conv.weight\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.1.1.norm.weight\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.1.1.norm.bias\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.2.conv.weight\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.2.norm.weight\n",
      "turned_of_val for temporal_model.model.0.convolution_paths.2.norm.bias\n",
      "turned_of_val for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.conv.weight\n",
      "turned_of_val for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.weight\n",
      "turned_of_val for temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.bias\n",
      "turned_of_val for temporal_model.model.0.aggregation.0.conv.weight\n",
      "turned_of_val for temporal_model.model.0.aggregation.0.norm.weight\n",
      "turned_of_val for temporal_model.model.0.aggregation.0.norm.bias\n",
      "turned_of_val for temporal_model.model.0.projection.0.weight\n",
      "turned_of_val for temporal_model.model.0.projection.1.weight\n",
      "turned_of_val for temporal_model.model.0.projection.1.bias\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.0.0.conv.weight\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.0.0.norm.weight\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.0.0.norm.bias\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.0.1.conv.weight\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.0.1.norm.weight\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.0.1.norm.bias\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.1.0.conv.weight\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.1.0.norm.weight\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.1.0.norm.bias\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.1.1.conv.weight\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.1.1.norm.weight\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.1.1.norm.bias\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.2.conv.weight\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.2.norm.weight\n",
      "turned_of_val for temporal_model.model.1.convolution_paths.2.norm.bias\n",
      "turned_of_val for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.conv.weight\n",
      "turned_of_val for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.weight\n",
      "turned_of_val for temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.bias\n",
      "turned_of_val for temporal_model.model.1.aggregation.0.conv.weight\n",
      "turned_of_val for temporal_model.model.1.aggregation.0.norm.weight\n",
      "turned_of_val for temporal_model.model.1.aggregation.0.norm.bias\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.0.0.conv.weight\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.0.0.norm.weight\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.0.0.norm.bias\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.0.1.conv.weight\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.0.1.norm.weight\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.0.1.norm.bias\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.1.0.conv.weight\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.1.0.norm.weight\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.1.0.norm.bias\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.1.1.conv.weight\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.1.1.norm.weight\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.1.1.norm.bias\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.2.conv.weight\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.2.norm.weight\n",
      "turned_of_val for temporal_model.model.2.convolution_paths.2.norm.bias\n",
      "turned_of_val for temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.conv.weight\n",
      "turned_of_val for temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.norm.weight\n",
      "turned_of_val for temporal_model.model.2.pyramid_pooling.features.0.conv_bn_relu.norm.bias\n",
      "turned_of_val for temporal_model.model.2.aggregation.0.conv.weight\n",
      "turned_of_val for temporal_model.model.2.aggregation.0.norm.weight\n",
      "turned_of_val for temporal_model.model.2.aggregation.0.norm.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.named_parameters():\n",
    "    if k.startswith(tuple(relevant_weights)):\n",
    "        print(f\"turned_of_val for {k}\")\n",
    "        v.requires_grad = False\n",
    "    else:\n",
    "        print(f\"Grad stays for {k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22752\n",
      "232\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(weights_tiny))\n",
    "print(sys.getsizeof(weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['img_backbone.patch_embed.projection.weight', 'img_backbone.patch_embed.projection.bias', 'img_backbone.patch_embed.norm.weight', 'img_backbone.patch_embed.norm.bias', 'img_backbone.stages.0.blocks.0.norm1.weight', 'img_backbone.stages.0.blocks.0.norm1.bias', 'img_backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table', 'img_backbone.stages.0.blocks.0.attn.w_msa.relative_position_index', 'img_backbone.stages.0.blocks.0.attn.w_msa.qkv.weight', 'img_backbone.stages.0.blocks.0.attn.w_msa.qkv.bias', 'img_backbone.stages.0.blocks.0.attn.w_msa.proj.weight', 'img_backbone.stages.0.blocks.0.attn.w_msa.proj.bias', 'img_backbone.stages.0.blocks.0.norm2.weight', 'img_backbone.stages.0.blocks.0.norm2.bias', 'img_backbone.stages.0.blocks.0.ffn.layers.0.0.weight', 'img_backbone.stages.0.blocks.0.ffn.layers.0.0.bias', 'img_backbone.stages.0.blocks.0.ffn.layers.1.weight', 'img_backbone.stages.0.blocks.0.ffn.layers.1.bias', 'img_backbone.stages.0.blocks.1.norm1.weight', 'img_backbone.stages.0.blocks.1.norm1.bias', 'img_backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table', 'img_backbone.stages.0.blocks.1.attn.w_msa.relative_position_index', 'img_backbone.stages.0.blocks.1.attn.w_msa.qkv.weight', 'img_backbone.stages.0.blocks.1.attn.w_msa.qkv.bias', 'img_backbone.stages.0.blocks.1.attn.w_msa.proj.weight', 'img_backbone.stages.0.blocks.1.attn.w_msa.proj.bias', 'img_backbone.stages.0.blocks.1.norm2.weight', 'img_backbone.stages.0.blocks.1.norm2.bias', 'img_backbone.stages.0.blocks.1.ffn.layers.0.0.weight', 'img_backbone.stages.0.blocks.1.ffn.layers.0.0.bias', 'img_backbone.stages.0.blocks.1.ffn.layers.1.weight', 'img_backbone.stages.0.blocks.1.ffn.layers.1.bias', 'img_backbone.stages.0.downsample.norm.weight', 'img_backbone.stages.0.downsample.norm.bias', 'img_backbone.stages.0.downsample.reduction.weight', 'img_backbone.stages.1.blocks.0.norm1.weight', 'img_backbone.stages.1.blocks.0.norm1.bias', 'img_backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table', 'img_backbone.stages.1.blocks.0.attn.w_msa.relative_position_index', 'img_backbone.stages.1.blocks.0.attn.w_msa.qkv.weight', 'img_backbone.stages.1.blocks.0.attn.w_msa.qkv.bias', 'img_backbone.stages.1.blocks.0.attn.w_msa.proj.weight', 'img_backbone.stages.1.blocks.0.attn.w_msa.proj.bias', 'img_backbone.stages.1.blocks.0.norm2.weight', 'img_backbone.stages.1.blocks.0.norm2.bias', 'img_backbone.stages.1.blocks.0.ffn.layers.0.0.weight', 'img_backbone.stages.1.blocks.0.ffn.layers.0.0.bias', 'img_backbone.stages.1.blocks.0.ffn.layers.1.weight', 'img_backbone.stages.1.blocks.0.ffn.layers.1.bias', 'img_backbone.stages.1.blocks.1.norm1.weight', 'img_backbone.stages.1.blocks.1.norm1.bias', 'img_backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table', 'img_backbone.stages.1.blocks.1.attn.w_msa.relative_position_index', 'img_backbone.stages.1.blocks.1.attn.w_msa.qkv.weight', 'img_backbone.stages.1.blocks.1.attn.w_msa.qkv.bias', 'img_backbone.stages.1.blocks.1.attn.w_msa.proj.weight', 'img_backbone.stages.1.blocks.1.attn.w_msa.proj.bias', 'img_backbone.stages.1.blocks.1.norm2.weight', 'img_backbone.stages.1.blocks.1.norm2.bias', 'img_backbone.stages.1.blocks.1.ffn.layers.0.0.weight', 'img_backbone.stages.1.blocks.1.ffn.layers.0.0.bias', 'img_backbone.stages.1.blocks.1.ffn.layers.1.weight', 'img_backbone.stages.1.blocks.1.ffn.layers.1.bias', 'img_backbone.stages.1.downsample.norm.weight', 'img_backbone.stages.1.downsample.norm.bias', 'img_backbone.stages.1.downsample.reduction.weight', 'img_backbone.stages.2.blocks.0.norm1.weight', 'img_backbone.stages.2.blocks.0.norm1.bias', 'img_backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table', 'img_backbone.stages.2.blocks.0.attn.w_msa.relative_position_index', 'img_backbone.stages.2.blocks.0.attn.w_msa.qkv.weight', 'img_backbone.stages.2.blocks.0.attn.w_msa.qkv.bias', 'img_backbone.stages.2.blocks.0.attn.w_msa.proj.weight', 'img_backbone.stages.2.blocks.0.attn.w_msa.proj.bias', 'img_backbone.stages.2.blocks.0.norm2.weight', 'img_backbone.stages.2.blocks.0.norm2.bias', 'img_backbone.stages.2.blocks.0.ffn.layers.0.0.weight', 'img_backbone.stages.2.blocks.0.ffn.layers.0.0.bias', 'img_backbone.stages.2.blocks.0.ffn.layers.1.weight', 'img_backbone.stages.2.blocks.0.ffn.layers.1.bias', 'img_backbone.stages.2.blocks.1.norm1.weight', 'img_backbone.stages.2.blocks.1.norm1.bias', 'img_backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table', 'img_backbone.stages.2.blocks.1.attn.w_msa.relative_position_index', 'img_backbone.stages.2.blocks.1.attn.w_msa.qkv.weight', 'img_backbone.stages.2.blocks.1.attn.w_msa.qkv.bias', 'img_backbone.stages.2.blocks.1.attn.w_msa.proj.weight', 'img_backbone.stages.2.blocks.1.attn.w_msa.proj.bias', 'img_backbone.stages.2.blocks.1.norm2.weight', 'img_backbone.stages.2.blocks.1.norm2.bias', 'img_backbone.stages.2.blocks.1.ffn.layers.0.0.weight', 'img_backbone.stages.2.blocks.1.ffn.layers.0.0.bias', 'img_backbone.stages.2.blocks.1.ffn.layers.1.weight', 'img_backbone.stages.2.blocks.1.ffn.layers.1.bias', 'img_backbone.stages.2.blocks.2.norm1.weight', 'img_backbone.stages.2.blocks.2.norm1.bias', 'img_backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table', 'img_backbone.stages.2.blocks.2.attn.w_msa.relative_position_index', 'img_backbone.stages.2.blocks.2.attn.w_msa.qkv.weight', 'img_backbone.stages.2.blocks.2.attn.w_msa.qkv.bias', 'img_backbone.stages.2.blocks.2.attn.w_msa.proj.weight', 'img_backbone.stages.2.blocks.2.attn.w_msa.proj.bias', 'img_backbone.stages.2.blocks.2.norm2.weight', 'img_backbone.stages.2.blocks.2.norm2.bias', 'img_backbone.stages.2.blocks.2.ffn.layers.0.0.weight', 'img_backbone.stages.2.blocks.2.ffn.layers.0.0.bias', 'img_backbone.stages.2.blocks.2.ffn.layers.1.weight', 'img_backbone.stages.2.blocks.2.ffn.layers.1.bias', 'img_backbone.stages.2.blocks.3.norm1.weight', 'img_backbone.stages.2.blocks.3.norm1.bias', 'img_backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table', 'img_backbone.stages.2.blocks.3.attn.w_msa.relative_position_index', 'img_backbone.stages.2.blocks.3.attn.w_msa.qkv.weight', 'img_backbone.stages.2.blocks.3.attn.w_msa.qkv.bias', 'img_backbone.stages.2.blocks.3.attn.w_msa.proj.weight', 'img_backbone.stages.2.blocks.3.attn.w_msa.proj.bias', 'img_backbone.stages.2.blocks.3.norm2.weight', 'img_backbone.stages.2.blocks.3.norm2.bias', 'img_backbone.stages.2.blocks.3.ffn.layers.0.0.weight', 'img_backbone.stages.2.blocks.3.ffn.layers.0.0.bias', 'img_backbone.stages.2.blocks.3.ffn.layers.1.weight', 'img_backbone.stages.2.blocks.3.ffn.layers.1.bias', 'img_backbone.stages.2.blocks.4.norm1.weight', 'img_backbone.stages.2.blocks.4.norm1.bias', 'img_backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table', 'img_backbone.stages.2.blocks.4.attn.w_msa.relative_position_index', 'img_backbone.stages.2.blocks.4.attn.w_msa.qkv.weight', 'img_backbone.stages.2.blocks.4.attn.w_msa.qkv.bias', 'img_backbone.stages.2.blocks.4.attn.w_msa.proj.weight', 'img_backbone.stages.2.blocks.4.attn.w_msa.proj.bias', 'img_backbone.stages.2.blocks.4.norm2.weight', 'img_backbone.stages.2.blocks.4.norm2.bias', 'img_backbone.stages.2.blocks.4.ffn.layers.0.0.weight', 'img_backbone.stages.2.blocks.4.ffn.layers.0.0.bias', 'img_backbone.stages.2.blocks.4.ffn.layers.1.weight', 'img_backbone.stages.2.blocks.4.ffn.layers.1.bias', 'img_backbone.stages.2.blocks.5.norm1.weight', 'img_backbone.stages.2.blocks.5.norm1.bias', 'img_backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table', 'img_backbone.stages.2.blocks.5.attn.w_msa.relative_position_index', 'img_backbone.stages.2.blocks.5.attn.w_msa.qkv.weight', 'img_backbone.stages.2.blocks.5.attn.w_msa.qkv.bias', 'img_backbone.stages.2.blocks.5.attn.w_msa.proj.weight', 'img_backbone.stages.2.blocks.5.attn.w_msa.proj.bias', 'img_backbone.stages.2.blocks.5.norm2.weight', 'img_backbone.stages.2.blocks.5.norm2.bias', 'img_backbone.stages.2.blocks.5.ffn.layers.0.0.weight', 'img_backbone.stages.2.blocks.5.ffn.layers.0.0.bias', 'img_backbone.stages.2.blocks.5.ffn.layers.1.weight', 'img_backbone.stages.2.blocks.5.ffn.layers.1.bias', 'img_backbone.stages.2.downsample.norm.weight', 'img_backbone.stages.2.downsample.norm.bias', 'img_backbone.stages.2.downsample.reduction.weight', 'img_backbone.stages.3.blocks.0.norm1.weight', 'img_backbone.stages.3.blocks.0.norm1.bias', 'img_backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table', 'img_backbone.stages.3.blocks.0.attn.w_msa.relative_position_index', 'img_backbone.stages.3.blocks.0.attn.w_msa.qkv.weight', 'img_backbone.stages.3.blocks.0.attn.w_msa.qkv.bias', 'img_backbone.stages.3.blocks.0.attn.w_msa.proj.weight', 'img_backbone.stages.3.blocks.0.attn.w_msa.proj.bias', 'img_backbone.stages.3.blocks.0.norm2.weight', 'img_backbone.stages.3.blocks.0.norm2.bias', 'img_backbone.stages.3.blocks.0.ffn.layers.0.0.weight', 'img_backbone.stages.3.blocks.0.ffn.layers.0.0.bias', 'img_backbone.stages.3.blocks.0.ffn.layers.1.weight', 'img_backbone.stages.3.blocks.0.ffn.layers.1.bias', 'img_backbone.stages.3.blocks.1.norm1.weight', 'img_backbone.stages.3.blocks.1.norm1.bias', 'img_backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table', 'img_backbone.stages.3.blocks.1.attn.w_msa.relative_position_index', 'img_backbone.stages.3.blocks.1.attn.w_msa.qkv.weight', 'img_backbone.stages.3.blocks.1.attn.w_msa.qkv.bias', 'img_backbone.stages.3.blocks.1.attn.w_msa.proj.weight', 'img_backbone.stages.3.blocks.1.attn.w_msa.proj.bias', 'img_backbone.stages.3.blocks.1.norm2.weight', 'img_backbone.stages.3.blocks.1.norm2.bias', 'img_backbone.stages.3.blocks.1.ffn.layers.0.0.weight', 'img_backbone.stages.3.blocks.1.ffn.layers.0.0.bias', 'img_backbone.stages.3.blocks.1.ffn.layers.1.weight', 'img_backbone.stages.3.blocks.1.ffn.layers.1.bias', 'img_backbone.norm2.weight', 'img_backbone.norm2.bias', 'img_backbone.norm3.weight', 'img_backbone.norm3.bias', 'img_neck.up.conv.0.weight', 'img_neck.up.conv.1.weight', 'img_neck.up.conv.1.bias', 'img_neck.up.conv.1.running_mean', 'img_neck.up.conv.1.running_var', 'img_neck.up.conv.1.num_batches_tracked', 'img_neck.up.conv.3.weight', 'img_neck.up.conv.4.weight', 'img_neck.up.conv.4.bias', 'img_neck.up.conv.4.running_mean', 'img_neck.up.conv.4.running_var', 'img_neck.up.conv.4.num_batches_tracked', 'transformer.frustum', 'transformer.depthnet.weight', 'transformer.depthnet.bias', 'temporal_model.model.0.convolution_paths.0.0.conv.weight', 'temporal_model.model.0.convolution_paths.0.0.norm.weight', 'temporal_model.model.0.convolution_paths.0.0.norm.bias', 'temporal_model.model.0.convolution_paths.0.0.norm.running_mean', 'temporal_model.model.0.convolution_paths.0.0.norm.running_var', 'temporal_model.model.0.convolution_paths.0.0.norm.num_batches_tracked', 'temporal_model.model.0.convolution_paths.0.1.conv.weight', 'temporal_model.model.0.convolution_paths.0.1.norm.weight', 'temporal_model.model.0.convolution_paths.0.1.norm.bias', 'temporal_model.model.0.convolution_paths.0.1.norm.running_mean', 'temporal_model.model.0.convolution_paths.0.1.norm.running_var', 'temporal_model.model.0.convolution_paths.0.1.norm.num_batches_tracked', 'temporal_model.model.0.convolution_paths.1.0.conv.weight', 'temporal_model.model.0.convolution_paths.1.0.norm.weight', 'temporal_model.model.0.convolution_paths.1.0.norm.bias', 'temporal_model.model.0.convolution_paths.1.0.norm.running_mean', 'temporal_model.model.0.convolution_paths.1.0.norm.running_var', 'temporal_model.model.0.convolution_paths.1.0.norm.num_batches_tracked', 'temporal_model.model.0.convolution_paths.1.1.conv.weight', 'temporal_model.model.0.convolution_paths.1.1.norm.weight', 'temporal_model.model.0.convolution_paths.1.1.norm.bias', 'temporal_model.model.0.convolution_paths.1.1.norm.running_mean', 'temporal_model.model.0.convolution_paths.1.1.norm.running_var', 'temporal_model.model.0.convolution_paths.1.1.norm.num_batches_tracked', 'temporal_model.model.0.convolution_paths.2.conv.weight', 'temporal_model.model.0.convolution_paths.2.norm.weight', 'temporal_model.model.0.convolution_paths.2.norm.bias', 'temporal_model.model.0.convolution_paths.2.norm.running_mean', 'temporal_model.model.0.convolution_paths.2.norm.running_var', 'temporal_model.model.0.convolution_paths.2.norm.num_batches_tracked', 'temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.conv.weight', 'temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.weight', 'temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.bias', 'temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.running_mean', 'temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.running_var', 'temporal_model.model.0.pyramid_pooling.features.0.conv_bn_relu.norm.num_batches_tracked', 'temporal_model.model.0.aggregation.0.conv.weight', 'temporal_model.model.0.aggregation.0.norm.weight', 'temporal_model.model.0.aggregation.0.norm.bias', 'temporal_model.model.0.aggregation.0.norm.running_mean', 'temporal_model.model.0.aggregation.0.norm.running_var', 'temporal_model.model.0.aggregation.0.norm.num_batches_tracked', 'temporal_model.model.0.projection.0.weight', 'temporal_model.model.0.projection.1.weight', 'temporal_model.model.0.projection.1.bias', 'temporal_model.model.0.projection.1.running_mean', 'temporal_model.model.0.projection.1.running_var', 'temporal_model.model.0.projection.1.num_batches_tracked', 'temporal_model.model.1.convolution_paths.0.0.conv.weight', 'temporal_model.model.1.convolution_paths.0.0.norm.weight', 'temporal_model.model.1.convolution_paths.0.0.norm.bias', 'temporal_model.model.1.convolution_paths.0.0.norm.running_mean', 'temporal_model.model.1.convolution_paths.0.0.norm.running_var', 'temporal_model.model.1.convolution_paths.0.0.norm.num_batches_tracked', 'temporal_model.model.1.convolution_paths.0.1.conv.weight', 'temporal_model.model.1.convolution_paths.0.1.norm.weight', 'temporal_model.model.1.convolution_paths.0.1.norm.bias', 'temporal_model.model.1.convolution_paths.0.1.norm.running_mean', 'temporal_model.model.1.convolution_paths.0.1.norm.running_var', 'temporal_model.model.1.convolution_paths.0.1.norm.num_batches_tracked', 'temporal_model.model.1.convolution_paths.1.0.conv.weight', 'temporal_model.model.1.convolution_paths.1.0.norm.weight', 'temporal_model.model.1.convolution_paths.1.0.norm.bias', 'temporal_model.model.1.convolution_paths.1.0.norm.running_mean', 'temporal_model.model.1.convolution_paths.1.0.norm.running_var', 'temporal_model.model.1.convolution_paths.1.0.norm.num_batches_tracked', 'temporal_model.model.1.convolution_paths.1.1.conv.weight', 'temporal_model.model.1.convolution_paths.1.1.norm.weight', 'temporal_model.model.1.convolution_paths.1.1.norm.bias', 'temporal_model.model.1.convolution_paths.1.1.norm.running_mean', 'temporal_model.model.1.convolution_paths.1.1.norm.running_var', 'temporal_model.model.1.convolution_paths.1.1.norm.num_batches_tracked', 'temporal_model.model.1.convolution_paths.2.conv.weight', 'temporal_model.model.1.convolution_paths.2.norm.weight', 'temporal_model.model.1.convolution_paths.2.norm.bias', 'temporal_model.model.1.convolution_paths.2.norm.running_mean', 'temporal_model.model.1.convolution_paths.2.norm.running_var', 'temporal_model.model.1.convolution_paths.2.norm.num_batches_tracked', 'temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.conv.weight', 'temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.weight', 'temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.bias', 'temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.running_mean', 'temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.running_var', 'temporal_model.model.1.pyramid_pooling.features.0.conv_bn_relu.norm.num_batches_tracked', 'temporal_model.model.1.aggregation.0.conv.weight', 'temporal_model.model.1.aggregation.0.norm.weight', 'temporal_model.model.1.aggregation.0.norm.bias', 'temporal_model.model.1.aggregation.0.norm.running_mean', 'temporal_model.model.1.aggregation.0.norm.running_var', 'temporal_model.model.1.aggregation.0.norm.num_batches_tracked'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(weights, \"weights/clean_weights_tiny.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "\n",
    "cfg = Config.fromfile(\n",
    "    r\"/home/niklas/ETM_BEV/BEVerse/projects/configs/beverse_tiny_org.py\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_lims = [\n",
    "    (0.3, 0.45),  # fiery\n",
    "    (0.38, 0.55),  # desTINY\n",
    "    (0.82, 0.99),  # small\n",
    "    (1, 1),  # BEVDEt\n",
    "]\n",
    "\n",
    "final_dims = [(224, 480), (256, 704), (512, 1408), (900, 1600)]\n",
    "\n",
    "backbones = [\n",
    "    \"beverse_tiny.py\",\n",
    "    \"beverse_tiny.py\",\n",
    "    \"beverse_small.py\",\n",
    "    \"beverse_small.py\",\n",
    "]\n",
    "\n",
    "# future frames -> tiny settings\n",
    "future_frames_list = [4, 4, 4, 4, 5, 7, 10]\n",
    "receptive_field_list = [\n",
    "    3,\n",
    "    5,\n",
    "    8,\n",
    "    13,\n",
    "    4,\n",
    "    6,\n",
    "    9,\n",
    "]\n",
    "\n",
    "# grid_size = (\n",
    "#     point_cloud_range[3:] -  # type: ignore\n",
    "#     point_cloud_range[:3]) / voxel_size  # type: ignore\n",
    "\n",
    "point_cloud_range_base = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n",
    "point_cloud_range_extended_fustrum = [-71.2, -71.2, -5.0, 71.2, 71.2, 3.0]\n",
    "det_grid_confs = {\n",
    "    \"xbound\": [\n",
    "        [-51.2, 51.2, 0.8],  # lower_bound, upper_bound, interval\n",
    "        [-51.2, 51.2, 0.4],\n",
    "        [-51.2, 51.2, 0.2],\n",
    "        [-51.2, 51.2, 0.1],\n",
    "        [-26.2, 26.2, 0.8],\n",
    "        [-26.2, 26.2, 0.4],\n",
    "    ],\n",
    "    \"ybound\": [\n",
    "        [-51.2, 51.2, 0.8],\n",
    "        [-51.2, 51.2, 0.4],\n",
    "        [-51.2, 51.2, 0.2],\n",
    "        [-51.2, 51.2, 0.1],\n",
    "        [-71.2, 71.2, 0.8],\n",
    "        [-71.2, 71.2, 0.4],\n",
    "    ],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [\n",
    "        [1.0, 60.0, 1.0],\n",
    "        [1.0, 60.0, 1.0],\n",
    "        [1.0, 60.0, 0.5],\n",
    "        [1.0, 60.0, 0.5],\n",
    "        [1.0, 70.0, 1.0],\n",
    "        [1.0, 70.0, 5.0],\n",
    "    ],  # [(lower_bound, upper_bound, interval).]\n",
    "}\n",
    "\n",
    "motion_grid_confs = {\n",
    "    \"xbound\": [\n",
    "        [-50.0, 50.0, 0.5],\n",
    "        [-50.0, 50.0, 0.25],\n",
    "        [-50.0, 50.0, 0.125],\n",
    "        [-50.0, 50.0, 0.075],\n",
    "        [-25.0, 25.0, 0.5],\n",
    "        [-25.0, 25.0, 0.25],\n",
    "    ],\n",
    "    \"ybound\": [\n",
    "        [-50.0, 50.0, 0.5],\n",
    "        [-50.0, 50.0, 0.25],\n",
    "        [-50.0, 50.0, 0.125],\n",
    "        [-50.0, 50.0, 0.075],\n",
    "        [-70.0, 70.0, 0.5],\n",
    "        [-70.0, 70.0, 0.25],\n",
    "    ],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [\n",
    "        [1.0, 60.0, 1.0],\n",
    "        [1.0, 60.0, 1.0],\n",
    "        [1.0, 60.0, 0.5],\n",
    "        [1.0, 60.0, 0.5],\n",
    "        [1.0, 70.0, 1.0],\n",
    "        [1.0, 70.0, 5.0],\n",
    "    ],\n",
    "}\n",
    "\n",
    "map_grid_confs = {\n",
    "    \"xbound\": [-30.0, 30.0, 0.15],\n",
    "    \"ybound\": [-15.0, 15.0, 0.15],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [\n",
    "        [1.0, 60.0, 1.0],\n",
    "        [1.0, 60.0, 1.0],\n",
    "        [1.0, 60.0, 0.5],\n",
    "        [1.0, 60.0, 0.5],\n",
    "        [1.0, 70.0, 1.0],\n",
    "        [1.0, 70.0, 5.0],\n",
    "    ],\n",
    "}\n",
    "det_grid_conf = {\n",
    "    \"xbound\": [-51.2, 51.2, 0.8],\n",
    "    \"ybound\": [-51.2, 51.2, 0.8],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}\n",
    "\n",
    "motion_grid_conf = {\n",
    "    \"xbound\": [-50.0, 50.0, 0.5],\n",
    "    \"ybound\": [-50.0, 50.0, 0.5],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}\n",
    "\n",
    "map_grid_conf = {\n",
    "    \"xbound\": [-30.0, 30.0, 0.15],\n",
    "    \"ybound\": [-15.0, 15.0, 0.15],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# det_grid_conf[\"xbound\"] = det_grid_confs[\"xbound\"][1]\n",
    "# det_grid_conf[\"ybound\"] = det_grid_confs[\"ybound\"][1]\n",
    "# det_grid_conf[\"zbound\"] = det_grid_confs[\"zbound\"]\n",
    "# det_grid_conf[\"dbound\"] = det_grid_confs[\"dbound\"][1]\n",
    "\n",
    "# motion_grid_conf[\"xbound\"] = motion_grid_confs[\"xbound\"][1]\n",
    "# motion_grid_conf[\"ybound\"] = motion_grid_confs[\"ybound\"][1]\n",
    "# motion_grid_conf[\"zbound\"] = motion_grid_confs[\"zbound\"]\n",
    "# motion_grid_conf[\"dbound\"] = motion_grid_confs[\"dbound\"][1]\n",
    "\n",
    "# map_grid_conf[\"xbound\"] = map_grid_confs[\"xbound\"]\n",
    "# map_grid_conf[\"ybound\"] = map_grid_confs[\"ybound\"]\n",
    "# map_grid_conf[\"zbound\"] = map_grid_confs[\"zbound\"]\n",
    "# map_grid_conf[\"dbound\"] = map_grid_confs[\"dbound\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    samples_per_gpu=2,\n",
    "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "    dist=False,\n",
    "    shuffle=False,\n",
    ")\n",
    "iter_loader = iter(data_loader)\n",
    "sample = next(iter_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# device = torch.device(\"cuda:0\")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# cfg = Config.fromfile(\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#     r\"/home/niklas/ETM_BEV/BEVerse/projects/configs/beverse_tiny.py\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m#     cfg.merge_from_dict(args.cfg_options)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# import modules from string list.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mif\u001b[39;00m cfg\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcustom_imports\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmmcv\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m import_modules_from_strings\n\u001b[1;32m     12\u001b[0m     import_modules_from_strings(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcfg[\u001b[39m\"\u001b[39m\u001b[39mcustom_imports\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# device = torch.device(\"cuda:0\")\n",
    "# cfg = Config.fromfile(\n",
    "#     r\"/home/niklas/ETM_BEV/BEVerse/projects/configs/beverse_tiny.py\"\n",
    "# )\n",
    "\n",
    "# if args.cfg_options is not None:\n",
    "#     cfg.merge_from_dict(args.cfg_options)\n",
    "# import modules from string list.\n",
    "if cfg.get(\"custom_imports\", None):\n",
    "    from mmcv.utils import import_modules_from_strings\n",
    "\n",
    "    import_modules_from_strings(**cfg[\"custom_imports\"])\n",
    "\n",
    "# import modules from plguin/xx, registry will be updated\n",
    "if hasattr(cfg, \"plugin\"):\n",
    "    if cfg.plugin:\n",
    "        import importlib\n",
    "\n",
    "        if hasattr(cfg, \"plugin_dir\"):\n",
    "            plugin_dir = cfg.plugin_dir\n",
    "            _module_dir = os.path.dirname(plugin_dir)\n",
    "            _module_dir = _module_dir.split(\"/\")\n",
    "            _module_path = _module_dir[0]\n",
    "\n",
    "            for m in _module_dir[1:]:\n",
    "                _module_path = _module_path + \".\" + m\n",
    "            print(_module_path)\n",
    "            plg_lib = importlib.import_module(_module_path)\n",
    "        else:\n",
    "            # import dir is the dirpath for the config file\n",
    "            _module_dir = os.path.dirname(\n",
    "                r\"/home/niklas/ETM_BEV/BEVerse/projects/configs/beverse_tiny_exp.py\"\n",
    "            )\n",
    "            _module_dir = _module_dir.split(\"/\")\n",
    "            _module_path = _module_dir[0]\n",
    "            for m in _module_dir[1:]:\n",
    "                _module_path = _module_path + \".\" + m\n",
    "            print(_module_path)\n",
    "            plg_lib = importlib.import_module(_module_path)\n",
    "            \n",
    "\n",
    "samples_per_gpu = 1\n",
    "if isinstance(cfg.data.test, dict):\n",
    "    cfg.data.test.test_mode = True\n",
    "    samples_per_gpu = cfg.data.test.pop(\"samples_per_gpu\", 1)\n",
    "    if samples_per_gpu > 1:\n",
    "        # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n",
    "        cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n",
    "elif isinstance(cfg.data.test, list):\n",
    "    for ds_cfg in cfg.data.test:\n",
    "        ds_cfg.test_mode = True\n",
    "    samples_per_gpu = max(\n",
    "        [ds_cfg.pop(\"samples_per_gpu\", 1) for ds_cfg in cfg.data.test]\n",
    "    )\n",
    "    if samples_per_gpu > 1:\n",
    "        for ds_cfg in cfg.data.test:\n",
    "            ds_cfg.pipeline = replace_ImageToTensor(ds_cfg.pipeline)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_time_host(\n",
    "    model: nn.Module,\n",
    "    input_tensor: torch.Tensor,\n",
    "    num_repeats: int = 100,\n",
    "    num_warmups: int = 10,\n",
    "    synchronize: bool = True,\n",
    "    continuous_measure: bool = True,\n",
    ") -> float:\n",
    "\n",
    "    for _ in range(num_warmups):\n",
    "        _ = model.forward(input_tensor)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    elapsed_time_ms = 0\n",
    "\n",
    "    if continuous_measure:\n",
    "        start = timer()\n",
    "        for _ in range(num_repeats):\n",
    "            _ = model.forward(input_tensor)\n",
    "        if synchronize:\n",
    "            torch.cuda.synchronize()\n",
    "        end = timer()\n",
    "        elapsed_time_ms = (end - start) * 1000\n",
    "\n",
    "    else:\n",
    "        for _ in range(num_repeats):\n",
    "            start = timer()\n",
    "            _ = model.forward(input_tensor)\n",
    "            if synchronize:\n",
    "                torch.cuda.synchronize()\n",
    "            end = timer()\n",
    "            elapsed_time_ms += (end - start) * 1000\n",
    "\n",
    "    return elapsed_time_ms / num_repeats\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_time_device(\n",
    "    model: nn.Module,\n",
    "    input_tensor: torch.Tensor,\n",
    "    num_repeats: int = 100,\n",
    "    num_warmups: int = 10,\n",
    "    synchronize: bool = True,\n",
    "    continuous_measure: bool = True,\n",
    ") -> float:\n",
    "\n",
    "    for _ in range(num_warmups):\n",
    "        _ = model.forward(input_tensor)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    elapsed_time_ms = 0\n",
    "\n",
    "    if continuous_measure:\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        start_event.record()\n",
    "        for _ in range(num_repeats):\n",
    "            _ = model.forward(input_tensor)\n",
    "        end_event.record()\n",
    "        if synchronize:\n",
    "            # This has to be synchronized to compute the elapsed time.\n",
    "            # Otherwise, there will be runtime error.\n",
    "            torch.cuda.synchronize()\n",
    "        elapsed_time_ms = start_event.elapsed_time(end_event)\n",
    "\n",
    "    else:\n",
    "        for _ in range(num_repeats):\n",
    "            start_event = torch.cuda.Event(enable_timing=True)\n",
    "            end_event = torch.cuda.Event(enable_timing=True)\n",
    "            start_event.record()\n",
    "            _ = model.forward(input_tensor)\n",
    "            end_event.record()\n",
    "            if synchronize:\n",
    "                # This has to be synchronized to compute the elapsed time.\n",
    "                # Otherwise, there will be runtime error.\n",
    "                torch.cuda.synchronize()\n",
    "            elapsed_time_ms += start_event.elapsed_time(end_event)\n",
    "\n",
    "    return elapsed_time_ms / num_repeats\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_inference(model: nn.Module, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "    return model.forward(input_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_grid_conf = {\n",
    "    \"xbound\": [-62.0, 62.0, 0.8],\n",
    "    \"ybound\": [-36.2, 36.2, 0.8],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 70.0, 1.0],\n",
    "}\n",
    "\n",
    "motion_grid_conf = {\n",
    "    \"xbound\": [-60.0, 60.0, 0.5],\n",
    "    \"ybound\": [-36.0, 36.0, 0.5],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 70.0, 1.0],\n",
    "}\n",
    "\n",
    "map_grid_conf = {\n",
    "    \"xbound\": [-30.0, 30.0, 0.15],\n",
    "    \"ybound\": [-15.0, 15.0, 0.15],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 70.0, 1.0],\n",
    "}\n",
    "\n",
    "----------\n",
    "det_grid_conf = {\n",
    "    \"xbound\": [-51.2, 51.2, 0.8],\n",
    "    \"ybound\": [-51.2, 51.2, 0.8],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}\n",
    "\n",
    "motion_grid_conf = {\n",
    "    \"xbound\": [-50.0, 50.0, 0.5],\n",
    "    \"ybound\": [-50.0, 50.0, 0.5],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}\n",
    "\n",
    "map_grid_conf = {\n",
    "    \"xbound\": [-30.0, 30.0, 0.15],\n",
    "    \"ybound\": [-15.0, 15.0, 0.15],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([240, 144,   1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_bounds, y_bounds,z_bounds=cfg[\"det_grid_conf\"][\"xbound\"],cfg[\"det_grid_conf\"][\"ybound\"],cfg[\"det_grid_conf\"][\"zbound\"]\n",
    "\n",
    "bev_dimension = torch.tensor(\n",
    "        [(row[1] - row[0]) / row[2] for row in [x_bounds, y_bounds, z_bounds]],\n",
    "        dtype=torch.long,\n",
    "    )\n",
    "bev_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240.7766990291262\n",
      "144.8\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for row in [x_bounds, y_bounds, z_bounds]:\n",
    "    print((row[1] - row[0]) / row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# det_grid_conf = {\n",
    "#     \"xbound\": [-62.0, 62.0, 0.37],#37\n",
    "#     \"ybound\": [-36.2, 36.2, 0.375],#37,5\n",
    "#     \"zbound\": [-10.0, 10.0, 20.0],\n",
    "#     \"dbound\": [1.0, 70.0, 1.0],\n",
    "# }\n",
    "\n",
    "# motion_grid_conf = {\n",
    "#     \"xbound\": [-60.0, 60.0, 0.25],\n",
    "#     \"ybound\": [-36.0, 36.0, 0.25],\n",
    "#     \"zbound\": [-10.0, 10.0, 20.0],\n",
    "#     \"dbound\": [1.0, 70.0, 1.0],\n",
    "# }\n",
    "\n",
    "# map_grid_conf = {\n",
    "#     \"xbound\": [-30.0, 30.0, 0.15],\n",
    "#     \"ybound\": [-15.0, 15.0, 0.15],\n",
    "#     \"zbound\": [-10.0, 10.0, 20.0],\n",
    "#     \"dbound\": [1.0, 70.0, 1.0],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_grid_conf = {\n",
    "    \"xbound\": [-51.2, 51.2, 0.2],\n",
    "    \"ybound\": [-51.2, 51.2, 0.2],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, .50],\n",
    "}\n",
    "\n",
    "motion_grid_conf = {\n",
    "    \"xbound\": [-50.0, 50.0, 0.125],\n",
    "    \"ybound\": [-50.0, 50.0, 0.125],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, .50],\n",
    "}\n",
    "\n",
    "map_grid_conf = {\n",
    "    \"xbound\": [-30.0, 30.0, 0.15],\n",
    "    \"ybound\": [-15.0, 15.0, 0.15],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, .50],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-25.6, 25.6, 0.1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i/2.0 for i in  [-51.2, 51.2, 0.2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects.mmdet3d_plugin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "det_grid_conf = {\n",
    "    \"xbound\": [-50.0, 50.0, 0.5],\n",
    "    \"ybound\": [-50.0, 50.0, 0.5],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}\n",
    "\n",
    "motion_grid_conf = {\n",
    "    \"xbound\": [-50.0, 50.0, 0.5],\n",
    "    \"ybound\": [-50.0, 50.0, 0.5],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, .50],\n",
    "}\n",
    "\n",
    "map_grid_conf = {\n",
    "    \"xbound\": [-50.0, 50.0, 0.5],\n",
    "    \"ybound\": [-50.0, 50.0, 0.5],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}\n",
    "\n",
    "point_cloud_range_base = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n",
    "point_cloud_range_extended_fustrum = [-62.0, -62.0, -5.0, 62.0, 62.0, 3.0]\n",
    "#motion_detr_tiny.py beverse_tiny_org.py\n",
    "\n",
    "cfg = import_modules_load_config(cfg_file=\"beverse_tiny_org.py\")\n",
    "\n",
    "cfg.data.train.dataset[\"data_root\"] = '/home/niklas/ETM_BEV/BEVerse/data/nuscenes'\n",
    "\n",
    "cfg = update_cfg(\n",
    "    cfg,det_grid_conf=det_grid_conf,grid_conf=det_grid_conf, map_grid_conf=map_grid_conf, motion_grid_conf=motion_grid_conf, point_cloud_range=point_cloud_range_extended_fustrum\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(cfg.data.test)  # build_dataset(cfg.data.train)\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    samples_per_gpu=2,\n",
    "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "    dist=False,\n",
    "    shuffle=False)\n",
    "\n",
    "sample = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CenterHeadv1\n",
      "CenterPointBBoxCoder\n",
      "ModuleList(\n",
      "  (0): SeparateHead(\n",
      "    (reg): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (height): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (dim): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (rot): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (vel): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (heatmap): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "  (1): SeparateHead(\n",
      "    (reg): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (height): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (dim): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (rot): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (vel): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (heatmap): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "  (2): SeparateHead(\n",
      "    (reg): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (height): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (dim): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (rot): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (vel): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (heatmap): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "  (3): SeparateHead(\n",
      "    (reg): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (height): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (dim): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (rot): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (vel): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (heatmap): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "  (4): SeparateHead(\n",
      "    (reg): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (height): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (dim): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (rot): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (vel): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (heatmap): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "  (5): SeparateHead(\n",
      "    (reg): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (height): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (dim): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (rot): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (vel): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (heatmap): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      ")\n",
      "MapHead\n",
      "BaseMotionHead\n",
      "Future Prediction\n",
      "IterativeFlow\n",
      "Future Prediction\n",
      "TASK DECODERS\n",
      "ModuleDict(\n",
      "  (3dod): CenterHeadv1(\n",
      "    (loss_cls): GaussianFocalLoss()\n",
      "    (loss_bbox): L1Loss()\n",
      "    (shared_conv): ConvModule(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activate): ReLU(inplace=True)\n",
      "    )\n",
      "    (task_heads): ModuleList(\n",
      "      (0): SeparateHead(\n",
      "        (reg): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (vel): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (heatmap): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "      (1): SeparateHead(\n",
      "        (reg): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (vel): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (heatmap): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "      (2): SeparateHead(\n",
      "        (reg): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (vel): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (heatmap): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "      (3): SeparateHead(\n",
      "        (reg): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (vel): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (heatmap): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "      (4): SeparateHead(\n",
      "        (reg): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (vel): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (heatmap): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "      (5): SeparateHead(\n",
      "        (reg): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (vel): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (heatmap): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "    )\n",
      "  )\n",
      "  (map): MapHead(\n",
      "    (task_heads): ModuleDict(\n",
      "      (semantic_seg): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (semantic_seg_criterion): SegmentationLoss()\n",
      "  )\n",
      "  (motion): IterativeFlow(\n",
      "    (task_heads): ModuleDict(\n",
      "      (segmentation): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (instance_center): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (instance_offset): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (instance_flow): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (present_distribution): SpatialDistributionModule(\n",
      "      (encoder): DistributionEncoder(\n",
      "        (model): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (layers): Sequential(\n",
      "              (conv_down_project): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_down_project): Sequential(\n",
      "                (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (abn): Sequential(\n",
      "                (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv_up_project): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_up_project): Sequential(\n",
      "                (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
      "            )\n",
      "            (projection): Sequential(\n",
      "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "              (conv_skip_proj): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn_skip_proj): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (layers): Sequential(\n",
      "              (conv_down_project): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_down_project): Sequential(\n",
      "                (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (abn): Sequential(\n",
      "                (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv_up_project): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_up_project): Sequential(\n",
      "                (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
      "            )\n",
      "            (projection): Sequential(\n",
      "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "              (conv_skip_proj): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn_skip_proj): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (last_conv): Sequential(\n",
      "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (future_distribution): SpatialDistributionModule(\n",
      "      (encoder): DistributionEncoder(\n",
      "        (model): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (layers): Sequential(\n",
      "              (conv_down_project): Conv2d(274, 137, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_down_project): Sequential(\n",
      "                (0): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv): Conv2d(137, 137, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (abn): Sequential(\n",
      "                (0): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv_up_project): Conv2d(137, 137, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_up_project): Sequential(\n",
      "                (0): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
      "            )\n",
      "            (projection): Sequential(\n",
      "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "              (conv_skip_proj): Conv2d(274, 137, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn_skip_proj): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (layers): Sequential(\n",
      "              (conv_down_project): Conv2d(137, 68, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_down_project): Sequential(\n",
      "                (0): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv): Conv2d(68, 68, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (abn): Sequential(\n",
      "                (0): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv_up_project): Conv2d(68, 137, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_up_project): Sequential(\n",
      "                (0): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
      "            )\n",
      "            (projection): Sequential(\n",
      "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "              (conv_skip_proj): Conv2d(137, 137, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn_skip_proj): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (last_conv): Sequential(\n",
      "        (0): Conv2d(137, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (future_prediction): ResFuturePrediction(\n",
      "      (offset_conv): ConvBlock(\n",
      "        (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (offset_pred): Conv2d(288, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (gru_cells): ModuleList(\n",
      "        (0): GRUCell(\n",
      "          (conv_update): Conv2d(544, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv_reset): Conv2d(544, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv_state_tilde): ConvBlock(\n",
      "            (conv): Conv2d(544, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activation): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (spatial_conv): ConvBlock(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (seg_criterion): MotionSegmentationLoss()\n",
      "    (reg_instance_center_criterion): SpatialRegressionLoss()\n",
      "    (cls_instance_center_criterion): GaussianFocalLoss(\n",
      "      (gaussian_focal_loss): GaussianFocalLoss()\n",
      "    )\n",
      "    (reg_instance_offset_criterion): SpatialRegressionLoss()\n",
      "    (reg_instance_flow_criterion): SpatialRegressionLoss()\n",
      "    (probabilistic_loss): ProbabilisticLoss()\n",
      "  )\n",
      ")\n",
      "------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "load_external_weights=False\n",
    "\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'),\n",
    "                    test_cfg=cfg.get('test_cfg'))\n",
    "if load_external_weights:\n",
    "    \n",
    "    cfg.checkpoint_config.meta = dict(\n",
    "        mmdet_version=mmdet_version,\n",
    "        mmseg_version=mmseg_version,\n",
    "        mmdet3d_version=mmdet3d_version,\n",
    "        config=cfg.pretty_text,\n",
    "        CLASSES=dataset.CLASSES,\n",
    "        PALETTE=dataset.PALETTE  # for segmentors\n",
    "        if hasattr(dataset, 'PALETTE') else None)\n",
    "    \n",
    "    weights_tiny = torch.load(\n",
    "        \"/home/niklas/ETM_BEV/BEVerse/weights/clean_weights_tiny.pth\")\n",
    "    \n",
    "    search_weights = tuple(weights_tiny.keys())\n",
    "    state_dict_detr = model.state_dict()\n",
    "    for k in state_dict_detr.keys():\n",
    "        if k in search_weights:\n",
    "            try:\n",
    "                state_dict_detr[k] = weights_tiny[k].clone()\n",
    "            except Exception as e:\n",
    "                print(f\"Failure for {k}, exception {e}\")\n",
    "\n",
    "\n",
    "wrap_fp16_model(model)\n",
    "model.cuda()\n",
    "model = MMDataParallel(model, device_ids=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mmcv.parallel.data_parallel.MMDataParallel"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "for k,v in model.named_parameters():\n",
    "    print(type(k))\n",
    "    print(type(v))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in model.named_parameters():\n",
    "    if v.grad is not None:\n",
    "        print(k)\n",
    "        print(type(v.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting t+1\n",
      "Predicting t+2\n",
      "Predicting t+3\n",
      "['present_mu', 'present_log_sigma', 'future_mu', 'future_log_sigma', 'segmentation', 'instance_center', 'instance_offset', 'instance_flow']\n",
      "MTL Head Inf\n",
      "MTL Head Inf 3dod\n",
      "get_BBoxes\n",
      "Decode Centerpoint BBoxcoders\n",
      "get_task_detections\n",
      "Decode Centerpoint BBoxcoders\n",
      "get_task_detections\n",
      "Decode Centerpoint BBoxcoders\n",
      "get_task_detections\n",
      "Decode Centerpoint BBoxcoders\n",
      "Decode Centerpoint BBoxcoders\n",
      "get_task_detections\n",
      "Decode Centerpoint BBoxcoders\n",
      "get_task_detections\n",
      "MTL Head Inf map\n",
      "MTL Head Inf motion\n",
      "predict_instance_segmentation_and_trajectories\n",
      "preds seg torch.Size([2, 4, 2, 200, 200])\n",
      "preds seg argmax torch.Size([2, 4, 1, 200, 200])\n",
      "foreground_masksx torch.Size([2, 4, 200, 200])\n",
      "pred_instance_t torch.Size([1, 200, 200]), centers torch.Size([100, 2])\n",
      "pred_instance_t torch.Size([1, 200, 200]), centers torch.Size([100, 2])\n",
      "pred_instance_t torch.Size([1, 200, 200]), centers torch.Size([100, 2])\n",
      "pred_instance_t torch.Size([1, 200, 200]), centers torch.Size([100, 2])\n",
      "pred_instance_t torch.Size([1, 200, 200]), centers torch.Size([100, 2])\n",
      "pred_instance_t torch.Size([1, 200, 200]), centers torch.Size([100, 2])\n",
      "pred_instance_t torch.Size([1, 200, 200]), centers torch.Size([100, 2])\n",
      "pred_instance_t torch.Size([1, 200, 200]), centers torch.Size([100, 2])\n",
      "consistent_instance_seg torch.Size([1, 4, 200, 200])\n",
      "consistent_instance_seg torch.Size([1, 4, 200, 200])\n"
     ]
    }
   ],
   "source": [
    "logger.debug(cfg[\"det_grid_conf\"])\n",
    "logger.debug(cfg[\"motion_grid_conf\"])\n",
    "logger.debug(cfg[\"map_grid_conf\"])\n",
    "\n",
    "\n",
    "bev_resolution, bev_start_position, bev_dimension = calculate_birds_eye_view_parameters(\n",
    "    cfg[\"det_grid_conf\"][\"xbound\"], cfg[\"det_grid_conf\"][\"ybound\"], cfg[\"det_grid_conf\"][\"zbound\"])\n",
    "logger.debug(f\"bev_resolution: {bev_resolution}\")\n",
    "logger.debug(f\"bev_start_position: {bev_start_position}\")\n",
    "logger.debug(f\"bev_dimension: {bev_dimension}\")\n",
    "\n",
    "\n",
    "motion_distribution_targets = {\n",
    "    # for motion prediction\n",
    "    'motion_segmentation': sample['motion_segmentation'][0],\n",
    "    'motion_instance': sample['motion_instance'][0],\n",
    "    'instance_centerness': sample['instance_centerness'][0],\n",
    "    'instance_offset': sample['instance_offset'][0],\n",
    "    'instance_flow': sample['instance_flow'][0],\n",
    "    'future_egomotion': sample['future_egomotions'][0],\n",
    "}\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    result = model(\n",
    "        return_loss=False,\n",
    "        rescale=True,\n",
    "        img_metas=sample['img_metas'],\n",
    "        img_inputs=sample['img_inputs'],\n",
    "        future_egomotions=sample['future_egomotions'],\n",
    "        motion_targets=motion_distribution_targets,\n",
    "        img_is_valid=sample['img_is_valid'][0],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict_keys(['img_metas', 'img_inputs', 'semantic_indices', 'semantic_map', 'future_egomotions', 'gt_bboxes_3d', 'gt_labels_3d', 'motion_segmentation', 'motion_instance', 'instance_centerness', 'instance_offset', 'instance_flow', 'has_invalid_frame', 'img_is_valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 200, 200])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"instance_flow\"][0][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 1, 200, 200])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"instance_centerness\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 2, 200, 200])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"instance_offset\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 2, 200, 200])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"instance_flow\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 200, 200])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"motion_segmentation\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 6])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"future_egomotions\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200, 200])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"semantic_indices\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 200, 200])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"semantic_map\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"gt_labels_3d\"][0].data[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'bev',\n",
    "* 'bottom_center',\n",
    "* 'bottom_height',\n",
    "* 'box_dim',\n",
    "* 'cat',\n",
    "* 'center',\n",
    "* 'clone',\n",
    "* 'convert_to',\n",
    "* 'corners',\n",
    "* 'device',\n",
    "* 'dims',\n",
    "* 'enlarged_box',\n",
    "* 'flip',\n",
    "* 'gravity_center',\n",
    "* 'height',\n",
    "* 'height_overlaps',\n",
    "* 'in_range_3d',\n",
    "* 'in_range_bev',\n",
    "* 'limit_yaw',\n",
    "* 'nearest_bev',\n",
    "* 'new_box',\n",
    "* 'nonempty',\n",
    "* 'overlaps',\n",
    "* 'points_in_boxes',\n",
    "* 'rotate',\n",
    "* 'scale',\n",
    "* 'tensor',\n",
    "* 'to',\n",
    "* 'top_height',\n",
    "* 'translate',\n",
    "* 'volume',\n",
    "* 'with_yaw',\n",
    "* 'yaw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"gt_bboxes_3d\"][0].data[0][0].nearest_bev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 3, 4, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_tiny['img_backbone.patch_embed.projection.weight'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 3, 4, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict_detr['img_backbone.patch_embed.projection.weight'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSFreeCoder\n",
      "MapHead\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# checkpoint = load_checkpoint(\n",
    "#     model, r\"/home/niklas/ETM_BEV/BEVerse/weights/clean_weights_tiny.pth\", map_location='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = build_model(cfg.model, test_cfg=cfg.get(\"test_cfg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 24\u001b[0m\n\u001b[1;32m     12\u001b[0m motion_distribution_targets \u001b[39m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m     \u001b[39m# for motion prediction\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmotion_segmentation\u001b[39m\u001b[39m'\u001b[39m: sample[\u001b[39m'\u001b[39m\u001b[39mmotion_segmentation\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfuture_egomotion\u001b[39m\u001b[39m'\u001b[39m: sample[\u001b[39m'\u001b[39m\u001b[39mfuture_egomotions\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m],\n\u001b[1;32m     20\u001b[0m }\n\u001b[1;32m     23\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 24\u001b[0m     result \u001b[39m=\u001b[39m model(\n\u001b[1;32m     25\u001b[0m         return_loss\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     26\u001b[0m         rescale\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     27\u001b[0m         img_metas\u001b[39m=\u001b[39;49msample[\u001b[39m'\u001b[39;49m\u001b[39mimg_metas\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     28\u001b[0m         img_inputs\u001b[39m=\u001b[39;49msample[\u001b[39m'\u001b[39;49m\u001b[39mimg_inputs\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     29\u001b[0m         future_egomotions\u001b[39m=\u001b[39;49msample[\u001b[39m'\u001b[39;49m\u001b[39mfuture_egomotions\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     30\u001b[0m         motion_targets\u001b[39m=\u001b[39;49mmotion_distribution_targets,\n\u001b[1;32m     31\u001b[0m         img_is_valid\u001b[39m=\u001b[39;49msample[\u001b[39m'\u001b[39;49m\u001b[39mimg_is_valid\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m],\n\u001b[1;32m     32\u001b[0m     )\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/mmcv/parallel/data_parallel.py:42\u001b[0m, in \u001b[0;36mMMDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule(\u001b[39m*\u001b[39minputs[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs[\u001b[39m0\u001b[39m])\n\u001b[1;32m     41\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:166\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m     kwargs \u001b[39m=\u001b[39m ({},)\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule(\u001b[39m*\u001b[39;49minputs[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    167\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[:\u001b[39mlen\u001b[39m(inputs)])\n\u001b[1;32m    168\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel_apply(replicas, inputs, kwargs)\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py:128\u001b[0m, in \u001b[0;36mauto_fp16.<locals>.auto_fp16_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m (TORCH_VERSION \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mparrots\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         digit_version(TORCH_VERSION) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m digit_version(\u001b[39m'\u001b[39m\u001b[39m1.6.0\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[1;32m    127\u001b[0m     \u001b[39mwith\u001b[39;00m autocast(enabled\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 128\u001b[0m         output \u001b[39m=\u001b[39m old_func(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m    129\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     output \u001b[39m=\u001b[39m old_func(\u001b[39m*\u001b[39mnew_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n",
      "File \u001b[0;32m~/ETM_BEV/BEVerse/mmdet3d/models/detectors/base.py:61\u001b[0m, in \u001b[0;36mBase3DDetector.forward\u001b[0;34m(self, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_train(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     60\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_test(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/ETM_BEV/BEVerse/projects/mmdet3d_plugin/models/detectors/beverse_motion_detr_ext.py:366\u001b[0m, in \u001b[0;36mBEVerse_Motion_DETR.forward_test\u001b[0;34m(self, points, img_metas, img_inputs, future_egomotions, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(img_inputs[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m):\n\u001b[1;32m    365\u001b[0m     img_inputs \u001b[39m=\u001b[39m [img_inputs] \u001b[39mif\u001b[39;00m img_inputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m img_inputs\n\u001b[0;32m--> 366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimple_test(\n\u001b[1;32m    367\u001b[0m         img_metas[\u001b[39m0\u001b[39;49m], img_inputs[\u001b[39m0\u001b[39;49m], future_egomotions[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    368\u001b[0m     )\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maug_test(\n\u001b[1;32m    371\u001b[0m         img_metas[\u001b[39m0\u001b[39m], img_inputs[\u001b[39m0\u001b[39m], future_egomotions[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    372\u001b[0m     )\n",
      "File \u001b[0;32m~/ETM_BEV/BEVerse/projects/mmdet3d_plugin/models/detectors/beverse_motion_detr_ext.py:397\u001b[0m, in \u001b[0;36mBEVerse_Motion_DETR.simple_test\u001b[0;34m(self, img_metas, img, future_egomotions, rescale, motion_targets, img_is_valid)\u001b[0m\n\u001b[1;32m    395\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39msynchronize()\n\u001b[1;32m    396\u001b[0m end \u001b[39m=\u001b[39m timer()\n\u001b[0;32m--> 397\u001b[0m time_stats[\u001b[39m\"\u001b[39;49m\u001b[39mExtract_img_feat_total\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m=\u001b[39m (end \u001b[39m-\u001b[39m start) \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m    399\u001b[0m t_Extract_img_feat_total \u001b[39m=\u001b[39m (end \u001b[39m-\u001b[39m start) \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m    400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    401\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mBEVerse Extract_img_feat_total \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m     \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(t_Extract_img_feat_total)\n\u001b[1;32m    403\u001b[0m )  \u001b[39m# str(t_Extract_img_feat_total)        )\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 3"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'device_ids',\n",
       " 'dim',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'gather',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'load_state_dict',\n",
       " 'module',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'output_device',\n",
       " 'parallel_apply',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_parameter',\n",
       " 'replicate',\n",
       " 'requires_grad_',\n",
       " 'scatter',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'src_device_obj',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'train_step',\n",
       " 'training',\n",
       " 'type',\n",
       " 'val_step',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_dump_init_info',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_is_init',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_parse_losses',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'aforward_test',\n",
       " 'apply',\n",
       " 'async_simple_test',\n",
       " 'aug_test',\n",
       " 'aug_test_pts',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'combine_bev_output',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'data_aug_conf',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'extract_feat',\n",
       " 'extract_feats',\n",
       " 'extract_img_feat',\n",
       " 'extract_img_feat_tta',\n",
       " 'extract_pts_feat',\n",
       " 'flip_bev_output',\n",
       " 'flip_feature',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'forward_dummy',\n",
       " 'forward_img_train',\n",
       " 'forward_pts_train',\n",
       " 'forward_test',\n",
       " 'forward_train',\n",
       " 'fp16_enabled',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'img_backbone',\n",
       " 'img_neck',\n",
       " 'init_cfg',\n",
       " 'init_weights',\n",
       " 'is_init',\n",
       " 'load_state_dict',\n",
       " 'logger',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'onnx_export',\n",
       " 'parameters',\n",
       " 'pts_bbox_head',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'show_result',\n",
       " 'show_results',\n",
       " 'simple_test',\n",
       " 'simple_test_img',\n",
       " 'simple_test_pts',\n",
       " 'simple_test_rpn',\n",
       " 'state_dict',\n",
       " 'temporal_model',\n",
       " 'test_cfg',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'train_cfg',\n",
       " 'train_step',\n",
       " 'training',\n",
       " 'transformer',\n",
       " 'type',\n",
       " 'val_step',\n",
       " 'voxelize',\n",
       " 'with_bbox',\n",
       " 'with_fusion',\n",
       " 'with_img_backbone',\n",
       " 'with_img_bbox',\n",
       " 'with_img_neck',\n",
       " 'with_img_roi_head',\n",
       " 'with_img_rpn',\n",
       " 'with_img_shared_head',\n",
       " 'with_mask',\n",
       " 'with_middle_encoder',\n",
       " 'with_neck',\n",
       " 'with_pts_backbone',\n",
       " 'with_pts_bbox',\n",
       " 'with_pts_neck',\n",
       " 'with_shared_head',\n",
       " 'with_voxel_encoder',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pred_semantic_indices', 'motion_predictions', 'motion_segmentation', 'motion_instance', 'bbox_results', 'time_stats'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boxes_3d', 'scores_3d', 'labels_3d'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"bbox_results\"][0][\"pts_bbox\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scores_3d - torch.Size([498])\n",
    "labels_3d - torch.Size([498])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([498])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['bbox_results'][0]['pts_bbox'][\"labels_3d\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 'bev', torch.Size([498, 5])\n",
    " 'bottom_center', torch.Size([498, 3])\n",
    " 'bottom_height', torch.Size([498])\n",
    " 'box_dim', 9 \n",
    " 'cat',\n",
    " 'center', orch.Size([498, 3])\n",
    " 'clone',\n",
    " 'convert_to',\n",
    " 'corners',\n",
    " 'device',\n",
    " 'dims',\n",
    " 'enlarged_box',\n",
    " 'flip',\n",
    " 'gravity_center', torch.Size([498, 3])\n",
    " 'height', torch.Size([498])\n",
    " 'height_overlaps',\n",
    " 'in_range_3d',\n",
    " 'in_range_bev',\n",
    " 'limit_yaw',\n",
    " 'nearest_bev',\n",
    " 'new_box',\n",
    " 'nonempty',\n",
    " 'overlaps',\n",
    " 'points_in_boxes',\n",
    " 'rotate',\n",
    " 'scale',\n",
    " 'tensor',\n",
    " 'to',\n",
    " 'top_height',\n",
    " 'translate',\n",
    " 'volume', torch.Size([498])\n",
    " 'with_yaw',\n",
    " 'yaw']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image (T: 3 H: 65 W: 178) smaller than kernel size (kT: 2 kH: 128 kW: 128)\n",
    "\n",
    "\n",
    "update\n",
    "pyramid pooling:  torch.Size([1, 70, 3, 128, 128])\n",
    "x_pool:  torch.Size([1, 23, 3, 1, 1])\n",
    "c:  23\n",
    "x_pool2:  torch.Size([3, 23, 128, 128])\n",
    "x_pool3:  torch.Size([1, 23, 3, 128, 128])\n",
    "update\n",
    "pyramid pooling:  torch.Size([1, 64, 3, 128, 128])\n",
    "x_pool:  torch.Size([1, 21, 3, 1, 1])\n",
    "c:  21\n",
    "x_pool2:  torch.Size([3, 21, 128, 128])\n",
    "x_pool3:  torch.Size([1, 21, 3, 128, 128])\n",
    "feats-1: torch.Size([1, 512, 25, 50]), feats-3: torch.Size([1, 128, 100, 200])\n",
    "Up: x1 torch.Size([1, 512, 100, 200]), x2 torch.Size([1, 128, 100, 200])\n",
    "feats-1: torch.Size([1, 512, 16, 16]), feats-3: torch.Size([1, 128, 64, 64])\n",
    "Up: x1 torch.Size([1, 512, 64, 64]), x2 torch.Size([1, 128, 64, 64])\n",
    "feats-1: torch.Size([1, 512, 25, 25]), feats-3: torch.Size([1, 128, 100, 100])\n",
    "Up: x1 torch.Size([1, 512, 100, 100]), x2 torch.Size([1, 128, 100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"IMAGE\": {\n",
    "    \"ORIGINAL_HEIGHT\": 900,\n",
    "    \"ORIGINAL_WIDTH\": 1600,\n",
    "    \"FINAL_DIM\": (512, 1408),\n",
    "    \"RESIZE_SCALE\": 0.25,\n",
    "    \"TOP_CROP\": 0,\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['IMAGE'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero padding left and right parts of the image.\n",
      "Zero padding bottom part of the image.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'scale_width': 0.25,\n",
       " 'scale_height': 0.25,\n",
       " 'resize_dims': (400, 225),\n",
       " 'crop': (0, 0, 1408, 512)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_resizing_and_cropping_parameters(config):\n",
    "    original_height, original_width = config[\"IMAGE\"][\"ORIGINAL_HEIGHT\"], config[\"IMAGE\"][\"ORIGINAL_WIDTH\"]\n",
    "    final_height, final_width = config[\"IMAGE\"][\"FINAL_DIM\"]\n",
    "\n",
    "    resize_scale = config[\"IMAGE\"][\"RESIZE_SCALE\"]\n",
    "    resize_dims = (int(original_width * resize_scale), int(original_height * resize_scale))\n",
    "    resized_width, resized_height = resize_dims\n",
    "\n",
    "    crop_h = config[\"IMAGE\"][\"TOP_CROP\"]\n",
    "    crop_w = int(max(0, (resized_width - final_width) / 2))\n",
    "    # Left, top, right, bottom crops.\n",
    "    crop = (crop_w, crop_h, crop_w + final_width, crop_h + final_height)\n",
    "\n",
    "    if resized_width != final_width:\n",
    "        print('Zero padding left and right parts of the image.')\n",
    "    if crop_h + final_height != resized_height:\n",
    "        print('Zero padding bottom part of the image.')\n",
    "\n",
    "    return {'scale_width': resize_scale,\n",
    "            'scale_height': resize_scale,\n",
    "            'resize_dims': resize_dims,\n",
    "            'crop': crop,\n",
    "            }\n",
    "get_resizing_and_cropping_parameters(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t_BEV': 1663055717.0110373,\n",
       " 't_temporal': 1663055717.5791538,\n",
       " 't0': 1663055712.6830127,\n",
       " 't_end': 1663055746.884341}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"time_stats\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x, rots, trans, intrins, post_rots, post_trans = input\n",
    "\n",
    "'CAM_FRONT_RIGHT': {\n",
    "    'data_path': './data/nuscenes/samples/CAM_FRONT_RIGHT/n015-2018-10-08-15-36-50+0800__CAM_FRONT_RIGHT__1538984233520339.jpg', \n",
    "    'type': 'CAM_FRONT_RIGHT', \n",
    "    'sample_data_token': 'd6f89460954c43d39ed7c9ac91ab03d0', \n",
    "    'sensor2ego_translation': [1.5508477543, -0.493404796419, 1.49574800619], \n",
    "    'sensor2ego_rotation': [0.2060347966337182, -0.2026940577919598, 0.6824507824531167, -0.6713610884174485], 'ego2global_translation': [715.6566537856895, 1810.1516804263824, 0.0], \n",
    "    'ego2global_rotation': [0.8004835927391405, 0.00541081062084495, -0.0028680900818508943, -0.5993233809414961], 'timestamp': 1538984233520339, \n",
    "    'sensor2lidar_rotation': array([[ 0.55971752, -0.01057234,  0.82861603],\n",
    "       [-0.82828535,  0.02385392,  0.55979851],\n",
    "       [-0.02568412, -0.99965955,  0.00459454]]), \n",
    "    'sensor2lidar_translation': array([ 0.48135698,  0.51094805, -0.32997566]), \n",
    "    'cam_intrinsic': array([[1.26084744e+03, 0.00000000e+00, 8.07968245e+02],\n",
    "       [0.00000000e+00, 1.26084744e+03, 4.95334427e+02],\n",
    "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future Egomotions:  torch.Size([1, 7, 6])\n",
      "img_is_valid:  torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "num_warmups = 100\n",
    "num_repeats = 1000\n",
    "# Change to C x 1 x 3 x 1600 x 900\n",
    "# 704×256 Tiny\n",
    "# 1408×512\n",
    "# B, S, N, C, imH, imW = imgs.shape\n",
    "img_inputs =  torch.rand(1,7,6,3,704,256).cuda()\n",
    "# (batch, seq, num_cam)\n",
    "future_egomotions = torch.zeros((batch_size, 7, 6)).type_as(img_inputs).cuda()\n",
    "img_is_valid = torch.ones((batch_size, 7)).type_as(img_inputs) > 0\n",
    "img_is_valid.cuda()\n",
    "print(\"Future Egomotions: \", future_egomotions.shape)\n",
    "print(\"img_is_valid: \", img_is_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #single frame \n",
    "# future_egomotions = future_egomotions[:, :1]\n",
    "# img_is_valid = img_is_valid[:, :1]\n",
    "# print(\"Future Egomotions: \", future_egomotions.shape)\n",
    "# print(\"img_is_valid: \", img_is_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([3])\n",
      "image meta: [{'box_type_3d': <class 'mmdet3d.core.bbox.structures.lidar_box3d.LiDARInstance3DBoxes'>, 'lidar2ego_rots': tensor([[-5.4280e-04,  9.9893e-01,  4.6229e-02],\n",
      "        [-1.0000e+00, -4.0569e-04, -2.9750e-03],\n",
      "        [-2.9531e-03, -4.6231e-02,  9.9893e-01]]), 'lidar2ego_trans': tensor([0.9858, 0.0000, 1.8402])}]\n"
     ]
    }
   ],
   "source": [
    "from mmdet3d.core.bbox.structures.box_3d_mode import LiDARInstance3DBoxes\n",
    "\n",
    "dummy_lidar2ego_rots = (\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [-5.4280e-04, 9.9893e-01, 4.6229e-02],\n",
    "            [-1.0000e00, -4.0569e-04, -2.9750e-03],\n",
    "            [-2.9531e-03, -4.6231e-02, 9.9893e-01],\n",
    "        ]\n",
    "    )\n",
    "    .type_as(img_inputs)\n",
    "    .cpu()\n",
    ")\n",
    "dummy_lidar2ego_trans = (\n",
    "    torch.tensor([0.9858, 0.0000, 1.8402]).type_as(img_inputs).cpu()\n",
    ")\n",
    "print(dummy_lidar2ego_rots.shape)\n",
    "print(dummy_lidar2ego_trans.shape)\n",
    "img_metas = [\n",
    "    dict(\n",
    "        box_type_3d=LiDARInstance3DBoxes,\n",
    "        lidar2ego_rots=dummy_lidar2ego_rots,\n",
    "        lidar2ego_trans=dummy_lidar2ego_trans,\n",
    "    )\n",
    "]\n",
    "print(\"image meta:\", img_metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'projects.mmdet3d_plugin.models.detectors.beverse.BEVerse'>\n"
     ]
    }
   ],
   "source": [
    "model = build_model(cfg.model, test_cfg=cfg.get(\"test_cfg\"))\n",
    "print(type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch?:  torch.Size([1, 7, 6, 3, 704, 256])\n",
      "B 1, S 7, 6, C 3, imH 704, imW 256\n",
      "imgs  torch.Size([42, 3, 704, 256])\n",
      "after backbone:  2\n",
      "shape in list:  [torch.Size([42, 384, 44, 16]), torch.Size([42, 768, 22, 8])]\n",
      "after backbone with_img_neck:  torch.Size([42, 512, 44, 16])\n",
      "after transformation:  torch.Size([1, 7, 6, 512, 44, 16])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"Tensor\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(cfg\u001b[38;5;241m.\u001b[39mmodel, test_cfg\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_cfg\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      2\u001b[0m wrap_fp16_model(model)\n\u001b[0;32m----> 3\u001b[0m img_feats,time_dict  \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_img_feat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimg_metas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_metas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfuture_egomotion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_egomotions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimg_is_valid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_is_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(img_feats\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(time_dict)\n",
      "File \u001b[0;32m~/ETM_BEV/BEVerse/projects/mmdet3d_plugin/models/detectors/beverse.py:105\u001b[0m, in \u001b[0;36mBEVerse.extract_img_feat\u001b[0;34m(self, img, img_metas, future_egomotion, aug_transform, img_is_valid, count_time)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mafter transformation: \u001b[39m\u001b[39m\"\u001b[39m, x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    104\u001b[0m \u001b[39m# lifting with LSS\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer([x] \u001b[39m+\u001b[39;49m img[\u001b[39m1\u001b[39;49m:])\n\u001b[1;32m    107\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39msynchronize()\n\u001b[1;32m    108\u001b[0m t_BEV \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"Tensor\") to list"
     ]
    }
   ],
   "source": [
    "model = build_model(cfg.model, test_cfg=cfg.get(\"test_cfg\")).cuda()\n",
    "wrap_fp16_model(model)\n",
    "img_feats,time_dict  = model.extract_img_feat(\n",
    "            img=img_inputs,\n",
    "            img_metas=img_metas,\n",
    "            future_egomotion=future_egomotions,\n",
    "            img_is_valid=img_is_valid,\n",
    "        )\n",
    "print(img_feats.shape)\n",
    "print(time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2000,  0.2000, 20.0000]) tensor([-51.1000, -51.1000,   0.0000]) tensor([512, 512,   1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_362/3561629359.py:21: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  bev_dimension = torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "# 'xbound': [-51.2, 51.2, 0.2], 'ybound': [-51.2, 51.2, 0.2], 'zbound': [-10.0, 10.0, 20.0], 'dbound': [1.0, 60.0, 0.5]}\n",
    "\n",
    "\n",
    "\n",
    "x_bounds, y_bounds, z_bounds = [-51.2, 51.2, 0.2], [-51.2, 51.2, 0.2], [-10.0, 10.0, 20.0]\n",
    "\n",
    "bev_resolution, bev_start_position, bev_dimension = calculate_birds_eye_view_parameters(x_bounds, y_bounds, z_bounds)\n",
    "\n",
    "print(bev_resolution, bev_start_position, bev_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "x_bounds, y_bounds, z_bounds = [-26.2, 26.2, 0.8], [-71.2, 71.2, 0.8], [-10.0, 10.0, 20.0]\n",
    "tensor([ 0.8000,  0.8000, 20.0000]) tensor([-25.8000, -70.8000,   0.0000]) tensor([ 65, 178,   1])\n",
    "\n",
    "\n",
    "x_bounds, y_bounds, z_bounds = [-26.2, 26.2, 0.4], [-71.2, 71.2, 0.4], [-10.0, 10.0, 20.0]\n",
    "tensor([ 0.4000,  0.4000, 20.0000]) tensor([-26., -71.,   0.]) tensor([131, 356,   1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0, 7, 6, 3, 704, 256])\n",
      "torch.Size([1, 7, 6, 3, 704, 256])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"Tensor\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m img_inputs \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m704\u001b[39m,\u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(img_inputs[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 6\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtrans_output\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m test\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"Tensor\") to list"
     ]
    }
   ],
   "source": [
    "img_inputs =  torch.rand(1,7,6,3,704,256)\n",
    "print(img_inputs[1:].shape)\n",
    "trans_output = torch.rand(1, 7, 6, 512, 44, 16)\n",
    "img_inputs =  torch.rand(2,7,6,3,704,256)\n",
    "print(img_inputs[1:].shape)\n",
    "test = [trans_output] + img_inputs[1:]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency Measurement Using CPU Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: N/A     ms| \n",
      "Latency Measurement Using CUDA Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: N/A     ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: N/A     ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: N/A     ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: N/A     ms| \n",
      "Latency Measurement Using PyTorch Benchmark...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dummy_input.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 95\u001b[0m\n\u001b[1;32m     85\u001b[0m num_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     86\u001b[0m timer \u001b[38;5;241m=\u001b[39m benchmark\u001b[38;5;241m.\u001b[39mTimer(\n\u001b[1;32m     87\u001b[0m     stmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_inference(model, input_tensor)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m     setup\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom __main__ import run_inference\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m     sub_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.utils.benchmark.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     93\u001b[0m )\n\u001b[0;32m---> 95\u001b[0m profile_result \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_repeats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# https://pytorch.org/docs/stable/_modules/torch/utils/benchmark/utils/common.html#Measurement\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatency: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprofile_result\u001b[38;5;241m.\u001b[39mmean \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/torch/utils/benchmark/utils/timer.py:261\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39m\"\"\"Mirrors the semantics of timeit.Timer.timeit().\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \n\u001b[1;32m    256\u001b[0m \u001b[39mExecute the main statement (`stmt`) `number` times.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[39mhttps://docs.python.org/3/library/timeit.html#timeit.Timer.timeit\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39mwith\u001b[39;00m common\u001b[39m.\u001b[39mset_torch_threads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_spec\u001b[39m.\u001b[39mnum_threads):\n\u001b[1;32m    260\u001b[0m     \u001b[39m# Warmup\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timer\u001b[39m.\u001b[39;49mtimeit(number\u001b[39m=\u001b[39;49m\u001b[39mmax\u001b[39;49m(\u001b[39mint\u001b[39;49m(number \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m100\u001b[39;49m), \u001b[39m2\u001b[39;49m))\n\u001b[1;32m    263\u001b[0m     \u001b[39mreturn\u001b[39;00m common\u001b[39m.\u001b[39mMeasurement(\n\u001b[1;32m    264\u001b[0m         number_per_run\u001b[39m=\u001b[39mnumber,\n\u001b[1;32m    265\u001b[0m         raw_times\u001b[39m=\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timer\u001b[39m.\u001b[39mtimeit(number\u001b[39m=\u001b[39mnumber)],\n\u001b[1;32m    266\u001b[0m         task_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_spec\n\u001b[1;32m    267\u001b[0m     )\n",
      "File \u001b[0;32m/usr/lib/python3.8/timeit.py:177\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    175\u001b[0m gc\u001b[39m.\u001b[39mdisable()\n\u001b[1;32m    176\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     timing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(it, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimer)\n\u001b[1;32m    178\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[39mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<timeit-src>:6\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn [15], line 89\u001b[0m, in \u001b[0;36mrun_inference\u001b[0;34m(model, input_tensor)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_inference\u001b[39m(model: nn\u001b[38;5;241m.\u001b[39mModule, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# from model.forward because BEVerse differentiates between different input types - img lidar etc \u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_dummy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ETM_BEV/BEVerse/projects/mmdet3d_plugin/models/detectors/beverse.py:209\u001b[0m, in \u001b[0;36mforward_dummy\u001b[0;34m(self, img_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39m\"\"\"Forward training function.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \n\u001b[1;32m    169\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39m    dict: Losses of different branches.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    193\u001b[0m img_feats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_img_feat(\n\u001b[1;32m    194\u001b[0m     img\u001b[39m=\u001b[39mimg_inputs,\n\u001b[1;32m    195\u001b[0m     img_metas\u001b[39m=\u001b[39mimg_metas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m     img_is_valid\u001b[39m=\u001b[39mimg_is_valid,\n\u001b[1;32m    199\u001b[0m )\n\u001b[1;32m    201\u001b[0m mtl_targets \u001b[39m=\u001b[39m {\n\u001b[1;32m    202\u001b[0m     \u001b[39m# for detection\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgt_bboxes_3d\u001b[39m\u001b[39m\"\u001b[39m: gt_bboxes_3d,\n\u001b[1;32m    204\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgt_labels_3d\u001b[39m\u001b[39m\"\u001b[39m: gt_labels_3d,\n\u001b[1;32m    205\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgt_bboxes_ignore\u001b[39m\u001b[39m\"\u001b[39m: gt_bboxes_ignore,\n\u001b[1;32m    206\u001b[0m     \u001b[39m# for map segmentation\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msemantic_seg\u001b[39m\u001b[39m\"\u001b[39m: semantic_indices,\n\u001b[1;32m    208\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msemantic_map\u001b[39m\u001b[39m\"\u001b[39m: semantic_map,\n\u001b[0;32m--> 209\u001b[0m     \u001b[39m# for motion prediction\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmotion_segmentation\u001b[39m\u001b[39m\"\u001b[39m: motion_segmentation,\n\u001b[1;32m    211\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmotion_instance\u001b[39m\u001b[39m\"\u001b[39m: motion_instance,\n\u001b[1;32m    212\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minstance_centerness\u001b[39m\u001b[39m\"\u001b[39m: instance_centerness,\n\u001b[1;32m    213\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minstance_offset\u001b[39m\u001b[39m\"\u001b[39m: instance_offset,\n\u001b[1;32m    214\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minstance_flow\u001b[39m\u001b[39m\"\u001b[39m: instance_flow,\n\u001b[1;32m    215\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfuture_egomotion\u001b[39m\u001b[39m\"\u001b[39m: future_egomotions,\n\u001b[1;32m    216\u001b[0m     \u001b[39m# for bev_augmentation\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maug_transform\u001b[39m\u001b[39m\"\u001b[39m: aug_transform,\n\u001b[1;32m    218\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimg_is_valid\u001b[39m\u001b[39m\"\u001b[39m: img_is_valid,\n\u001b[1;32m    219\u001b[0m }\n\u001b[1;32m    221\u001b[0m loss_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_pts_train(img_feats, img_metas, mtl_targets)\n\u001b[1;32m    223\u001b[0m \u001b[39mreturn\u001b[39;00m loss_dict\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/torch/serialization.py:594\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    592\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 594\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    595\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    596\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dummy_input.pt'"
     ]
    }
   ],
   "source": [
    "\n",
    "num_warmups = 100\n",
    "num_repeats = 1000\n",
    "# Change to C x 1 x 3 x 1600 x 900\n",
    "# 704×256 Tiny\n",
    "# 1408×512\n",
    "# B, T, N, C, imH, imW = imgs.shape\n",
    "input_shape = (1,3,6,3,1600,900)\n",
    "\n",
    "future_egomotions = torch.zeros((batch_size, 7, 6)).type_as(img_inputs)\n",
    "img_is_valid = torch.ones((batch_size, 7)).type_as(img_inputs) > 0\n",
    "print(\"Future Egomotions: \", future_egomotions.shape)\n",
    "print(\"img_is_valid: \", img_is_valid.shape)\n",
    "\n",
    "\n",
    "# imgs = imgs.view(B * S * N, C, imH, imW)\n",
    "\n",
    "model = build_model(cfg.model, test_cfg=cfg.get(\"test_cfg\"))\n",
    "wrap_fp16_model(model)\n",
    "# load_checkpoint(\n",
    "#     model,\n",
    "#     r\"/home/niklas/ETM_BEV/BEVerse/checkpoints/beverse_tiny.pth\",\n",
    "#     map_location=\"cpu\",\n",
    "# )\n",
    "# model = fuse_module(model)\n",
    "model.cuda(device)\n",
    "model.eval()\n",
    "# model = nn.Conv2d(in_channels=input_shape[1], out_channels=256, kernel_size=(5, 5))\n",
    "\n",
    "# Input tensor\n",
    "input_tensor = torch.rand(input_shape, device=device)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "print(\"Latency Measurement Using CPU Timer...\")\n",
    "for continuous_measure in [True]:\n",
    "    for synchronize in [True]:\n",
    "        try:\n",
    "            latency_ms = measure_time_host(\n",
    "                model=model,\n",
    "                input_tensor=input_tensor,\n",
    "                num_repeats=num_repeats,\n",
    "                num_warmups=num_warmups,\n",
    "                synchronize=synchronize,\n",
    "                continuous_measure=continuous_measure,\n",
    "            )\n",
    "            print(\n",
    "                f\"|\"\n",
    "                f\"Synchronization: {synchronize!s:5}| \"\n",
    "                f\"Continuous Measurement: {continuous_measure!s:5}| \"\n",
    "                f\"Latency: {latency_ms:.5f} ms| \"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"|\"\n",
    "                f\"Synchronization: {synchronize!s:5}| \"\n",
    "                f\"Continuous Measurement: {continuous_measure!s:5}| \"\n",
    "                f\"Latency: N/A     ms| \"\n",
    "            )\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "print(\"Latency Measurement Using CUDA Timer...\")\n",
    "for continuous_measure in [True, False]:\n",
    "    for synchronize in [True, False]:\n",
    "        try:\n",
    "            latency_ms = measure_time_device(\n",
    "                model=model,\n",
    "                input_tensor=input_tensor,\n",
    "                num_repeats=num_repeats,\n",
    "                num_warmups=num_warmups,\n",
    "                synchronize=synchronize,\n",
    "                continuous_measure=continuous_measure,\n",
    "            )\n",
    "            print(\n",
    "                f\"|\"\n",
    "                f\"Synchronization: {synchronize!s:5}| \"\n",
    "                f\"Continuous Measurement: {continuous_measure!s:5}| \"\n",
    "                f\"Latency: {latency_ms:.5f} ms| \"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"|\"\n",
    "                f\"Synchronization: {synchronize!s:5}| \"\n",
    "                f\"Continuous Measurement: {continuous_measure!s:5}| \"\n",
    "                f\"Latency: N/A     ms| \"\n",
    "            )\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "print(\"Latency Measurement Using PyTorch Benchmark...\")\n",
    "num_threads = 1\n",
    "timer = benchmark.Timer(\n",
    "    stmt=\"run_inference(model, input_tensor)\",\n",
    "    setup=\"from __main__ import run_inference\",\n",
    "    globals={\"model\": model, \"input_tensor\": input_tensor},\n",
    "    num_threads=num_threads,\n",
    "    label=\"Latency Measurement\",\n",
    "    sub_label=\"torch.utils.benchmark.\",\n",
    ")\n",
    "\n",
    "profile_result = timer.timeit(num_repeats)\n",
    "# https://pytorch.org/docs/stable/_modules/torch/utils/benchmark/utils/common.html#Measurement\n",
    "print(f\"Latency: {profile_result.mean * 1000:.5f} ms\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49a6cb26e152f15aca94d1d3fa9630fb57fb8fd83a336982cd2ebf9e9635e69c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
