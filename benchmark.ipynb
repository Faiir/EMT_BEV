{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging \n",
    "from custome_logger import setup_custom_logger\n",
    "logger = setup_custom_logger()\n",
    "logger.debug(\"test\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.benchmark as benchmark\n",
    "from timeit import default_timer as timer\n",
    "import warnings\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import get_dist_info, init_dist, load_checkpoint, wrap_fp16_model\n",
    "from mmdet3d.models import build_model\n",
    "from mmdet3d.datasets import build_dataset\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('beverse')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n beverse ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "weights = torch.load(\"/home/niklas/ETM_BEV/BEVerse/weights/beverse_tiny.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "\n",
    "cfg = Config.fromfile(\n",
    "    r\"/home/niklas/ETM_BEV/BEVerse/projects/configs/beverse_tiny_org.py\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cfg(\n",
    "    cfg,\n",
    "    n_future=3,\n",
    "    receptive_field=3,\n",
    "    resize_lim=(0.38, 0.55),\n",
    "    final_dim=(256, 704),\n",
    "    grid_conf={\n",
    "        \"xbound\": [-51.2, 51.2, 0.8],\n",
    "        \"ybound\": [-51.2, 51.2, 0.8],\n",
    "        \"zbound\": [-10.0, 10.0, 20.0],\n",
    "        \"dbound\": [1.0, 60.0, 1.0],\n",
    "    },\n",
    "    det_grid_conf={\n",
    "        \"xbound\": [-51.2, 51.2, 0.8],\n",
    "        \"ybound\": [-51.2, 51.2, 0.8],\n",
    "        \"zbound\": [-10.0, 10.0, 20.0],\n",
    "        \"dbound\": [1.0, 60.0, 1.0],\n",
    "    },\n",
    "    map_grid_conf={\n",
    "        \"xbound\": [-30.0, 30.0, 0.15],\n",
    "        \"ybound\": [-15.0, 15.0, 0.15],\n",
    "        \"zbound\": [-10.0, 10.0, 20.0],\n",
    "        \"dbound\": [1.0, 60.0, 1.0],\n",
    "    },\n",
    "    motion_grid_conf={\n",
    "        \"xbound\": [-50.0, 50.0, 0.5],\n",
    "        \"ybound\": [-50.0, 50.0, 0.5],\n",
    "        \"zbound\": [-10.0, 10.0, 20.0],\n",
    "        \"dbound\": [1.0, 60.0, 1.0],\n",
    "    },\n",
    "    t_input_shape=(128, 128),\n",
    "    point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],\n",
    "):\n",
    "    \n",
    "    cfg[\"det_grid_conf\"] = det_grid_conf\n",
    "    cfg[\"map_grid_conf\"] = map_grid_conf\n",
    "    cfg[\"motion_grid_conf\"] = motion_grid_conf\n",
    "    cfg[\"grid_conf\"] = det_grid_conf\n",
    "\n",
    "    cfg[\"model\"][\"temporal_model\"][\"input_shape\"] = t_input_shape\n",
    "\n",
    "    cfg[\"data\"][\"val\"][\"pipeline\"][0][\"data_aug_conf\"][\"resize_lim\"] = resize_lim\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"pipeline\"][0][\"data_aug_conf\"][\n",
    "        \"resize_lim\"\n",
    "    ] = resize_lim\n",
    "    cfg[\"data\"][\"val\"][\"pipeline\"][0][\"data_aug_conf\"][\"final_dim\"] = final_dim\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"pipeline\"][0][\"data_aug_conf\"][\n",
    "        \"final_dim\"\n",
    "    ] = final_dim\n",
    "\n",
    "    cfg[\"data\"][\"test\"][\"pipeline\"][0][\"data_aug_conf\"][\"resize_lim\"] = resize_lim\n",
    "    cfg[\"data\"][\"test\"][\"pipeline\"][0][\"data_aug_conf\"][\"final_dim\"] = final_dim\n",
    "\n",
    "    cfg[\"model\"][\"pts_bbox_head\"][\"cfg_motion\"][\n",
    "        \"grid_conf\"\n",
    "    ] = motion_grid_conf  # motion_grid\n",
    "    cfg[\"model\"][\"temporal_model\"][\"grid_conf\"] = grid_conf\n",
    "    cfg[\"model\"][\"transformer\"][\"grid_conf\"] = grid_conf\n",
    "    cfg[\"model\"][\"pts_bbox_head\"][\"grid_conf\"] = grid_conf\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"grid_conf\"] = motion_grid_conf\n",
    "    cfg[\"data\"][\"val\"][\"pipeline\"][3][\"grid_conf\"] = motion_grid_conf\n",
    "    cfg[\"data\"][\"test\"][\"pipeline\"][3][\"grid_conf\"] = motion_grid_conf\n",
    "    cfg[\"data\"][\"val\"][\"grid_conf\"] = grid_conf\n",
    "    cfg[\"data\"][\"test\"][\"grid_conf\"] = grid_conf\n",
    "\n",
    "    cfg[\"model\"][\"pts_bbox_head\"][\"det_grid_conf\"] = det_grid_conf\n",
    "\n",
    "    cfg[\"model\"][\"pts_bbox_head\"][\"map_grid_conf\"] = map_grid_conf\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"map_grid_conf\"] = map_grid_conf\n",
    "    cfg[\"data\"][\"test\"][\"pipeline\"][2][\"map_grid_conf\"] = map_grid_conf\n",
    "    cfg[\"data\"][\"val\"][\"pipeline\"][2][\"map_grid_conf\"] = map_grid_conf\n",
    "    cfg[\"data\"][\"test\"][\"map_grid_conf\"] = map_grid_conf\n",
    "    cfg[\"data\"][\"val\"][\"map_grid_conf\"] = map_grid_conf\n",
    "\n",
    "    cfg[\"model\"][\"pts_bbox_head\"][\"motion_grid_conf\"] = motion_grid_conf\n",
    "\n",
    "    cfg[\"data\"][\"test\"][\"pipeline\"][5][\"point_cloud_range\"] = point_cloud_range\n",
    "    cfg[\"data\"][\"train\"][\"pipeline\"][5][\n",
    "        \"point_cloud_range\"\n",
    "    ] = point_cloud_range  # point_cloud_range=None\n",
    "    cfg[\"data\"][\"train\"][\"pipeline\"][6][\n",
    "        \"point_cloud_range\"\n",
    "    ] = point_cloud_range  #'point_cloud_range =None\n",
    "    cfg[\"data\"][\"val\"][\"pipeline\"][5][\"point_cloud_range\"] = point_cloud_range\n",
    "\n",
    "    cfg[\"model\"][\"pts_bbox_head\"][\"cfg_motion\"][\"receptive_field\"] = receptive_field\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"receptive_field\"] = receptive_field\n",
    "    cfg[\"model\"][\"temporal_model\"][\"receptive_field\"] = receptive_field\n",
    "    cfg[\"data\"][\"test\"][\"receptive_field\"] = receptive_field\n",
    "    cfg[\"data\"][\"val\"][\"receptive_field\"] = receptive_field\n",
    "\n",
    "    cfg[\"data\"][\"val\"][\"future_frames\"] = n_future\n",
    "    cfg[\"model\"][\"pts_bbox_head\"][\"cfg_motion\"][\"n_future\"] = n_future\n",
    "    cfg[\"data\"][\"test\"][\"future_frames\"] = n_future\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"future_frames\"] = n_future\n",
    "    \n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"pipeline\"][4][\"map_grid_conf\"] = map_grid_conf\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"pipeline\"][5][\"grid_conf\"] = motion_grid_conf\n",
    "    cfg[\"data\"][\"train\"][\"dataset\"][\"pipeline\"][7][\"point_cloud_range\"] = point_cloud_range\n",
    "\n",
    "    return cfg\n",
    "\n",
    "def import_modules_load_config(cfg_file=\"beverse_tiny.py\", samples_per_gpu=1):\n",
    "    cfg_path = r\"/home/niklas/ETM_BEV/BEVerse/projects/configs\"\n",
    "    cfg_path = os.path.join(cfg_path, cfg_file)\n",
    "\n",
    "    cfg = Config.fromfile(cfg_path)\n",
    "\n",
    "    # if args.cfg_options is not None:\n",
    "    #     cfg.merge_from_dict(args.cfg_options)\n",
    "    # import modules from string list.\n",
    "    if cfg.get(\"custom_imports\", None):\n",
    "        from mmcv.utils import import_modules_from_strings\n",
    "\n",
    "        import_modules_from_strings(**cfg[\"custom_imports\"])\n",
    "\n",
    "    # import modules from plguin/xx, registry will be updated\n",
    "    if hasattr(cfg, \"plugin\"):\n",
    "        if cfg.plugin:\n",
    "            import importlib\n",
    "\n",
    "            if hasattr(cfg, \"plugin_dir\"):\n",
    "                plugin_dir = cfg.plugin_dir\n",
    "                _module_dir = os.path.dirname(plugin_dir)\n",
    "                _module_dir = _module_dir.split(\"/\")\n",
    "                _module_path = _module_dir[0]\n",
    "\n",
    "                for m in _module_dir[1:]:\n",
    "                    _module_path = _module_path + \".\" + m\n",
    "                print(_module_path)\n",
    "                plg_lib = importlib.import_module(_module_path)\n",
    "            else:\n",
    "                # import dir is the dirpath for the config file\n",
    "                _module_dir = cfg_path\n",
    "                _module_dir = _module_dir.split(\"/\")\n",
    "                _module_path = _module_dir[0]\n",
    "                for m in _module_dir[1:]:\n",
    "                    _module_path = _module_path + \".\" + m\n",
    "                print(_module_path)\n",
    "                plg_lib = importlib.import_module(_module_path)\n",
    "\n",
    "    samples_per_gpu = 1\n",
    "    if isinstance(cfg.data.test, dict):\n",
    "        cfg.data.test.test_mode = True\n",
    "        samples_per_gpu = cfg.data.test.pop(\"samples_per_gpu\", 1)\n",
    "        if samples_per_gpu > 1:\n",
    "            # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n",
    "            cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n",
    "    elif isinstance(cfg.data.test, list):\n",
    "        for ds_cfg in cfg.data.test:\n",
    "            ds_cfg.test_mode = True\n",
    "        samples_per_gpu = max(\n",
    "            [ds_cfg.pop(\"samples_per_gpu\", 1) for ds_cfg in cfg.data.test]\n",
    "        )\n",
    "        if samples_per_gpu > 1:\n",
    "            for ds_cfg in cfg.data.test:\n",
    "                ds_cfg.pipeline = replace_ImageToTensor(ds_cfg.pipeline)\n",
    "\n",
    "    return cfg\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_time_host(\n",
    "    model: nn.Module,\n",
    "    input_tensor: torch.Tensor,\n",
    "    num_repeats: int = 100,\n",
    "    num_warmups: int = 10,\n",
    "    synchronize: bool = True,\n",
    "    continuous_measure: bool = True,\n",
    ") -> float:\n",
    "\n",
    "    for _ in range(num_warmups):\n",
    "        _ = model.forward(input_tensor)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    elapsed_time_ms = 0\n",
    "\n",
    "    if continuous_measure:\n",
    "        start = timer()\n",
    "        for _ in range(num_repeats):\n",
    "            _ = model.forward(input_tensor)\n",
    "        if synchronize:\n",
    "            torch.cuda.synchronize()\n",
    "        end = timer()\n",
    "        elapsed_time_ms = (end - start) * 1000\n",
    "\n",
    "    else:\n",
    "        for _ in range(num_repeats):\n",
    "            start = timer()\n",
    "            _ = model.forward(input_tensor)\n",
    "            if synchronize:\n",
    "                torch.cuda.synchronize()\n",
    "            end = timer()\n",
    "            elapsed_time_ms += (end - start) * 1000\n",
    "\n",
    "    return elapsed_time_ms / num_repeats\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_time_device(\n",
    "    model: nn.Module,\n",
    "    input_tensor: torch.Tensor,\n",
    "    num_repeats: int = 100,\n",
    "    num_warmups: int = 10,\n",
    "    synchronize: bool = True,\n",
    "    continuous_measure: bool = True,\n",
    ") -> float:\n",
    "\n",
    "    for _ in range(num_warmups):\n",
    "        _ = model.forward(input_tensor)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    elapsed_time_ms = 0\n",
    "\n",
    "    if continuous_measure:\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        start_event.record()\n",
    "        for _ in range(num_repeats):\n",
    "            _ = model.forward(input_tensor)\n",
    "        end_event.record()\n",
    "        if synchronize:\n",
    "            # This has to be synchronized to compute the elapsed time.\n",
    "            # Otherwise, there will be runtime error.\n",
    "            torch.cuda.synchronize()\n",
    "        elapsed_time_ms = start_event.elapsed_time(end_event)\n",
    "\n",
    "    else:\n",
    "        for _ in range(num_repeats):\n",
    "            start_event = torch.cuda.Event(enable_timing=True)\n",
    "            end_event = torch.cuda.Event(enable_timing=True)\n",
    "            start_event.record()\n",
    "            _ = model.forward(input_tensor)\n",
    "            end_event.record()\n",
    "            if synchronize:\n",
    "                # This has to be synchronized to compute the elapsed time.\n",
    "                # Otherwise, there will be runtime error.\n",
    "                torch.cuda.synchronize()\n",
    "            elapsed_time_ms += start_event.elapsed_time(end_event)\n",
    "\n",
    "    return elapsed_time_ms / num_repeats\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_inference(model: nn.Module, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "    # from model.forward because BEVerse differentiates between different input types - img lidar etc \n",
    "    return model.forward_dummy()\n",
    "\n",
    "def calculate_birds_eye_view_parameters(x_bounds, y_bounds, z_bounds):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "        x_bounds: Forward direction in the ego-car.\n",
    "        y_bounds: Sides\n",
    "        z_bounds: Height\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        bev_resolution: Bird's-eye view bev_resolution\n",
    "        bev_start_position Bird's-eye view first element\n",
    "        bev_dimension Bird's-eye view tensor spatial dimension\n",
    "    \"\"\"\n",
    "    bev_resolution = torch.tensor([row[2] for row in [x_bounds, y_bounds, z_bounds]])\n",
    "    bev_start_position = torch.tensor(\n",
    "        [row[0] + row[2] / 2.0 for row in [x_bounds, y_bounds, z_bounds]]\n",
    "    )\n",
    "    bev_dimension = torch.tensor(\n",
    "        [(row[1] - row[0]) / row[2] for row in [x_bounds, y_bounds, z_bounds]],\n",
    "        dtype=torch.long,\n",
    "    )\n",
    "\n",
    "    return bev_resolution, bev_start_position, bev_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_lims = [\n",
    "    (0.3, 0.45),  # fiery\n",
    "    (0.38, 0.55),  # desTINY\n",
    "    (0.82, 0.99),  # small\n",
    "    (1, 1),  # BEVDEt\n",
    "]\n",
    "\n",
    "final_dims = [(224, 480), (256, 704), (512, 1408), (900, 1600)]\n",
    "\n",
    "backbones = [\n",
    "    \"beverse_tiny.py\",\n",
    "    \"beverse_tiny.py\",\n",
    "    \"beverse_small.py\",\n",
    "    \"beverse_small.py\",\n",
    "]\n",
    "\n",
    "# future frames -> tiny settings\n",
    "future_frames_list = [4, 4, 4, 4, 5, 7, 10]\n",
    "receptive_field_list = [\n",
    "    3,\n",
    "    5,\n",
    "    8,\n",
    "    13,\n",
    "    4,\n",
    "    6,\n",
    "    9,\n",
    "]\n",
    "\n",
    "# grid_size = (\n",
    "#     point_cloud_range[3:] -  # type: ignore\n",
    "#     point_cloud_range[:3]) / voxel_size  # type: ignore\n",
    "\n",
    "point_cloud_range_base = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n",
    "point_cloud_range_extended_fustrum = [-71.2, -71.2, -5.0, 71.2, 71.2, 3.0]\n",
    "det_grid_confs = {\n",
    "    \"xbound\": [\n",
    "        [-51.2, 51.2, 0.8],  # lower_bound, upper_bound, interval\n",
    "        [-51.2, 51.2, 0.4],\n",
    "        [-51.2, 51.2, 0.2],\n",
    "        [-51.2, 51.2, 0.1],\n",
    "        [-26.2, 26.2, 0.8],\n",
    "        [-26.2, 26.2, 0.4],\n",
    "    ],\n",
    "    \"ybound\": [\n",
    "        [-51.2, 51.2, 0.8],\n",
    "        [-51.2, 51.2, 0.4],\n",
    "        [-51.2, 51.2, 0.2],\n",
    "        [-51.2, 51.2, 0.1],\n",
    "        [-71.2, 71.2, 0.8],\n",
    "        [-71.2, 71.2, 0.4],\n",
    "    ],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [\n",
    "        [1.0, 60.0, 1.0],\n",
    "        [1.0, 60.0, 1.0],\n",
    "        [1.0, 60.0, 0.5],\n",
    "        [1.0, 60.0, 0.5],\n",
    "        [1.0, 70.0, 1.0],\n",
    "        [1.0, 70.0, 5.0],\n",
    "    ],  # [(lower_bound, upper_bound, interval).]\n",
    "}\n",
    "\n",
    "motion_grid_confs = {\n",
    "    \"xbound\": [\n",
    "        [-50.0, 50.0, 0.5],\n",
    "        [-50.0, 50.0, 0.25],\n",
    "        [-50.0, 50.0, 0.125],\n",
    "        [-50.0, 50.0, 0.075],\n",
    "        [-25.0, 25.0, 0.5],\n",
    "        [-25.0, 25.0, 0.25],\n",
    "    ],\n",
    "    \"ybound\": [\n",
    "        [-50.0, 50.0, 0.5],\n",
    "        [-50.0, 50.0, 0.25],\n",
    "        [-50.0, 50.0, 0.125],\n",
    "        [-50.0, 50.0, 0.075],\n",
    "        [-70.0, 70.0, 0.5],\n",
    "        [-70.0, 70.0, 0.25],\n",
    "    ],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [\n",
    "        [1.0, 60.0, 1.0],\n",
    "        [1.0, 60.0, 1.0],\n",
    "        [1.0, 60.0, 0.5],\n",
    "        [1.0, 60.0, 0.5],\n",
    "        [1.0, 70.0, 1.0],\n",
    "        [1.0, 70.0, 5.0],\n",
    "    ],\n",
    "}\n",
    "\n",
    "map_grid_confs = {\n",
    "    \"xbound\": [-30.0, 30.0, 0.15],\n",
    "    \"ybound\": [-15.0, 15.0, 0.15],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [\n",
    "        [1.0, 60.0, 1.0],\n",
    "        [1.0, 60.0, 1.0],\n",
    "        [1.0, 60.0, 0.5],\n",
    "        [1.0, 60.0, 0.5],\n",
    "        [1.0, 70.0, 1.0],\n",
    "        [1.0, 70.0, 5.0],\n",
    "    ],\n",
    "}\n",
    "det_grid_conf = {\n",
    "    \"xbound\": [-51.2, 51.2, 0.8],\n",
    "    \"ybound\": [-51.2, 51.2, 0.8],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}\n",
    "\n",
    "motion_grid_conf = {\n",
    "    \"xbound\": [-50.0, 50.0, 0.5],\n",
    "    \"ybound\": [-50.0, 50.0, 0.5],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}\n",
    "\n",
    "map_grid_conf = {\n",
    "    \"xbound\": [-30.0, 30.0, 0.15],\n",
    "    \"ybound\": [-15.0, 15.0, 0.15],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# det_grid_conf[\"xbound\"] = det_grid_confs[\"xbound\"][1]\n",
    "# det_grid_conf[\"ybound\"] = det_grid_confs[\"ybound\"][1]\n",
    "# det_grid_conf[\"zbound\"] = det_grid_confs[\"zbound\"]\n",
    "# det_grid_conf[\"dbound\"] = det_grid_confs[\"dbound\"][1]\n",
    "\n",
    "# motion_grid_conf[\"xbound\"] = motion_grid_confs[\"xbound\"][1]\n",
    "# motion_grid_conf[\"ybound\"] = motion_grid_confs[\"ybound\"][1]\n",
    "# motion_grid_conf[\"zbound\"] = motion_grid_confs[\"zbound\"]\n",
    "# motion_grid_conf[\"dbound\"] = motion_grid_confs[\"dbound\"][1]\n",
    "\n",
    "# map_grid_conf[\"xbound\"] = map_grid_confs[\"xbound\"]\n",
    "# map_grid_conf[\"ybound\"] = map_grid_confs[\"ybound\"]\n",
    "# map_grid_conf[\"zbound\"] = map_grid_confs[\"zbound\"]\n",
    "# map_grid_conf[\"dbound\"] = map_grid_confs[\"dbound\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects.mmdet3d_plugin\n"
     ]
    }
   ],
   "source": [
    "cfg = import_modules_load_config(cfg_file=\"/home/niklas/ETM_BEV/BEVerse/projects/configs/beverse_tiny_org.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    samples_per_gpu=2,\n",
    "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "    dist=False,\n",
    "    shuffle=False,\n",
    ")\n",
    "iter_loader = iter(data_loader)\n",
    "sample = next(iter_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# device = torch.device(\"cuda:0\")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# cfg = Config.fromfile(\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#     r\"/home/niklas/ETM_BEV/BEVerse/projects/configs/beverse_tiny.py\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m#     cfg.merge_from_dict(args.cfg_options)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# import modules from string list.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mif\u001b[39;00m cfg\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcustom_imports\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmmcv\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m import_modules_from_strings\n\u001b[1;32m     12\u001b[0m     import_modules_from_strings(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcfg[\u001b[39m\"\u001b[39m\u001b[39mcustom_imports\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# device = torch.device(\"cuda:0\")\n",
    "# cfg = Config.fromfile(\n",
    "#     r\"/home/niklas/ETM_BEV/BEVerse/projects/configs/beverse_tiny.py\"\n",
    "# )\n",
    "\n",
    "# if args.cfg_options is not None:\n",
    "#     cfg.merge_from_dict(args.cfg_options)\n",
    "# import modules from string list.\n",
    "if cfg.get(\"custom_imports\", None):\n",
    "    from mmcv.utils import import_modules_from_strings\n",
    "\n",
    "    import_modules_from_strings(**cfg[\"custom_imports\"])\n",
    "\n",
    "# import modules from plguin/xx, registry will be updated\n",
    "if hasattr(cfg, \"plugin\"):\n",
    "    if cfg.plugin:\n",
    "        import importlib\n",
    "\n",
    "        if hasattr(cfg, \"plugin_dir\"):\n",
    "            plugin_dir = cfg.plugin_dir\n",
    "            _module_dir = os.path.dirname(plugin_dir)\n",
    "            _module_dir = _module_dir.split(\"/\")\n",
    "            _module_path = _module_dir[0]\n",
    "\n",
    "            for m in _module_dir[1:]:\n",
    "                _module_path = _module_path + \".\" + m\n",
    "            print(_module_path)\n",
    "            plg_lib = importlib.import_module(_module_path)\n",
    "        else:\n",
    "            # import dir is the dirpath for the config file\n",
    "            _module_dir = os.path.dirname(\n",
    "                r\"/home/niklas/ETM_BEV/BEVerse/projects/configs/beverse_tiny_exp.py\"\n",
    "            )\n",
    "            _module_dir = _module_dir.split(\"/\")\n",
    "            _module_path = _module_dir[0]\n",
    "            for m in _module_dir[1:]:\n",
    "                _module_path = _module_path + \".\" + m\n",
    "            print(_module_path)\n",
    "            plg_lib = importlib.import_module(_module_path)\n",
    "            \n",
    "\n",
    "samples_per_gpu = 1\n",
    "if isinstance(cfg.data.test, dict):\n",
    "    cfg.data.test.test_mode = True\n",
    "    samples_per_gpu = cfg.data.test.pop(\"samples_per_gpu\", 1)\n",
    "    if samples_per_gpu > 1:\n",
    "        # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n",
    "        cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n",
    "elif isinstance(cfg.data.test, list):\n",
    "    for ds_cfg in cfg.data.test:\n",
    "        ds_cfg.test_mode = True\n",
    "    samples_per_gpu = max(\n",
    "        [ds_cfg.pop(\"samples_per_gpu\", 1) for ds_cfg in cfg.data.test]\n",
    "    )\n",
    "    if samples_per_gpu > 1:\n",
    "        for ds_cfg in cfg.data.test:\n",
    "            ds_cfg.pipeline = replace_ImageToTensor(ds_cfg.pipeline)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_time_host(\n",
    "    model: nn.Module,\n",
    "    input_tensor: torch.Tensor,\n",
    "    num_repeats: int = 100,\n",
    "    num_warmups: int = 10,\n",
    "    synchronize: bool = True,\n",
    "    continuous_measure: bool = True,\n",
    ") -> float:\n",
    "\n",
    "    for _ in range(num_warmups):\n",
    "        _ = model.forward(input_tensor)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    elapsed_time_ms = 0\n",
    "\n",
    "    if continuous_measure:\n",
    "        start = timer()\n",
    "        for _ in range(num_repeats):\n",
    "            _ = model.forward(input_tensor)\n",
    "        if synchronize:\n",
    "            torch.cuda.synchronize()\n",
    "        end = timer()\n",
    "        elapsed_time_ms = (end - start) * 1000\n",
    "\n",
    "    else:\n",
    "        for _ in range(num_repeats):\n",
    "            start = timer()\n",
    "            _ = model.forward(input_tensor)\n",
    "            if synchronize:\n",
    "                torch.cuda.synchronize()\n",
    "            end = timer()\n",
    "            elapsed_time_ms += (end - start) * 1000\n",
    "\n",
    "    return elapsed_time_ms / num_repeats\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_time_device(\n",
    "    model: nn.Module,\n",
    "    input_tensor: torch.Tensor,\n",
    "    num_repeats: int = 100,\n",
    "    num_warmups: int = 10,\n",
    "    synchronize: bool = True,\n",
    "    continuous_measure: bool = True,\n",
    ") -> float:\n",
    "\n",
    "    for _ in range(num_warmups):\n",
    "        _ = model.forward(input_tensor)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    elapsed_time_ms = 0\n",
    "\n",
    "    if continuous_measure:\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        start_event.record()\n",
    "        for _ in range(num_repeats):\n",
    "            _ = model.forward(input_tensor)\n",
    "        end_event.record()\n",
    "        if synchronize:\n",
    "            # This has to be synchronized to compute the elapsed time.\n",
    "            # Otherwise, there will be runtime error.\n",
    "            torch.cuda.synchronize()\n",
    "        elapsed_time_ms = start_event.elapsed_time(end_event)\n",
    "\n",
    "    else:\n",
    "        for _ in range(num_repeats):\n",
    "            start_event = torch.cuda.Event(enable_timing=True)\n",
    "            end_event = torch.cuda.Event(enable_timing=True)\n",
    "            start_event.record()\n",
    "            _ = model.forward(input_tensor)\n",
    "            end_event.record()\n",
    "            if synchronize:\n",
    "                # This has to be synchronized to compute the elapsed time.\n",
    "                # Otherwise, there will be runtime error.\n",
    "                torch.cuda.synchronize()\n",
    "            elapsed_time_ms += start_event.elapsed_time(end_event)\n",
    "\n",
    "    return elapsed_time_ms / num_repeats\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_inference(model: nn.Module, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "    return model.forward(input_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_grid_conf = {\n",
    "    \"xbound\": [-62.0, 62.0, 0.8],\n",
    "    \"ybound\": [-36.2, 36.2, 0.8],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 70.0, 1.0],\n",
    "}\n",
    "\n",
    "motion_grid_conf = {\n",
    "    \"xbound\": [-60.0, 60.0, 0.5],\n",
    "    \"ybound\": [-36.0, 36.0, 0.5],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 70.0, 1.0],\n",
    "}\n",
    "\n",
    "map_grid_conf = {\n",
    "    \"xbound\": [-30.0, 30.0, 0.15],\n",
    "    \"ybound\": [-15.0, 15.0, 0.15],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 70.0, 1.0],\n",
    "}\n",
    "\n",
    "----------\n",
    "det_grid_conf = {\n",
    "    \"xbound\": [-51.2, 51.2, 0.8],\n",
    "    \"ybound\": [-51.2, 51.2, 0.8],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}\n",
    "\n",
    "motion_grid_conf = {\n",
    "    \"xbound\": [-50.0, 50.0, 0.5],\n",
    "    \"ybound\": [-50.0, 50.0, 0.5],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}\n",
    "\n",
    "map_grid_conf = {\n",
    "    \"xbound\": [-30.0, 30.0, 0.15],\n",
    "    \"ybound\": [-15.0, 15.0, 0.15],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([240, 144,   1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_bounds, y_bounds,z_bounds=cfg[\"det_grid_conf\"][\"xbound\"],cfg[\"det_grid_conf\"][\"ybound\"],cfg[\"det_grid_conf\"][\"zbound\"]\n",
    "\n",
    "bev_dimension = torch.tensor(\n",
    "        [(row[1] - row[0]) / row[2] for row in [x_bounds, y_bounds, z_bounds]],\n",
    "        dtype=torch.long,\n",
    "    )\n",
    "bev_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240.7766990291262\n",
      "144.8\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for row in [x_bounds, y_bounds, z_bounds]:\n",
    "    print((row[1] - row[0]) / row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# det_grid_conf = {\n",
    "#     \"xbound\": [-62.0, 62.0, 0.37],#37\n",
    "#     \"ybound\": [-36.2, 36.2, 0.375],#37,5\n",
    "#     \"zbound\": [-10.0, 10.0, 20.0],\n",
    "#     \"dbound\": [1.0, 70.0, 1.0],\n",
    "# }\n",
    "\n",
    "# motion_grid_conf = {\n",
    "#     \"xbound\": [-60.0, 60.0, 0.25],\n",
    "#     \"ybound\": [-36.0, 36.0, 0.25],\n",
    "#     \"zbound\": [-10.0, 10.0, 20.0],\n",
    "#     \"dbound\": [1.0, 70.0, 1.0],\n",
    "# }\n",
    "\n",
    "# map_grid_conf = {\n",
    "#     \"xbound\": [-30.0, 30.0, 0.15],\n",
    "#     \"ybound\": [-15.0, 15.0, 0.15],\n",
    "#     \"zbound\": [-10.0, 10.0, 20.0],\n",
    "#     \"dbound\": [1.0, 70.0, 1.0],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_grid_conf = {\n",
    "    \"xbound\": [-51.2, 51.2, 0.2],\n",
    "    \"ybound\": [-51.2, 51.2, 0.2],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, .50],\n",
    "}\n",
    "\n",
    "motion_grid_conf = {\n",
    "    \"xbound\": [-50.0, 50.0, 0.125],\n",
    "    \"ybound\": [-50.0, 50.0, 0.125],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, .50],\n",
    "}\n",
    "\n",
    "map_grid_conf = {\n",
    "    \"xbound\": [-30.0, 30.0, 0.15],\n",
    "    \"ybound\": [-15.0, 15.0, 0.15],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, .50],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-25.6, 25.6, 0.1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i/2.0 for i in  [-51.2, 51.2, 0.2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects.mmdet3d_plugin\n"
     ]
    }
   ],
   "source": [
    "det_grid_conf = {\n",
    "    \"xbound\": [-50.0, 50.0, 0.5],\n",
    "    \"ybound\": [-50.0, 50.0, 0.5],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}\n",
    "\n",
    "motion_grid_conf = {\n",
    "    \"xbound\": [-50.0, 50.0, 0.5],\n",
    "    \"ybound\": [-50.0, 50.0, 0.5],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, .50],\n",
    "}\n",
    "\n",
    "map_grid_conf = {\n",
    "    \"xbound\": [-50.0, 50.0, 0.5],\n",
    "    \"ybound\": [-50.0, 50.0, 0.5],\n",
    "    \"zbound\": [-10.0, 10.0, 20.0],\n",
    "    \"dbound\": [1.0, 60.0, 1.0],\n",
    "}\n",
    "\n",
    "point_cloud_range_base = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n",
    "point_cloud_range_extended_fustrum = [-62.0, -62.0, -5.0, 62.0, 62.0, 3.0]\n",
    "\n",
    "cfg = import_modules_load_config(cfg_file=\"beverse_tiny_org.py\")\n",
    "\n",
    "cfg = update_cfg(\n",
    "    cfg,det_grid_conf=det_grid_conf,grid_conf=det_grid_conf, map_grid_conf=map_grid_conf, motion_grid_conf=motion_grid_conf, point_cloud_range=point_cloud_range_extended_fustrum, t_input_shape=(90, 155)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'MTLEgoNuScenesDataset',\n",
       " 'data_root': 'data/nuscenes/',\n",
       " 'ann_file': '/home/niklas/ETM_BEV/BEVerse/data/nuscenes_infos/nuscenes_infos_val.pkl',\n",
       " 'pipeline': [{'type': 'LoadMultiViewImageFromFiles_MTL',\n",
       "   'using_ego': True,\n",
       "   'data_aug_conf': {'resize_lim': (0.38, 0.55),\n",
       "    'final_dim': (256, 704),\n",
       "    'rot_lim': (-5.4, 5.4),\n",
       "    'H': 900,\n",
       "    'W': 1600,\n",
       "    'rand_flip': True,\n",
       "    'bot_pct_lim': (0.0, 0.22),\n",
       "    'crop_h': (0.0, 0.0),\n",
       "    'cams': ['CAM_FRONT_LEFT',\n",
       "     'CAM_FRONT',\n",
       "     'CAM_FRONT_RIGHT',\n",
       "     'CAM_BACK_LEFT',\n",
       "     'CAM_BACK',\n",
       "     'CAM_BACK_RIGHT'],\n",
       "    'Ncams': 6}},\n",
       "  {'type': 'LoadAnnotations3D_MTL',\n",
       "   'with_bbox_3d': True,\n",
       "   'with_label_3d': True,\n",
       "   'with_instance_tokens': True},\n",
       "  {'type': 'RasterizeMapVectors',\n",
       "   'map_grid_conf': {'xbound': [-50.0, 50.0, 0.5],\n",
       "    'ybound': [-50.0, 50.0, 0.5],\n",
       "    'zbound': [-10.0, 10.0, 20.0],\n",
       "    'dbound': [1.0, 60.0, 1.0]}},\n",
       "  {'type': 'ConvertMotionLabels',\n",
       "   'grid_conf': {'xbound': [-50.0, 50.0, 0.5],\n",
       "    'ybound': [-50.0, 50.0, 0.5],\n",
       "    'zbound': [-10.0, 10.0, 20.0],\n",
       "    'dbound': [1.0, 60.0, 0.5]},\n",
       "   'only_vehicle': True},\n",
       "  {'type': 'ObjectValidFilter'},\n",
       "  {'type': 'ObjectRangeFilter',\n",
       "   'point_cloud_range': [-62.0, -62.0, -5.0, 62.0, 62.0, 3.0]},\n",
       "  {'type': 'ObjectNameFilter',\n",
       "   'classes': ['car',\n",
       "    'truck',\n",
       "    'construction_vehicle',\n",
       "    'bus',\n",
       "    'trailer',\n",
       "    'barrier',\n",
       "    'motorcycle',\n",
       "    'bicycle',\n",
       "    'pedestrian',\n",
       "    'traffic_cone']},\n",
       "  {'type': 'MultiScaleFlipAug3D',\n",
       "   'img_scale': (1333, 800),\n",
       "   'pts_scale_ratio': 1,\n",
       "   'flip': False,\n",
       "   'transforms': [{'type': 'DefaultFormatBundle3D',\n",
       "     'class_names': ['car',\n",
       "      'truck',\n",
       "      'construction_vehicle',\n",
       "      'bus',\n",
       "      'trailer',\n",
       "      'barrier',\n",
       "      'motorcycle',\n",
       "      'bicycle',\n",
       "      'pedestrian',\n",
       "      'traffic_cone'],\n",
       "     'with_label': False},\n",
       "    {'type': 'Collect3D',\n",
       "     'keys': ['img_inputs',\n",
       "      'semantic_indices',\n",
       "      'semantic_map',\n",
       "      'future_egomotions',\n",
       "      'gt_bboxes_3d',\n",
       "      'gt_labels_3d',\n",
       "      'motion_segmentation',\n",
       "      'motion_instance',\n",
       "      'instance_centerness',\n",
       "      'instance_offset',\n",
       "      'instance_flow',\n",
       "      'has_invalid_frame',\n",
       "      'img_is_valid'],\n",
       "     'meta_keys': ('filename',\n",
       "      'ori_shape',\n",
       "      'img_shape',\n",
       "      'lidar2img',\n",
       "      'depth2img',\n",
       "      'cam2img',\n",
       "      'pad_shape',\n",
       "      'scale_factor',\n",
       "      'flip',\n",
       "      'pcd_horizontal_flip',\n",
       "      'pcd_vertical_flip',\n",
       "      'box_mode_3d',\n",
       "      'box_type_3d',\n",
       "      'img_norm_cfg',\n",
       "      'pcd_trans',\n",
       "      'sample_idx',\n",
       "      'pcd_scale_factor',\n",
       "      'pcd_rotation',\n",
       "      'pts_filename',\n",
       "      'transformation_3d_flow',\n",
       "      'img_info',\n",
       "      'lidar2ego_rots',\n",
       "      'lidar2ego_trans')}]}],\n",
       " 'classes': ['car',\n",
       "  'truck',\n",
       "  'construction_vehicle',\n",
       "  'bus',\n",
       "  'trailer',\n",
       "  'barrier',\n",
       "  'motorcycle',\n",
       "  'bicycle',\n",
       "  'pedestrian',\n",
       "  'traffic_cone'],\n",
       " 'modality': {'use_lidar': False,\n",
       "  'use_camera': True,\n",
       "  'use_radar': False,\n",
       "  'use_map': False,\n",
       "  'use_external': False,\n",
       "  'prototype': 'lift-splat-shoot'},\n",
       " 'test_mode': True,\n",
       " 'box_type_3d': 'LiDAR',\n",
       " 'receptive_field': 3,\n",
       " 'future_frames': 3,\n",
       " 'grid_conf': {'xbound': [-50.0, 50.0, 0.5],\n",
       "  'ybound': [-50.0, 50.0, 0.5],\n",
       "  'zbound': [-10.0, 10.0, 20.0],\n",
       "  'dbound': [1.0, 60.0, 1.0]},\n",
       " 'map_grid_conf': {'xbound': [-50.0, 50.0, 0.5],\n",
       "  'ybound': [-50.0, 50.0, 0.5],\n",
       "  'zbound': [-10.0, 10.0, 20.0],\n",
       "  'dbound': [1.0, 60.0, 1.0]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.data.test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    samples_per_gpu=2,\n",
    "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "    dist=False,\n",
    "    shuffle=False)\n",
    "\n",
    "sample = next(iter(data_loader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict_keys(['img_metas', 'img_inputs', 'semantic_indices', 'semantic_map', 'future_egomotions', 'gt_bboxes_3d', 'gt_labels_3d', 'motion_segmentation', 'motion_instance', 'instance_centerness', 'instance_offset', 'instance_flow', 'has_invalid_frame', 'img_is_valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 200, 200])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"instance_flow\"][0][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 1, 200, 200])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"instance_centerness\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 2, 200, 200])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"instance_offset\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 2, 200, 200])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"instance_flow\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 200, 200])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"motion_segmentation\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 6])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"future_egomotions\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200, 200])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"semantic_indices\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 200, 200])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"semantic_map\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"gt_labels_3d\"][0].data[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'bev',\n",
    "* 'bottom_center',\n",
    "* 'bottom_height',\n",
    "* 'box_dim',\n",
    "* 'cat',\n",
    "* 'center',\n",
    "* 'clone',\n",
    "* 'convert_to',\n",
    "* 'corners',\n",
    "* 'device',\n",
    "* 'dims',\n",
    "* 'enlarged_box',\n",
    "* 'flip',\n",
    "* 'gravity_center',\n",
    "* 'height',\n",
    "* 'height_overlaps',\n",
    "* 'in_range_3d',\n",
    "* 'in_range_bev',\n",
    "* 'limit_yaw',\n",
    "* 'nearest_bev',\n",
    "* 'new_box',\n",
    "* 'nonempty',\n",
    "* 'overlaps',\n",
    "* 'points_in_boxes',\n",
    "* 'rotate',\n",
    "* 'scale',\n",
    "* 'tensor',\n",
    "* 'to',\n",
    "* 'top_height',\n",
    "* 'translate',\n",
    "* 'volume',\n",
    "* 'with_yaw',\n",
    "* 'yaw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample[\"gt_bboxes_3d\"][0].data[0][0].nearest_bev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet import __version__ as mmdet_version\n",
    "from mmdet3d import __version__ as mmdet3d_version\n",
    "from mmseg import __version__ as mmseg_version\n",
    "cfg.checkpoint_config.meta = dict(\n",
    "            mmdet_version=mmdet_version,\n",
    "            mmseg_version=mmseg_version,\n",
    "            mmdet3d_version=mmdet3d_version,\n",
    "            config=cfg.pretty_text,\n",
    "            CLASSES=dataset.CLASSES,\n",
    "            PALETTE=dataset.PALETTE  # for segmentors\n",
    "            if hasattr(dataset, 'PALETTE') else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsample(scale_factor=4.0, mode=bilinear)\n",
      "Upsample(scale_factor=4.0, mode=bilinear)\n",
      "Upsample(scale_factor=4.0, mode=bilinear)\n",
      "CenterHeadv1\n",
      "CenterPointBBoxCoder\n",
      "MapHead\n",
      "BaseMotionHead\n",
      "IterativeFlow\n",
      "Temp3d:  (128, 128)\n",
      "Temp3d:  {'xbound': [-51.2, 51.2, 0.8], 'ybound': [-51.2, 51.2, 0.8], 'zbound': [-10.0, 10.0, 20.0], 'dbound': [1.0, 60.0, 1.0]}\n",
      "pool_sizes [(2, 96, 167)]\n",
      "temp block, in_channels  70 reduction_channels  23 pool_sizes  [(2, 96, 167)] \n",
      "Temproal3DConvModel: block_in_channels 70, block_out_channels 64, pool_sizes [(2, 96, 167)]\n",
      "pool_sizes [(2, 96, 167)]\n",
      "temp block, in_channels  64 reduction_channels  21 pool_sizes  [(2, 96, 167)] \n",
      "Temproal3DConvModel: block_in_channels 64, block_out_channels 64, pool_sizes [(2, 96, 167)]\n",
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "#checkpoint = load_checkpoint(model, r\"/home/niklas/ETM_BEV/BEVerse/weights/beverse_tiny.pth\", map_location='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CenterHeadv1\n",
      "CenterPointBBoxCoder\n",
      "ModuleList(\n",
      "  (0): SeparateHead(\n",
      "    (reg): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (height): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (dim): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (rot): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (vel): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (heatmap): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "  (1): SeparateHead(\n",
      "    (reg): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (height): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (dim): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (rot): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (vel): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (heatmap): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "  (2): SeparateHead(\n",
      "    (reg): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (height): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (dim): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (rot): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (vel): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (heatmap): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "  (3): SeparateHead(\n",
      "    (reg): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (height): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (dim): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (rot): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (vel): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (heatmap): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "  (4): SeparateHead(\n",
      "    (reg): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (height): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (dim): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (rot): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (vel): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (heatmap): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "  (5): SeparateHead(\n",
      "    (reg): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (height): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (dim): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (rot): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (vel): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (heatmap): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      ")\n",
      "MapHead\n",
      "BaseMotionHead\n",
      "Future Prediction\n",
      "IterativeFlow\n",
      "Future Prediction\n",
      "TASK HEADS\n",
      "ModuleDict(\n",
      "  (segmentation): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (instance_center): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (instance_offset): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (instance_flow): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "TASK DECODERS\n",
      "ModuleDict(\n",
      "  (3dod): CenterHeadv1(\n",
      "    (loss_cls): GaussianFocalLoss()\n",
      "    (loss_bbox): L1Loss()\n",
      "    (shared_conv): ConvModule(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activate): ReLU(inplace=True)\n",
      "    )\n",
      "    (task_heads): ModuleList(\n",
      "      (0): SeparateHead(\n",
      "        (reg): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (vel): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (heatmap): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "      (1): SeparateHead(\n",
      "        (reg): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (vel): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (heatmap): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "      (2): SeparateHead(\n",
      "        (reg): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (vel): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (heatmap): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "      (3): SeparateHead(\n",
      "        (reg): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (vel): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (heatmap): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "      (4): SeparateHead(\n",
      "        (reg): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (vel): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (heatmap): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "      (5): SeparateHead(\n",
      "        (reg): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (vel): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (heatmap): Sequential(\n",
      "          (0): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
      "    )\n",
      "  )\n",
      "  (map): MapHead(\n",
      "    (task_heads): ModuleDict(\n",
      "      (semantic_seg): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (semantic_seg_criterion): SegmentationLoss()\n",
      "  )\n",
      "  (motion): IterativeFlow(\n",
      "    (task_heads): ModuleDict(\n",
      "      (segmentation): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (instance_center): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (instance_offset): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (instance_flow): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (present_distribution): SpatialDistributionModule(\n",
      "      (encoder): DistributionEncoder(\n",
      "        (model): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (layers): Sequential(\n",
      "              (conv_down_project): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_down_project): Sequential(\n",
      "                (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (abn): Sequential(\n",
      "                (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv_up_project): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_up_project): Sequential(\n",
      "                (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
      "            )\n",
      "            (projection): Sequential(\n",
      "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "              (conv_skip_proj): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn_skip_proj): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (layers): Sequential(\n",
      "              (conv_down_project): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_down_project): Sequential(\n",
      "                (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (abn): Sequential(\n",
      "                (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv_up_project): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_up_project): Sequential(\n",
      "                (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
      "            )\n",
      "            (projection): Sequential(\n",
      "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "              (conv_skip_proj): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn_skip_proj): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (last_conv): Sequential(\n",
      "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (future_distribution): SpatialDistributionModule(\n",
      "      (encoder): DistributionEncoder(\n",
      "        (model): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (layers): Sequential(\n",
      "              (conv_down_project): Conv2d(274, 137, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_down_project): Sequential(\n",
      "                (0): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv): Conv2d(137, 137, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (abn): Sequential(\n",
      "                (0): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv_up_project): Conv2d(137, 137, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_up_project): Sequential(\n",
      "                (0): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
      "            )\n",
      "            (projection): Sequential(\n",
      "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "              (conv_skip_proj): Conv2d(274, 137, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn_skip_proj): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (layers): Sequential(\n",
      "              (conv_down_project): Conv2d(137, 68, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_down_project): Sequential(\n",
      "                (0): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv): Conv2d(68, 68, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (abn): Sequential(\n",
      "                (0): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv_up_project): Conv2d(68, 137, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (abn_up_project): Sequential(\n",
      "                (0): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "              )\n",
      "              (dropout): Dropout2d(p=0.0, inplace=False)\n",
      "            )\n",
      "            (projection): Sequential(\n",
      "              (upsample_skip_proj): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "              (conv_skip_proj): Conv2d(137, 137, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn_skip_proj): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (last_conv): Sequential(\n",
      "        (0): Conv2d(137, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (future_prediction): ResFuturePrediction(\n",
      "      (offset_conv): ConvBlock(\n",
      "        (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (offset_pred): Conv2d(288, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (gru_cells): ModuleList(\n",
      "        (0): GRUCell(\n",
      "          (conv_update): Conv2d(544, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv_reset): Conv2d(544, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv_state_tilde): ConvBlock(\n",
      "            (conv): Conv2d(544, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activation): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (spatial_conv): ConvBlock(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (seg_criterion): MotionSegmentationLoss()\n",
      "    (reg_instance_center_criterion): SpatialRegressionLoss()\n",
      "    (cls_instance_center_criterion): GaussianFocalLoss(\n",
      "      (gaussian_focal_loss): GaussianFocalLoss()\n",
      "    )\n",
      "    (reg_instance_offset_criterion): SpatialRegressionLoss()\n",
      "    (reg_instance_flow_criterion): SpatialRegressionLoss()\n",
      "    (probabilistic_loss): ProbabilisticLoss()\n",
      "  )\n",
      ")\n",
      "------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = build_model(cfg.model, test_cfg=cfg.get(\"test_cfg\"))\n",
    "wrap_fp16_model(model)\n",
    "\n",
    "model.cuda()\n",
    "model = MMDataParallel(model, device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmentation_labels.shape = torch.Size([2, 4, 200, 200])\n",
      "instance_center_labels.shape = torch.Size([2, 4, 1, 200, 200])\n",
      "instance_offset_labels.shape = torch.Size([2, 4, 2, 200, 200])\n",
      "instance_flow_labels.shape = torch.Size([2, 4, 2, 200, 200])\n",
      "gt_instance.shape = torch.Size([2, 4, 200, 200])\n",
      "future_egomotion.shape = torch.Size([2, 6, 6])\n",
      "WARPING\n",
      "Seg labels shape: segmentation_labels.shape =torch.Size([2, 4, 1, 200, 200])\n",
      "gt_instance shape: gt_instance.shape =torch.Size([2, 4, 200, 200])\n",
      "instance_center_labels shape: instance_center_labels.shape = torch.Size([2, 4, 1, 200, 200])\n",
      "instance_offset_labels shape: instance_offset_labels.shape =torch.Size([2, 4, 2, 200, 200])\n",
      "instance_flow_labels shape: instance_flow_labels.shape = torch.Size([2, 4, 2, 200, 200])\n",
      "segmentation_labels.shape = torch.Size([2, 4, 200, 200])\n",
      "instance_center_labels.shape = torch.Size([2, 4, 1, 200, 200])\n",
      "instance_offset_labels.shape = torch.Size([2, 4, 2, 200, 200])\n",
      "instance_flow_labels.shape = torch.Size([2, 4, 2, 200, 200])\n",
      "gt_instance.shape = torch.Size([2, 4, 200, 200])\n",
      "future_egomotion.shape = torch.Size([2, 6, 6])\n",
      "WARPING\n",
      "Seg labels shape: segmentation_labels.shape =torch.Size([2, 4, 1, 200, 200])\n",
      "gt_instance shape: gt_instance.shape =torch.Size([2, 4, 200, 200])\n",
      "instance_center_labels shape: instance_center_labels.shape = torch.Size([2, 4, 1, 200, 200])\n",
      "instance_offset_labels shape: instance_offset_labels.shape =torch.Size([2, 4, 2, 200, 200])\n",
      "instance_flow_labels shape: instance_flow_labels.shape = torch.Size([2, 4, 2, 200, 200])\n",
      "Predicting t+1\n",
      "Predicting t+2\n",
      "Predicting t+3\n",
      "['present_mu', 'present_log_sigma', 'future_mu', 'future_log_sigma', 'segmentation', 'instance_center', 'instance_offset', 'instance_flow']\n",
      "MTL Head Inf\n",
      "MTL Head Inf 3dod\n",
      "get_BBoxes\n",
      "Decode Centerpoint BBoxcoders\n",
      "get_task_detections\n",
      "Decode Centerpoint BBoxcoders\n",
      "get_task_detections\n",
      "Decode Centerpoint BBoxcoders\n",
      "get_task_detections\n",
      "Decode Centerpoint BBoxcoders\n",
      "Decode Centerpoint BBoxcoders\n",
      "get_task_detections\n",
      "Decode Centerpoint BBoxcoders\n",
      "get_task_detections\n",
      "MTL Head Inf map\n",
      "MTL Head Inf motion\n",
      "predict_instance_segmentation_and_trajectories\n",
      "preds seg torch.Size([2, 4, 2, 200, 200])\n",
      "preds seg argmax torch.Size([2, 4, 1, 200, 200])\n",
      "foreground_masksx torch.Size([2, 4, 200, 200])\n",
      "pred_instance_t torch.Size([1, 200, 200]), unbekannt torch.Size([100, 2])\n",
      "pred_instance_t torch.Size([1, 200, 200]), unbekannt torch.Size([100, 2])\n",
      "pred_instance_t torch.Size([1, 200, 200]), unbekannt torch.Size([100, 2])\n",
      "pred_instance_t torch.Size([1, 200, 200]), unbekannt torch.Size([100, 2])\n",
      "pred_instance_t torch.Size([1, 200, 200]), unbekannt torch.Size([100, 2])\n",
      "pred_instance_t torch.Size([1, 200, 200]), unbekannt torch.Size([100, 2])\n",
      "pred_instance_t torch.Size([1, 200, 200]), unbekannt torch.Size([100, 2])\n",
      "pred_instance_t torch.Size([1, 200, 200]), unbekannt torch.Size([100, 2])\n",
      "consistent_instance_seg torch.Size([1, 4, 200, 200])\n",
      "consistent_instance_seg torch.Size([1, 4, 200, 200])\n"
     ]
    }
   ],
   "source": [
    "logger.debug(cfg[\"det_grid_conf\"])\n",
    "logger.debug(cfg[\"motion_grid_conf\"])\n",
    "logger.debug(cfg[\"map_grid_conf\"])\n",
    "\n",
    "\n",
    "bev_resolution, bev_start_position, bev_dimension=calculate_birds_eye_view_parameters(cfg[\"det_grid_conf\"][\"xbound\"],cfg[\"det_grid_conf\"][\"ybound\"],cfg[\"det_grid_conf\"][\"zbound\"])\n",
    "logger.debug(f\"bev_resolution: {bev_resolution}\")\n",
    "logger.debug(f\"bev_start_position: {bev_start_position}\")\n",
    "logger.debug(f\"bev_dimension: {bev_dimension}\")\n",
    "\n",
    "\n",
    "motion_distribution_targets = {\n",
    "    # for motion prediction\n",
    "    'motion_segmentation': sample['motion_segmentation'][0],\n",
    "    'motion_instance': sample['motion_instance'][0],\n",
    "    'instance_centerness': sample['instance_centerness'][0],\n",
    "    'instance_offset': sample['instance_offset'][0],\n",
    "    'instance_flow': sample['instance_flow'][0],\n",
    "    'future_egomotion': sample['future_egomotions'][0],\n",
    "}\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    result = model(\n",
    "        return_loss=False,\n",
    "        rescale=True,\n",
    "        img_metas=sample['img_metas'],\n",
    "        img_inputs=sample['img_inputs'],\n",
    "        future_egomotions=sample['future_egomotions'],\n",
    "        motion_targets=motion_distribution_targets,\n",
    "        img_is_valid=sample['img_is_valid'][0],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'device_ids',\n",
       " 'dim',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'gather',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'load_state_dict',\n",
       " 'module',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'output_device',\n",
       " 'parallel_apply',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_parameter',\n",
       " 'replicate',\n",
       " 'requires_grad_',\n",
       " 'scatter',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'src_device_obj',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'train_step',\n",
       " 'training',\n",
       " 'type',\n",
       " 'val_step',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_dump_init_info',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_is_init',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_parse_losses',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'aforward_test',\n",
       " 'apply',\n",
       " 'async_simple_test',\n",
       " 'aug_test',\n",
       " 'aug_test_pts',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'combine_bev_output',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'data_aug_conf',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'extract_feat',\n",
       " 'extract_feats',\n",
       " 'extract_img_feat',\n",
       " 'extract_img_feat_tta',\n",
       " 'extract_pts_feat',\n",
       " 'flip_bev_output',\n",
       " 'flip_feature',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'forward_dummy',\n",
       " 'forward_img_train',\n",
       " 'forward_pts_train',\n",
       " 'forward_test',\n",
       " 'forward_train',\n",
       " 'fp16_enabled',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'img_backbone',\n",
       " 'img_neck',\n",
       " 'init_cfg',\n",
       " 'init_weights',\n",
       " 'is_init',\n",
       " 'load_state_dict',\n",
       " 'logger',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'onnx_export',\n",
       " 'parameters',\n",
       " 'pts_bbox_head',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'show_result',\n",
       " 'show_results',\n",
       " 'simple_test',\n",
       " 'simple_test_img',\n",
       " 'simple_test_pts',\n",
       " 'simple_test_rpn',\n",
       " 'state_dict',\n",
       " 'temporal_model',\n",
       " 'test_cfg',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'train_cfg',\n",
       " 'train_step',\n",
       " 'training',\n",
       " 'transformer',\n",
       " 'type',\n",
       " 'val_step',\n",
       " 'voxelize',\n",
       " 'with_bbox',\n",
       " 'with_fusion',\n",
       " 'with_img_backbone',\n",
       " 'with_img_bbox',\n",
       " 'with_img_neck',\n",
       " 'with_img_roi_head',\n",
       " 'with_img_rpn',\n",
       " 'with_img_shared_head',\n",
       " 'with_mask',\n",
       " 'with_middle_encoder',\n",
       " 'with_neck',\n",
       " 'with_pts_backbone',\n",
       " 'with_pts_bbox',\n",
       " 'with_pts_neck',\n",
       " 'with_shared_head',\n",
       " 'with_voxel_encoder',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pred_semantic_indices', 'motion_predictions', 'motion_segmentation', 'motion_instance', 'bbox_results', 'time_stats'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boxes_3d', 'scores_3d', 'labels_3d'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"bbox_results\"][0][\"pts_bbox\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scores_3d - torch.Size([498])\n",
    "labels_3d - torch.Size([498])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([498])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['bbox_results'][0]['pts_bbox'][\"labels_3d\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 'bev', torch.Size([498, 5])\n",
    " 'bottom_center', torch.Size([498, 3])\n",
    " 'bottom_height', torch.Size([498])\n",
    " 'box_dim', 9 \n",
    " 'cat',\n",
    " 'center', orch.Size([498, 3])\n",
    " 'clone',\n",
    " 'convert_to',\n",
    " 'corners',\n",
    " 'device',\n",
    " 'dims',\n",
    " 'enlarged_box',\n",
    " 'flip',\n",
    " 'gravity_center', torch.Size([498, 3])\n",
    " 'height', torch.Size([498])\n",
    " 'height_overlaps',\n",
    " 'in_range_3d',\n",
    " 'in_range_bev',\n",
    " 'limit_yaw',\n",
    " 'nearest_bev',\n",
    " 'new_box',\n",
    " 'nonempty',\n",
    " 'overlaps',\n",
    " 'points_in_boxes',\n",
    " 'rotate',\n",
    " 'scale',\n",
    " 'tensor',\n",
    " 'to',\n",
    " 'top_height',\n",
    " 'translate',\n",
    " 'volume', torch.Size([498])\n",
    " 'with_yaw',\n",
    " 'yaw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2716849234.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [12], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    image (T: 3 H: 65 W: 178) smaller than kernel size (kT: 2 kH: 128 kW: 128)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "image (T: 3 H: 65 W: 178) smaller than kernel size (kT: 2 kH: 128 kW: 128)\n",
    "\n",
    "\n",
    "update\n",
    "pyramid pooling:  torch.Size([1, 70, 3, 128, 128])\n",
    "x_pool:  torch.Size([1, 23, 3, 1, 1])\n",
    "c:  23\n",
    "x_pool2:  torch.Size([3, 23, 128, 128])\n",
    "x_pool3:  torch.Size([1, 23, 3, 128, 128])\n",
    "update\n",
    "pyramid pooling:  torch.Size([1, 64, 3, 128, 128])\n",
    "x_pool:  torch.Size([1, 21, 3, 1, 1])\n",
    "c:  21\n",
    "x_pool2:  torch.Size([3, 21, 128, 128])\n",
    "x_pool3:  torch.Size([1, 21, 3, 128, 128])\n",
    "feats-1: torch.Size([1, 512, 25, 50]), feats-3: torch.Size([1, 128, 100, 200])\n",
    "Up: x1 torch.Size([1, 512, 100, 200]), x2 torch.Size([1, 128, 100, 200])\n",
    "feats-1: torch.Size([1, 512, 16, 16]), feats-3: torch.Size([1, 128, 64, 64])\n",
    "Up: x1 torch.Size([1, 512, 64, 64]), x2 torch.Size([1, 128, 64, 64])\n",
    "feats-1: torch.Size([1, 512, 25, 25]), feats-3: torch.Size([1, 128, 100, 100])\n",
    "Up: x1 torch.Size([1, 512, 100, 100]), x2 torch.Size([1, 128, 100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"IMAGE\": {\n",
    "    \"ORIGINAL_HEIGHT\": 900,\n",
    "    \"ORIGINAL_WIDTH\": 1600,\n",
    "    \"FINAL_DIM\": (512, 1408),\n",
    "    \"RESIZE_SCALE\": 0.25,\n",
    "    \"TOP_CROP\": 0,\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['IMAGE'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero padding left and right parts of the image.\n",
      "Zero padding bottom part of the image.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'scale_width': 0.25,\n",
       " 'scale_height': 0.25,\n",
       " 'resize_dims': (400, 225),\n",
       " 'crop': (0, 0, 1408, 512)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_resizing_and_cropping_parameters(config):\n",
    "    original_height, original_width = config[\"IMAGE\"][\"ORIGINAL_HEIGHT\"], config[\"IMAGE\"][\"ORIGINAL_WIDTH\"]\n",
    "    final_height, final_width = config[\"IMAGE\"][\"FINAL_DIM\"]\n",
    "\n",
    "    resize_scale = config[\"IMAGE\"][\"RESIZE_SCALE\"]\n",
    "    resize_dims = (int(original_width * resize_scale), int(original_height * resize_scale))\n",
    "    resized_width, resized_height = resize_dims\n",
    "\n",
    "    crop_h = config[\"IMAGE\"][\"TOP_CROP\"]\n",
    "    crop_w = int(max(0, (resized_width - final_width) / 2))\n",
    "    # Left, top, right, bottom crops.\n",
    "    crop = (crop_w, crop_h, crop_w + final_width, crop_h + final_height)\n",
    "\n",
    "    if resized_width != final_width:\n",
    "        print('Zero padding left and right parts of the image.')\n",
    "    if crop_h + final_height != resized_height:\n",
    "        print('Zero padding bottom part of the image.')\n",
    "\n",
    "    return {'scale_width': resize_scale,\n",
    "            'scale_height': resize_scale,\n",
    "            'resize_dims': resize_dims,\n",
    "            'crop': crop,\n",
    "            }\n",
    "get_resizing_and_cropping_parameters(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t_BEV': 1663055717.0110373,\n",
       " 't_temporal': 1663055717.5791538,\n",
       " 't0': 1663055712.6830127,\n",
       " 't_end': 1663055746.884341}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"time_stats\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x, rots, trans, intrins, post_rots, post_trans = input\n",
    "\n",
    "'CAM_FRONT_RIGHT': {\n",
    "    'data_path': './data/nuscenes/samples/CAM_FRONT_RIGHT/n015-2018-10-08-15-36-50+0800__CAM_FRONT_RIGHT__1538984233520339.jpg', \n",
    "    'type': 'CAM_FRONT_RIGHT', \n",
    "    'sample_data_token': 'd6f89460954c43d39ed7c9ac91ab03d0', \n",
    "    'sensor2ego_translation': [1.5508477543, -0.493404796419, 1.49574800619], \n",
    "    'sensor2ego_rotation': [0.2060347966337182, -0.2026940577919598, 0.6824507824531167, -0.6713610884174485], 'ego2global_translation': [715.6566537856895, 1810.1516804263824, 0.0], \n",
    "    'ego2global_rotation': [0.8004835927391405, 0.00541081062084495, -0.0028680900818508943, -0.5993233809414961], 'timestamp': 1538984233520339, \n",
    "    'sensor2lidar_rotation': array([[ 0.55971752, -0.01057234,  0.82861603],\n",
    "       [-0.82828535,  0.02385392,  0.55979851],\n",
    "       [-0.02568412, -0.99965955,  0.00459454]]), \n",
    "    'sensor2lidar_translation': array([ 0.48135698,  0.51094805, -0.32997566]), \n",
    "    'cam_intrinsic': array([[1.26084744e+03, 0.00000000e+00, 8.07968245e+02],\n",
    "       [0.00000000e+00, 1.26084744e+03, 4.95334427e+02],\n",
    "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future Egomotions:  torch.Size([1, 7, 6])\n",
      "img_is_valid:  torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "num_warmups = 100\n",
    "num_repeats = 1000\n",
    "# Change to C x 1 x 3 x 1600 x 900\n",
    "# 704256 Tiny\n",
    "# 1408512\n",
    "# B, S, N, C, imH, imW = imgs.shape\n",
    "img_inputs =  torch.rand(1,7,6,3,704,256).cuda()\n",
    "# (batch, seq, num_cam)\n",
    "future_egomotions = torch.zeros((batch_size, 7, 6)).type_as(img_inputs).cuda()\n",
    "img_is_valid = torch.ones((batch_size, 7)).type_as(img_inputs) > 0\n",
    "img_is_valid.cuda()\n",
    "print(\"Future Egomotions: \", future_egomotions.shape)\n",
    "print(\"img_is_valid: \", img_is_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #single frame \n",
    "# future_egomotions = future_egomotions[:, :1]\n",
    "# img_is_valid = img_is_valid[:, :1]\n",
    "# print(\"Future Egomotions: \", future_egomotions.shape)\n",
    "# print(\"img_is_valid: \", img_is_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([3])\n",
      "image meta: [{'box_type_3d': <class 'mmdet3d.core.bbox.structures.lidar_box3d.LiDARInstance3DBoxes'>, 'lidar2ego_rots': tensor([[-5.4280e-04,  9.9893e-01,  4.6229e-02],\n",
      "        [-1.0000e+00, -4.0569e-04, -2.9750e-03],\n",
      "        [-2.9531e-03, -4.6231e-02,  9.9893e-01]]), 'lidar2ego_trans': tensor([0.9858, 0.0000, 1.8402])}]\n"
     ]
    }
   ],
   "source": [
    "from mmdet3d.core.bbox.structures.box_3d_mode import LiDARInstance3DBoxes\n",
    "\n",
    "dummy_lidar2ego_rots = (\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [-5.4280e-04, 9.9893e-01, 4.6229e-02],\n",
    "            [-1.0000e00, -4.0569e-04, -2.9750e-03],\n",
    "            [-2.9531e-03, -4.6231e-02, 9.9893e-01],\n",
    "        ]\n",
    "    )\n",
    "    .type_as(img_inputs)\n",
    "    .cpu()\n",
    ")\n",
    "dummy_lidar2ego_trans = (\n",
    "    torch.tensor([0.9858, 0.0000, 1.8402]).type_as(img_inputs).cpu()\n",
    ")\n",
    "print(dummy_lidar2ego_rots.shape)\n",
    "print(dummy_lidar2ego_trans.shape)\n",
    "img_metas = [\n",
    "    dict(\n",
    "        box_type_3d=LiDARInstance3DBoxes,\n",
    "        lidar2ego_rots=dummy_lidar2ego_rots,\n",
    "        lidar2ego_trans=dummy_lidar2ego_trans,\n",
    "    )\n",
    "]\n",
    "print(\"image meta:\", img_metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'projects.mmdet3d_plugin.models.detectors.beverse.BEVerse'>\n"
     ]
    }
   ],
   "source": [
    "model = build_model(cfg.model, test_cfg=cfg.get(\"test_cfg\"))\n",
    "print(type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch?:  torch.Size([1, 7, 6, 3, 704, 256])\n",
      "B 1, S 7, 6, C 3, imH 704, imW 256\n",
      "imgs  torch.Size([42, 3, 704, 256])\n",
      "after backbone:  2\n",
      "shape in list:  [torch.Size([42, 384, 44, 16]), torch.Size([42, 768, 22, 8])]\n",
      "after backbone with_img_neck:  torch.Size([42, 512, 44, 16])\n",
      "after transformation:  torch.Size([1, 7, 6, 512, 44, 16])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"Tensor\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(cfg\u001b[38;5;241m.\u001b[39mmodel, test_cfg\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_cfg\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      2\u001b[0m wrap_fp16_model(model)\n\u001b[0;32m----> 3\u001b[0m img_feats,time_dict  \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_img_feat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimg_metas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_metas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfuture_egomotion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_egomotions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimg_is_valid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_is_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(img_feats\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(time_dict)\n",
      "File \u001b[0;32m~/ETM_BEV/BEVerse/projects/mmdet3d_plugin/models/detectors/beverse.py:105\u001b[0m, in \u001b[0;36mBEVerse.extract_img_feat\u001b[0;34m(self, img, img_metas, future_egomotion, aug_transform, img_is_valid, count_time)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mafter transformation: \u001b[39m\u001b[39m\"\u001b[39m, x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    104\u001b[0m \u001b[39m# lifting with LSS\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer([x] \u001b[39m+\u001b[39;49m img[\u001b[39m1\u001b[39;49m:])\n\u001b[1;32m    107\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39msynchronize()\n\u001b[1;32m    108\u001b[0m t_BEV \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"Tensor\") to list"
     ]
    }
   ],
   "source": [
    "model = build_model(cfg.model, test_cfg=cfg.get(\"test_cfg\")).cuda()\n",
    "wrap_fp16_model(model)\n",
    "img_feats,time_dict  = model.extract_img_feat(\n",
    "            img=img_inputs,\n",
    "            img_metas=img_metas,\n",
    "            future_egomotion=future_egomotions,\n",
    "            img_is_valid=img_is_valid,\n",
    "        )\n",
    "print(img_feats.shape)\n",
    "print(time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2000,  0.2000, 20.0000]) tensor([-51.1000, -51.1000,   0.0000]) tensor([512, 512,   1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_362/3561629359.py:21: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  bev_dimension = torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "# 'xbound': [-51.2, 51.2, 0.2], 'ybound': [-51.2, 51.2, 0.2], 'zbound': [-10.0, 10.0, 20.0], 'dbound': [1.0, 60.0, 0.5]}\n",
    "\n",
    "\n",
    "\n",
    "x_bounds, y_bounds, z_bounds = [-51.2, 51.2, 0.2], [-51.2, 51.2, 0.2], [-10.0, 10.0, 20.0]\n",
    "\n",
    "bev_resolution, bev_start_position, bev_dimension = calculate_birds_eye_view_parameters(x_bounds, y_bounds, z_bounds)\n",
    "\n",
    "print(bev_resolution, bev_start_position, bev_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_bounds, y_bounds, z_bounds = [-26.2, 26.2, 0.8], [-71.2, 71.2, 0.8], [-10.0, 10.0, 20.0]\n",
    "tensor([ 0.8000,  0.8000, 20.0000]) tensor([-25.8000, -70.8000,   0.0000]) tensor([ 65, 178,   1])\n",
    "\n",
    "\n",
    "x_bounds, y_bounds, z_bounds = [-26.2, 26.2, 0.4], [-71.2, 71.2, 0.4], [-10.0, 10.0, 20.0]\n",
    "tensor([ 0.4000,  0.4000, 20.0000]) tensor([-26., -71.,   0.]) tensor([131, 356,   1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0, 7, 6, 3, 704, 256])\n",
      "torch.Size([1, 7, 6, 3, 704, 256])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"Tensor\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m img_inputs \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m704\u001b[39m,\u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(img_inputs[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 6\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtrans_output\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m test\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"Tensor\") to list"
     ]
    }
   ],
   "source": [
    "img_inputs =  torch.rand(1,7,6,3,704,256)\n",
    "print(img_inputs[1:].shape)\n",
    "trans_output = torch.rand(1, 7, 6, 512, 44, 16)\n",
    "img_inputs =  torch.rand(2,7,6,3,704,256)\n",
    "print(img_inputs[1:].shape)\n",
    "test = [trans_output] + img_inputs[1:]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency Measurement Using CPU Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: N/A     ms| \n",
      "Latency Measurement Using CUDA Timer...\n",
      "|Synchronization: True | Continuous Measurement: True | Latency: N/A     ms| \n",
      "|Synchronization: False| Continuous Measurement: True | Latency: N/A     ms| \n",
      "|Synchronization: True | Continuous Measurement: False| Latency: N/A     ms| \n",
      "|Synchronization: False| Continuous Measurement: False| Latency: N/A     ms| \n",
      "Latency Measurement Using PyTorch Benchmark...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dummy_input.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 95\u001b[0m\n\u001b[1;32m     85\u001b[0m num_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     86\u001b[0m timer \u001b[38;5;241m=\u001b[39m benchmark\u001b[38;5;241m.\u001b[39mTimer(\n\u001b[1;32m     87\u001b[0m     stmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_inference(model, input_tensor)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m     setup\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom __main__ import run_inference\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m     sub_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.utils.benchmark.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     93\u001b[0m )\n\u001b[0;32m---> 95\u001b[0m profile_result \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_repeats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# https://pytorch.org/docs/stable/_modules/torch/utils/benchmark/utils/common.html#Measurement\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatency: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprofile_result\u001b[38;5;241m.\u001b[39mmean \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/torch/utils/benchmark/utils/timer.py:261\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39m\"\"\"Mirrors the semantics of timeit.Timer.timeit().\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \n\u001b[1;32m    256\u001b[0m \u001b[39mExecute the main statement (`stmt`) `number` times.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[39mhttps://docs.python.org/3/library/timeit.html#timeit.Timer.timeit\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39mwith\u001b[39;00m common\u001b[39m.\u001b[39mset_torch_threads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_spec\u001b[39m.\u001b[39mnum_threads):\n\u001b[1;32m    260\u001b[0m     \u001b[39m# Warmup\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timer\u001b[39m.\u001b[39;49mtimeit(number\u001b[39m=\u001b[39;49m\u001b[39mmax\u001b[39;49m(\u001b[39mint\u001b[39;49m(number \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m100\u001b[39;49m), \u001b[39m2\u001b[39;49m))\n\u001b[1;32m    263\u001b[0m     \u001b[39mreturn\u001b[39;00m common\u001b[39m.\u001b[39mMeasurement(\n\u001b[1;32m    264\u001b[0m         number_per_run\u001b[39m=\u001b[39mnumber,\n\u001b[1;32m    265\u001b[0m         raw_times\u001b[39m=\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timer\u001b[39m.\u001b[39mtimeit(number\u001b[39m=\u001b[39mnumber)],\n\u001b[1;32m    266\u001b[0m         task_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_spec\n\u001b[1;32m    267\u001b[0m     )\n",
      "File \u001b[0;32m/usr/lib/python3.8/timeit.py:177\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    175\u001b[0m gc\u001b[39m.\u001b[39mdisable()\n\u001b[1;32m    176\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     timing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(it, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimer)\n\u001b[1;32m    178\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[39mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<timeit-src>:6\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn [15], line 89\u001b[0m, in \u001b[0;36mrun_inference\u001b[0;34m(model, input_tensor)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_inference\u001b[39m(model: nn\u001b[38;5;241m.\u001b[39mModule, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# from model.forward because BEVerse differentiates between different input types - img lidar etc \u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_dummy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ETM_BEV/BEVerse/projects/mmdet3d_plugin/models/detectors/beverse.py:209\u001b[0m, in \u001b[0;36mforward_dummy\u001b[0;34m(self, img_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39m\"\"\"Forward training function.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \n\u001b[1;32m    169\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39m    dict: Losses of different branches.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    193\u001b[0m img_feats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_img_feat(\n\u001b[1;32m    194\u001b[0m     img\u001b[39m=\u001b[39mimg_inputs,\n\u001b[1;32m    195\u001b[0m     img_metas\u001b[39m=\u001b[39mimg_metas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m     img_is_valid\u001b[39m=\u001b[39mimg_is_valid,\n\u001b[1;32m    199\u001b[0m )\n\u001b[1;32m    201\u001b[0m mtl_targets \u001b[39m=\u001b[39m {\n\u001b[1;32m    202\u001b[0m     \u001b[39m# for detection\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgt_bboxes_3d\u001b[39m\u001b[39m\"\u001b[39m: gt_bboxes_3d,\n\u001b[1;32m    204\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgt_labels_3d\u001b[39m\u001b[39m\"\u001b[39m: gt_labels_3d,\n\u001b[1;32m    205\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgt_bboxes_ignore\u001b[39m\u001b[39m\"\u001b[39m: gt_bboxes_ignore,\n\u001b[1;32m    206\u001b[0m     \u001b[39m# for map segmentation\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msemantic_seg\u001b[39m\u001b[39m\"\u001b[39m: semantic_indices,\n\u001b[1;32m    208\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msemantic_map\u001b[39m\u001b[39m\"\u001b[39m: semantic_map,\n\u001b[0;32m--> 209\u001b[0m     \u001b[39m# for motion prediction\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmotion_segmentation\u001b[39m\u001b[39m\"\u001b[39m: motion_segmentation,\n\u001b[1;32m    211\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmotion_instance\u001b[39m\u001b[39m\"\u001b[39m: motion_instance,\n\u001b[1;32m    212\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minstance_centerness\u001b[39m\u001b[39m\"\u001b[39m: instance_centerness,\n\u001b[1;32m    213\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minstance_offset\u001b[39m\u001b[39m\"\u001b[39m: instance_offset,\n\u001b[1;32m    214\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minstance_flow\u001b[39m\u001b[39m\"\u001b[39m: instance_flow,\n\u001b[1;32m    215\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfuture_egomotion\u001b[39m\u001b[39m\"\u001b[39m: future_egomotions,\n\u001b[1;32m    216\u001b[0m     \u001b[39m# for bev_augmentation\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maug_transform\u001b[39m\u001b[39m\"\u001b[39m: aug_transform,\n\u001b[1;32m    218\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimg_is_valid\u001b[39m\u001b[39m\"\u001b[39m: img_is_valid,\n\u001b[1;32m    219\u001b[0m }\n\u001b[1;32m    221\u001b[0m loss_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_pts_train(img_feats, img_metas, mtl_targets)\n\u001b[1;32m    223\u001b[0m \u001b[39mreturn\u001b[39;00m loss_dict\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/torch/serialization.py:594\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    592\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 594\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    595\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    596\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/ETM_BEV/venv/lib/python3.8/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dummy_input.pt'"
     ]
    }
   ],
   "source": [
    "\n",
    "num_warmups = 100\n",
    "num_repeats = 1000\n",
    "# Change to C x 1 x 3 x 1600 x 900\n",
    "# 704256 Tiny\n",
    "# 1408512\n",
    "# B, T, N, C, imH, imW = imgs.shape\n",
    "input_shape = (1,3,6,3,1600,900)\n",
    "\n",
    "future_egomotions = torch.zeros((batch_size, 7, 6)).type_as(img_inputs)\n",
    "img_is_valid = torch.ones((batch_size, 7)).type_as(img_inputs) > 0\n",
    "print(\"Future Egomotions: \", future_egomotions.shape)\n",
    "print(\"img_is_valid: \", img_is_valid.shape)\n",
    "\n",
    "\n",
    "# imgs = imgs.view(B * S * N, C, imH, imW)\n",
    "\n",
    "model = build_model(cfg.model, test_cfg=cfg.get(\"test_cfg\"))\n",
    "wrap_fp16_model(model)\n",
    "# load_checkpoint(\n",
    "#     model,\n",
    "#     r\"/home/niklas/ETM_BEV/BEVerse/checkpoints/beverse_tiny.pth\",\n",
    "#     map_location=\"cpu\",\n",
    "# )\n",
    "# model = fuse_module(model)\n",
    "model.cuda(device)\n",
    "model.eval()\n",
    "# model = nn.Conv2d(in_channels=input_shape[1], out_channels=256, kernel_size=(5, 5))\n",
    "\n",
    "# Input tensor\n",
    "input_tensor = torch.rand(input_shape, device=device)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "print(\"Latency Measurement Using CPU Timer...\")\n",
    "for continuous_measure in [True]:\n",
    "    for synchronize in [True]:\n",
    "        try:\n",
    "            latency_ms = measure_time_host(\n",
    "                model=model,\n",
    "                input_tensor=input_tensor,\n",
    "                num_repeats=num_repeats,\n",
    "                num_warmups=num_warmups,\n",
    "                synchronize=synchronize,\n",
    "                continuous_measure=continuous_measure,\n",
    "            )\n",
    "            print(\n",
    "                f\"|\"\n",
    "                f\"Synchronization: {synchronize!s:5}| \"\n",
    "                f\"Continuous Measurement: {continuous_measure!s:5}| \"\n",
    "                f\"Latency: {latency_ms:.5f} ms| \"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"|\"\n",
    "                f\"Synchronization: {synchronize!s:5}| \"\n",
    "                f\"Continuous Measurement: {continuous_measure!s:5}| \"\n",
    "                f\"Latency: N/A     ms| \"\n",
    "            )\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "print(\"Latency Measurement Using CUDA Timer...\")\n",
    "for continuous_measure in [True, False]:\n",
    "    for synchronize in [True, False]:\n",
    "        try:\n",
    "            latency_ms = measure_time_device(\n",
    "                model=model,\n",
    "                input_tensor=input_tensor,\n",
    "                num_repeats=num_repeats,\n",
    "                num_warmups=num_warmups,\n",
    "                synchronize=synchronize,\n",
    "                continuous_measure=continuous_measure,\n",
    "            )\n",
    "            print(\n",
    "                f\"|\"\n",
    "                f\"Synchronization: {synchronize!s:5}| \"\n",
    "                f\"Continuous Measurement: {continuous_measure!s:5}| \"\n",
    "                f\"Latency: {latency_ms:.5f} ms| \"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"|\"\n",
    "                f\"Synchronization: {synchronize!s:5}| \"\n",
    "                f\"Continuous Measurement: {continuous_measure!s:5}| \"\n",
    "                f\"Latency: N/A     ms| \"\n",
    "            )\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "print(\"Latency Measurement Using PyTorch Benchmark...\")\n",
    "num_threads = 1\n",
    "timer = benchmark.Timer(\n",
    "    stmt=\"run_inference(model, input_tensor)\",\n",
    "    setup=\"from __main__ import run_inference\",\n",
    "    globals={\"model\": model, \"input_tensor\": input_tensor},\n",
    "    num_threads=num_threads,\n",
    "    label=\"Latency Measurement\",\n",
    "    sub_label=\"torch.utils.benchmark.\",\n",
    ")\n",
    "\n",
    "profile_result = timer.timeit(num_repeats)\n",
    "# https://pytorch.org/docs/stable/_modules/torch/utils/benchmark/utils/common.html#Measurement\n",
    "print(f\"Latency: {profile_result.mean * 1000:.5f} ms\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49a6cb26e152f15aca94d1d3fa9630fb57fb8fd83a336982cd2ebf9e9635e69c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
